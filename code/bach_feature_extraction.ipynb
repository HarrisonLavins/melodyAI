{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from music21 import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from math import ceil, floor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the notes from each piece in the corpus and place in in the x_train variable\n",
    "\n",
    "bach_corpus = corpus.getComposer('bach')\n",
    "# pitch_train/duration_train are NOT one-hot encoded, but hold data that will be transformed to one-hot later\n",
    "pitch_train = []  # training data for the sequence of pitches (MIDI number)\n",
    "duration_train = []  # training data for the sequence of note durations (floats)\n",
    "pitch_freq = {} # how often a given pitch occurs (will be normalized after all pieces have been analyzed)\n",
    "duration_freq = {}  # how often each pitch occurs (will be normalized after all pieces have been analyzed)\n",
    "starting_pitch_likelihood = {}  # how likely a piece is to start with a given MIDI pitch \n",
    "starting_duration_likelihood = {}  # how likely a piece is to start with a given duration\n",
    "\n",
    "for piece in bach_corpus:\n",
    "    piece_score = corpus.parse(piece)  # stream.Score object\n",
    "    melody_part = piece_score.getElementsByClass('Part')[0]  # melody parts are always the first part in the score\n",
    "    melody_notes = melody_part.flat.getElementsByClass(['Note', 'Rest'])\n",
    "    \n",
    "    # transpose all pitches within the range of +6 to -5 half steps (including the unaltered version)\n",
    "    for i in range(6,-6,-1):\n",
    "        # transpose the melody part\n",
    "        melody_transposed = melody_notes.transpose(i)\n",
    "        pitch_sequence = []  # the sequence of MIDI pitches for this piece\n",
    "        duration_sequence = []  # the sequence of quarter length note durations for this piece\n",
    "    \n",
    "        is_first_note = True # used to build the prob. dist of starting pitch/duration\n",
    "        # builds the feature vectors by One-Hot encoding MIDI numbers and durations\n",
    "        for n in melody_transposed.recurse():  # iterates through all notes in the piece\n",
    "            note_duration = n.duration.quarterLength\n",
    "            if note_duration < 0.25 or note_duration >= 6.0:\n",
    "                continue  # discard all notes less than 16th notes\n",
    "            else:\n",
    "                duration_sequence.append(note_duration)\n",
    "                if note_duration not in duration_freq.keys():\n",
    "                    duration_freq[note_duration] = 1\n",
    "                else:\n",
    "                    duration_freq[note_duration] += 1\n",
    "                duration_sequence.append(note_duration)\n",
    "\n",
    "            if n.isNote:  # and is therefore not a rest; has pitch\n",
    "                midi_pitch = n.pitch.midi\n",
    "                pitch_sequence.append(midi_pitch)\n",
    "                if midi_pitch not in pitch_freq.keys():\n",
    "                    pitch_freq[midi_pitch] = 1\n",
    "                else:\n",
    "                    pitch_freq[midi_pitch] += 1\n",
    "            else:  # is a rest\n",
    "                if -1 not in pitch_freq.keys():\n",
    "                    pitch_freq[-1] = 1\n",
    "                else:\n",
    "                    pitch_freq[-1] += 1\n",
    "                pitch_sequence.append(-1) # -1 pitch indicates it is a rest (will one-hot encode to 0 vector)\n",
    "                \n",
    "            if is_first_note: # save the note info to keep track of how often each pitch/duration starts a piece\n",
    "                if midi_pitch in starting_pitch_likelihood.keys():\n",
    "                    starting_pitch_likelihood[midi_pitch] += 1\n",
    "                else:\n",
    "                    starting_pitch_likelihood[midi_pitch] = 1\n",
    "                    \n",
    "                if note_duration in starting_duration_likelihood:\n",
    "                    starting_duration_likelihood[note_duration] += 1\n",
    "                else:\n",
    "                    starting_duration_likelihood[note_duration] = 1\n",
    "                    \n",
    "                is_first_note = False\n",
    "        \n",
    "        pitch_train.append(pitch_sequence)\n",
    "        duration_train.append(duration_sequence) \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitches, durations = sorted(list(pitch_freq.keys())), sorted(list(duration_freq.keys()))\n",
    "num_pitches, num_durations = len(pitches), len(durations)\n",
    "\n",
    "# dictionary to map possible pitch/duration to a one-hot vector index\n",
    "pitch_indices = {p: i for (i, p) in enumerate(pitches)}\n",
    "duration_indices = {d: i for (i, d) in enumerate(durations)}\n",
    "# normalize the frequency of ALL pitches/duration\n",
    "pitch_freq = {p: float(pitch_freq[p]/sum(pitch_freq.values())) for p in sorted(pitch_freq.keys())}\n",
    "duration_freq = {d: float(duration_freq[d]/sum(duration_freq.values())) for d in sorted(duration_freq.keys())}\n",
    "# normalize the occurrences of STARTING pitches/durations\n",
    "starting_pitch_likelihood = {p: float(starting_pitch_likelihood[p]/sum(starting_pitch_likelihood.values())) for p in sorted(starting_pitch_likelihood.keys())}\n",
    "starting_duration_likelihood = {d: float(starting_duration_likelihood[d]/sum(starting_duration_likelihood.values())) for d in sorted(starting_duration_likelihood.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{23: 24,\n",
       " 25: 24,\n",
       " 27: 24,\n",
       " 29: 24,\n",
       " 30: 24,\n",
       " 31: 24,\n",
       " 32: 108,\n",
       " 33: 84,\n",
       " 34: 96,\n",
       " 35: 120,\n",
       " 36: 36,\n",
       " 37: 180,\n",
       " 38: 108,\n",
       " 39: 120,\n",
       " 40: 96,\n",
       " 41: 156,\n",
       " 42: 144,\n",
       " 43: 216,\n",
       " 44: 168,\n",
       " 45: 156,\n",
       " 46: 336,\n",
       " 47: 144,\n",
       " 48: 108,\n",
       " 49: 144,\n",
       " 50: 120,\n",
       " 51: 180,\n",
       " 52: 144,\n",
       " 53: 96,\n",
       " 54: 84,\n",
       " 55: 96,\n",
       " 56: 60,\n",
       " 57: 60,\n",
       " 58: 12,\n",
       " 59: 120,\n",
       " 60: 72,\n",
       " 61: 36,\n",
       " 62: 36,\n",
       " 63: 72,\n",
       " 64: 108,\n",
       " 65: 72,\n",
       " 66: 72,\n",
       " 67: 60,\n",
       " 68: 60,\n",
       " 69: 24,\n",
       " 70: 60,\n",
       " 71: 60,\n",
       " 72: 36,\n",
       " 73: 12,\n",
       " 74: 12,\n",
       " 75: 12,\n",
       " 76: 36,\n",
       " 77: 12,\n",
       " 78: 12,\n",
       " 79: 12,\n",
       " 81: 36,\n",
       " 82: 36,\n",
       " 86: 12,\n",
       " 87: 24,\n",
       " 88: 12,\n",
       " 89: 24,\n",
       " 92: 12,\n",
       " 98: 12,\n",
       " 99: 12,\n",
       " 100: 24,\n",
       " 103: 12,\n",
       " 105: 48,\n",
       " 107: 12,\n",
       " 109: 24,\n",
       " 114: 12,\n",
       " 117: 12,\n",
       " 122: 12,\n",
       " 133: 12,\n",
       " 150: 12,\n",
       " 154: 12,\n",
       " 176: 12,\n",
       " 187: 12,\n",
       " 219: 12,\n",
       " 362: 12,\n",
       " 464: 12,\n",
       " 573: 12}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length_counts = {}\n",
    "all_sequence_lengths = []\n",
    "for sequence in pitch_train:\n",
    "    if len(sequence) == 0:\n",
    "        continue\n",
    "    if len(sequence) in sequence_length_counts.keys():\n",
    "        sequence_length_counts[len(sequence)] += 1\n",
    "    else:\n",
    "        sequence_length_counts[len(sequence)] = 1\n",
    "\n",
    "sequence_length_counts = {key: sequence_length_counts[key] for key in sorted(sequence_length_counts.keys())}\n",
    "\n",
    "sequence_length_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrarily decide on ceiling/floor of lengths that we will consider for training\n",
    "# this is a bit clunky, but I'm trying to make it an general as possible (in case the corpus somehow drastically changes)\n",
    "min_length, max_length = 40, 70\n",
    "range_size = ceil((max_length - min_length) / 3)\n",
    "short_range = range(min_length, min_length + range_size)\n",
    "medium_range = range(min_length + range_size, max_length - range_size) \n",
    "long_range = range(max_length - range_size, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences before pruning: 5196\n",
      "Number of sequences (short, medium, long) after pruning: (1668, 972, 612)\n"
     ]
    }
   ],
   "source": [
    "# prune the data set\n",
    "print(f\"Number of sequences before pruning: {len(pitch_train)}\")\n",
    "short_sequences_duration = []\n",
    "short_sequences_pitch = []\n",
    "medium_sequences_duration = []\n",
    "medium_sequences_pitch = []\n",
    "long_sequences_duration = []\n",
    "long_sequences_pitch = []\n",
    "\n",
    "for seq_index in range(len(pitch_train)):\n",
    "    # the sequence must fall in one of the ranges we have determined\n",
    "    if len(pitch_train[seq_index]) in short_range:\n",
    "        short_sequences_duration.append(duration_train[seq_index])\n",
    "        short_sequences_pitch.append(pitch_train[seq_index])\n",
    "    elif len(pitch_train[seq_index]) in medium_range:\n",
    "        medium_sequences_duration.append(duration_train[seq_index])\n",
    "        medium_sequences_pitch.append(pitch_train[seq_index])\n",
    "    elif len(pitch_train[seq_index]) in long_range:\n",
    "        long_sequences_duration.append(duration_train[seq_index])\n",
    "        long_sequences_pitch.append(pitch_train[seq_index])\n",
    "    # else we don't use the sample\n",
    "        \n",
    "print(f\"Number of sequences (short, medium, long) after pruning: {len(short_sequences_duration), len(medium_sequences_duration), len(long_sequences_duration)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/int_short_seqs_pitch.pickle', 'wb') as f:\n",
    "    pickle.dump(short_sequences_pitch, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode the samples we are keeping\n",
    "\n",
    "# short sequences\n",
    "one_hot_short_seqs_pitch = []\n",
    "one_hot_short_seqs_duration = []\n",
    "for seq in short_sequences_pitch:\n",
    "    encoded_seq = []\n",
    "    for p in seq:\n",
    "        vec = np.zeros(num_pitches)\n",
    "        if p != -1:  # is a rest, all 0 vector will indicate this\n",
    "            vec[pitch_indices[p]] = 1.0\n",
    "        encoded_seq.append(vec)\n",
    "    one_hot_short_seqs_pitch.append(encoded_seq)\n",
    "    \n",
    "for seq in short_sequences_duration:\n",
    "    encoded_seq = []\n",
    "    for d in seq:\n",
    "        vec = np.zeros(num_durations)\n",
    "        vec[duration_indices[d]] = 1.0\n",
    "        encoded_seq.append(vec)\n",
    "    one_hot_short_seqs_duration.append(encoded_seq)\n",
    "    \n",
    "\n",
    "# medium sequences\n",
    "one_hot_medium_seqs_pitch = []\n",
    "one_hot_medium_seqs_duration = []\n",
    "for seq in medium_sequences_pitch:\n",
    "    encoded_seq = []\n",
    "    for p in seq:\n",
    "        vec = np.zeros(num_pitches)\n",
    "        if p != -1:  # is a rest, all 0 vector will indicate this\n",
    "            vec[pitch_indices[p]] = 1.0\n",
    "        encoded_seq.append(vec)\n",
    "    one_hot_medium_seqs_pitch.append(encoded_seq)\n",
    "    \n",
    "for seq in medium_sequences_duration:\n",
    "    encoded_seq = []\n",
    "    for d in seq:\n",
    "        vec = np.zeros(num_durations)\n",
    "        vec[duration_indices[d]] = 1.0\n",
    "        encoded_seq.append(vec)\n",
    "    one_hot_medium_seqs_duration.append(encoded_seq)\n",
    "    \n",
    "# long sequences\n",
    "one_hot_long_seqs_pitch = []\n",
    "one_hot_long_seqs_duration = []\n",
    "for seq in long_sequences_pitch:\n",
    "    encoded_seq = []\n",
    "    for p in seq:\n",
    "        vec = np.zeros(num_pitches)\n",
    "        if p != -1:  # is a rest, all 0 vector will indicate this\n",
    "            vec[pitch_indices[p]] = 1.0\n",
    "        encoded_seq.append(vec)\n",
    "    one_hot_long_seqs_pitch.append(encoded_seq)\n",
    "    \n",
    "for seq in long_sequences_duration:\n",
    "    encoded_seq = []\n",
    "    for d in seq:\n",
    "        vec = np.zeros(num_durations)\n",
    "        vec[duration_indices[d]] = 1.0\n",
    "        encoded_seq.append(vec)\n",
    "    one_hot_long_seqs_duration.append(encoded_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pad sequences\n",
    "short_sequences_duration = pad_sequences(one_hot_short_seqs_duration, padding=\"post\", dtype='float32')\n",
    "short_sequences_pitch = pad_sequences(one_hot_short_seqs_pitch, padding=\"post\", dtype='float32')\n",
    "medium_sequences_duration = pad_sequences(one_hot_medium_seqs_duration, padding=\"post\", dtype='float32')\n",
    "medium_sequences_pitch = pad_sequences(one_hot_medium_seqs_pitch, padding=\"post\", dtype='float32')\n",
    "long_sequences_duration = pad_sequences(one_hot_long_seqs_duration, padding=\"post\", dtype='float32')\n",
    "long_sequences_pitch = pad_sequences(one_hot_long_seqs_pitch, padding=\"post\", dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1668, 98, 8) (1668, 49, 51)\n",
      "(972, 118, 8) (972, 59, 51)\n",
      "(612, 138, 8) (612, 69, 51)\n"
     ]
    }
   ],
   "source": [
    "print(short_sequences_duration.shape, short_sequences_pitch.shape)\n",
    "print(medium_sequences_duration.shape, medium_sequences_pitch.shape)\n",
    "print(long_sequences_duration.shape, long_sequences_pitch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize training data and labels for use in another script\n",
    "with open('pickles/short_seqs_duration.pickle', 'wb') as f:\n",
    "    pickle.dump(short_sequences_duration, f)\n",
    "    \n",
    "with open('pickles/short_seqs_pitch.pickle', 'wb') as f:\n",
    "    pickle.dump(short_sequences_pitch, f)\n",
    "    \n",
    "with open('pickles/medium_seqs_duration.pickle', 'wb') as f:\n",
    "    pickle.dump(medium_sequences_duration, f)\n",
    "    \n",
    "with open('pickles/medium_seqs_pitch.pickle', 'wb') as f:\n",
    "    pickle.dump(medium_sequences_pitch, f)\n",
    "    \n",
    "with open('pickles/long_seqs_duration.pickle', 'wb') as f:\n",
    "    pickle.dump(long_sequences_duration, f)\n",
    "    \n",
    "with open('pickles/long_seqs_pitch.pickle', 'wb') as f:\n",
    "    pickle.dump(long_sequences_pitch, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the relevant pitches/durations so we can get the respective values from the prediction output vectors\n",
    "with open('pickles/pitches.pickle', 'wb') as f:\n",
    "    pickle.dump(pitches, f)\n",
    "\n",
    "with open('pickles/durations.pickle', 'wb') as f:\n",
    "    pickle.dump(durations, f)\n",
    "    \n",
    "# serialize the mapping from pitch/duration to one hot indices\n",
    "with open('pickles/pitch_indices.pickle', 'wb') as f:\n",
    "    pickle.dump(pitch_indices, f)\n",
    "    \n",
    "with open('pickles/duration_indices.pickle', 'wb') as f:\n",
    "    pickle.dump(duration_indices, f)\n",
    "    \n",
    "with open('pickles/starting_pitch_likelihood.pickle', 'wb') as f:\n",
    "    pickle.dump(starting_pitch_likelihood, f)\n",
    "    \n",
    "with open('pickles/starting_duration_likelihood.pickle', 'wb') as f:\n",
    "    pickle.dump(starting_duration_likelihood, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eqoqHneHP97F"
   },
   "outputs": [],
   "source": [
    "RUNNING_IN_COLAB = False\n",
    "\n",
    "if RUNNING_IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k8Y_Z-dgB50P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# tensorflow/keras imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Bidirectional, Lambda, Embedding\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Python libraries\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "# miscellaneous imports (visualization, plotting, music21, etc)\n",
    "import numpy as np\n",
    "import seaborn as sb  # Heatmaps\n",
    "import matplotlib.pyplot as plt\n",
    "import util_plotting  # for plotting loss over time\n",
    "from tqdm import tqdm  # for a progress bar\n",
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3OiZAScEDQWe"
   },
   "outputs": [],
   "source": [
    "MODELS_DIRECTORY = '../models'\n",
    "PICKLES_DIRECTORY = 'pickles'\n",
    "COMPOSITIONS_DIRECTORY = '../outputs/compositions'\n",
    "TENSORBOARD_LOGS_DIRECTORY = '../tensorboard_logs'\n",
    "\n",
    "if RUNNING_IN_COLAB:  # access the shared drive instead\n",
    "    MODELS_DIRECTORY = '/content/drive/Shared drives/melodyAI/outputs/models'\n",
    "    PICKLES_DIRECTORY = '/content/drive/Shared drives/melodyAI/pickles'\n",
    "    COMPOSITIONS_DIRECTORY = '/content/drive/Shared drives/melodyAI/outputs/compositions'\n",
    "    TENSORBOARD_LOGS_DIRECTORY = '/content/drive/Shared drives/melodyAI/tensorboard_logs'\n",
    "\n",
    "\n",
    "if not os.path.exists(MODELS_DIRECTORY):\n",
    "    os.makedirs(MODELS_DIRECTORY)\n",
    "if not os.path.exists(PICKLES_DIRECTORY):\n",
    "    os.makedirs(PICKLES_DIRECTORY)\n",
    "if not os.path.exists(COMPOSITIONS_DIRECTORY):\n",
    "    os.makedirs(COMPOSITIONS_DIRECTORY)\n",
    "if not os.path.exists(TENSORBOARD_LOGS_DIRECTORY):\n",
    "    os.makedirs(TENSORBOARD_LOGS_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aiFxk9TKCb_O"
   },
   "outputs": [],
   "source": [
    "assert os.path.exists(MODELS_DIRECTORY)\n",
    "assert os.path.exists(PICKLES_DIRECTORY)\n",
    "assert os.path.exists(COMPOSITIONS_DIRECTORY)\n",
    "assert os.path.exists(TENSORBOARD_LOGS_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6wjash0PB50T"
   },
   "source": [
    "# Retrieving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thD8OStZB50U"
   },
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "with open(f\"{PICKLES_DIRECTORY}/short_seqs_duration.pickle\", 'rb') as short_duration,\\\n",
    "     open(f\"{PICKLES_DIRECTORY}/short_seqs_pitch.pickle\", 'rb') as short_pitch:\n",
    "    short_seqs_duration = pickle.load(short_duration)\n",
    "    short_seqs_pitch = pickle.load(short_pitch)\n",
    "\n",
    "with open(f\"{PICKLES_DIRECTORY}/medium_seqs_duration.pickle\", 'rb') as medium_duration,\\\n",
    "     open(f\"{PICKLES_DIRECTORY}/medium_seqs_pitch.pickle\", 'rb') as medium_pitch:\n",
    "    medium_seqs_duration = pickle.load(medium_duration)\n",
    "    medium_seqs_pitch = pickle.load(medium_pitch)\n",
    "    \n",
    "with open(f\"{PICKLES_DIRECTORY}/long_seqs_duration.pickle\", 'rb') as long_duration,\\\n",
    "     open(f\"{PICKLES_DIRECTORY}/long_seqs_pitch.pickle\", 'rb') as long_pitch:\n",
    "    long_seqs_duration = pickle.load(long_duration)\n",
    "    long_seqs_pitch = pickle.load(long_pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0TTdX7yGB50l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 51 unique pitches in the dataset\n",
      "There are 8 unique duration values in the dataset\n"
     ]
    }
   ],
   "source": [
    "# retrieve the pitches and durations that were used to build the data set\n",
    "with open(f'{PICKLES_DIRECTORY}/duration_vocab.pickle', 'rb') as d, open(f'{PICKLES_DIRECTORY}/pitch_vocab.pickle', 'rb') as p:\n",
    "    duration_vocab = sorted(pickle.load(d))\n",
    "    pitch_vocab = sorted(pickle.load(p))\n",
    "    \n",
    "# retrieve the likelihood of starting with a given pitch/duration\n",
    "# these are used in sampling to find the starting pitch/duration of each composition\n",
    "with open(f'{PICKLES_DIRECTORY}/starting_pitch_likelihood.pickle', 'rb') as p, open(f'{PICKLES_DIRECTORY}/starting_duration_likelihood.pickle', 'rb') as d:\n",
    "    starting_pitch_likelihood = pickle.load(p)\n",
    "    starting_duration_likelihood = pickle.load(d)\n",
    "    \n",
    "duration_vocab_size = len(duration_vocab)\n",
    "pitch_vocab_size = len(pitch_vocab)\n",
    "pitch_vocab = sorted(pitch_vocab)\n",
    "print(f\"There are {pitch_vocab_size} unique pitches in the dataset\")\n",
    "duration_vocab = sorted(duration_vocab)\n",
    "print(f\"There are {duration_vocab_size} unique duration values in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_qrT5pl1B50o"
   },
   "source": [
    "# Experimenting with how temperature affects a softmax distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kt2Xjc7rB50o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW: [0.0320586  0.08714432 0.23688282 0.64391426]\n",
      "TEMP 0.0: [5.14820022e-131 1.38389653e-087 3.72007598e-044 1.00000000e+000]\n",
      "TEMP 0.2: [3.03841168e-07 4.50940275e-05 6.69254708e-03 9.93262055e-01]\n",
      "TEMP 0.4: [5.07707490e-04 6.18514343e-03 7.53504725e-02 9.17956677e-01]\n",
      "TEMP 0.6: [0.00547228 0.02897292 0.15339683 0.81215798]\n",
      "TEMP 0.8: [0.01689363 0.05896455 0.20580651 0.71833531]\n",
      "TEMP 1.0: [0.0320586  0.08714432 0.23688282 0.64391426]\n",
      "TEMP 1.5: [0.07076911 0.13783941 0.26847452 0.52291696]\n",
      "TEMP 150: [0.24750558 0.24916113 0.25082776 0.25250553]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Simply performs the softmax operation on an input vector.\n",
    "    \n",
    "    Parameters:\n",
    "        x: a vector of logits.\n",
    "        \n",
    "    Returns: \n",
    "        np.array: array representing the softmax distribution of the input logits.\n",
    "    \"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "logits = np.array([1,2,3,4])\n",
    "logits_temp_p0 = logits / 0.01\n",
    "logits_temp_p2 = logits / 0.2\n",
    "logits_temp_p4 = logits / 0.4\n",
    "logits_temp_p6 = logits / 0.6\n",
    "logits_temp_p8 = logits / 0.8\n",
    "logits_temp_p10 = logits / 1.0\n",
    "logits_temp_p15 = logits / 1.5\n",
    "logits_temp_p150 = logits / 150\n",
    "\n",
    "print(f\"RAW: {softmax(logits)}\")\n",
    "print(f\"TEMP 0.0: {softmax(logits_temp_p0)}\")\n",
    "print(f\"TEMP 0.2: {softmax(logits_temp_p2)}\")\n",
    "print(f\"TEMP 0.4: {softmax(logits_temp_p4)}\")\n",
    "print(f\"TEMP 0.6: {softmax(logits_temp_p6)}\")\n",
    "print(f\"TEMP 0.8: {softmax(logits_temp_p8)}\")\n",
    "print(f\"TEMP 1.0: {softmax(logits_temp_p10)}\")\n",
    "print(f\"TEMP 1.5: {softmax(logits_temp_p15)}\")\n",
    "print(f\"TEMP 150: {softmax(logits_temp_p150)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3QGHJt8vB50y"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-fVTzMStB50y"
   },
   "source": [
    "### Helper functions and data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mrxg1G8RB50z"
   },
   "outputs": [],
   "source": [
    "# Map from MIDI pitch => unique index.\n",
    "# E.g., index of MIDI pitch `69` can be retrieved by evaluating `midi2index[69]` \n",
    "# A rest `-1` would be evaluated by `char2index[-1]`.\n",
    "midi2index = {u:i for i, u in enumerate(pitch_vocab)}\n",
    "\n",
    "# Map from unique index => MIDI pitch; inverse mapping of midi2index\n",
    "index2midi = np.array(pitch_vocab)\n",
    "\n",
    "# Map from duration value => unique index.\n",
    "# E.g., index of duration `1.5` can be retrieved by evaluating `duration2index[1.5]` \n",
    "duration2index = {u:i for i, u in enumerate(duration_vocab)}\n",
    "\n",
    "# Map from unique index => duration value; inverse mapping of midi2index\n",
    "index2duration = np.array(duration_vocab)\n",
    "\n",
    "def timestep_to3d(x):\n",
    "    \"\"\"\n",
    "    Takes a 1D vector (a vector representing a single timestep) and converts it to a 3D vector (which is required by an LSTM network).\n",
    "    \n",
    "    Parameters:\n",
    "        x: a 1D vector which is the one-hot encoding of a value at a single timestep.\n",
    "        \n",
    "    Returns: \n",
    "        np.array: a 3D vector corresponding to a one-hot encoding of a single timestep.\n",
    "    \"\"\"\n",
    "    return np.reshape(x, (1, 1, x.shape[0]))\n",
    "\n",
    "def vectorize_seqs(seqs, feature):\n",
    "    \"\"\"\n",
    "    Mass conversion of MIDI pitches or duration values to their corresponding one\n",
    "    \"\"\"\n",
    "    vectorized_pieces = []\n",
    "    for seq in seqs:\n",
    "        vectorized_seqs = []\n",
    "        if feature == \"pitch\":\n",
    "            for p in seq:\n",
    "                vectorized_seqs.append(midi2index[p])\n",
    "        elif feature == \"duration\":\n",
    "            for d in seq:\n",
    "                vectorized_seqs.append(duration2index[d])\n",
    "        else:\n",
    "            raise ValueError(f\"\\\"{feature}\\\" is not a valid feature name.\")\n",
    "        vectorized_pieces.append(vectorized_seqs)\n",
    "        \n",
    "    return np.array(vectorized_pieces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize all of the data sets\n",
    "vec_short_seqs_duration = vectorize_seqs(short_seqs_duration, \"duration\")\n",
    "vec_short_seqs_pitch = vectorize_seqs(short_seqs_pitch, \"pitch\")\n",
    "vec_medium_seqs_duration = vectorize_seqs(medium_seqs_duration, \"duration\")\n",
    "vec_medium_seqs_pitch = vectorize_seqs(medium_seqs_pitch, \"pitch\")\n",
    "vec_long_seqs_duration = vectorize_seqs(long_seqs_duration, \"duration\")\n",
    "vec_long_seqs_pitch = vectorize_seqs(long_seqs_pitch, \"pitch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad the sequences with trailing 0's to make them all the same length\n",
    "padded_short_duration = pad_sequences(vec_short_seqs_duration, padding=\"post\", dtype='int32')\n",
    "padded_short_pitch = pad_sequences(vec_short_seqs_pitch, padding=\"post\", dtype='int32')\n",
    "padded_medium_duration = pad_sequences(vec_medium_seqs_duration, padding=\"post\", dtype='int32')\n",
    "padded_medium_pitch = pad_sequences(vec_medium_seqs_pitch, padding=\"post\", dtype='int32')\n",
    "padded_long_duration = pad_sequences(vec_long_seqs_duration, padding=\"post\", dtype='int32')\n",
    "padded_long_pitch = pad_sequences(vec_long_seqs_pitch, padding=\"post\", dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check (pitch/duration seqs should have same # of time steps for short/medium/long seqs)\n",
    "assert padded_short_duration.shape[1] == padded_short_pitch.shape[1]\n",
    "assert padded_medium_duration.shape[1] == padded_medium_pitch.shape[1]\n",
    "assert padded_long_duration.shape[1] == padded_long_pitch.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All short sequences now encompass 49 time steps.\n",
      "All medium sequences now encompass 59 time steps.\n",
      "All long sequences now encompass 69 time steps.\n"
     ]
    }
   ],
   "source": [
    "print(f'All short sequences now encompass {padded_short_duration.shape[1]} time steps.')\n",
    "print(f'All medium sequences now encompass {padded_medium_duration.shape[1]} time steps.')\n",
    "print(f'All long sequences now encompass {padded_long_duration.shape[1]} time steps.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(seqs, batch_size, bidirectional=True):\n",
    "    \"\"\"\n",
    "    Batch definition to return training examples X and targets Y\n",
    "    \n",
    "    Parameters:\n",
    "        seqs (np.array): 2D array of shape (num_seqs, seq_length) for which to choose batch samples.\n",
    "        num_sequences (int): How many sequences (pieces) we want to return for a single training batch.\n",
    "        bidirectional (boolean): Whether the batches are used in a bidirectional LSTM.    \n",
    "    Returns:\n",
    "        x_batch (np.array): Input sequence for training.\n",
    "        y_batch (np.array): Output (label) sequence for training.\n",
    "    \"\"\"\n",
    "    \n",
    "    # the length of the vectorized melodies (number of pieces to choose from) \n",
    "    n = seqs.shape[0] - 1\n",
    "    # randomly choose the pieces for this training batch\n",
    "    seq_choice = np.random.choice(n, batch_size)\n",
    "\n",
    "    # x_batch, y_batch provide the true inputs and targets for network training\n",
    "    if bidirectional:\n",
    "        # need all time steps for x and y, since network flows in both directions\n",
    "        x_batch = np.array([seqs[seq] for seq in seq_choice])\n",
    "        y_batch = deepcopy(x_batch)\n",
    "    else:\n",
    "        # don't need the final time step for x because the final time step should be predicted\n",
    "        x_batch = np.array([seqs[mel][0:-1] for seq in seq_choice])\n",
    "        # don't need the first time step for y because we don't predict the starting time step\n",
    "        y_batch = np.array([seqs[mel][1:] for seq in seq_choice])  \n",
    "\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PgYZ8dftB52M"
   },
   "source": [
    "# Composing with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-HrHl_rB52N"
   },
   "outputs": [],
   "source": [
    "def sample_distribution(dist_vec, num_categories):\n",
    "    \"\"\"\n",
    "    Sample a softmax distribution vector.\n",
    "    \n",
    "    Parameters:\n",
    "        dist_vec (np.array): A logit vector from which to take a sample from.\n",
    "        num_categories (int): Number of categories to sample from (used for reshaping).\n",
    "        \n",
    "    Returns:\n",
    "        int: The index of the output value which was sampled.\n",
    "    \"\"\"\n",
    "    return tf.random.categorical(dist_vec.reshape(1, num_categories), 1).numpy().flatten()[0]\n",
    "\n",
    "def compose(pitch_model, duration_model, pitch_prompt, duration_prompt, length=50):\n",
    "    '''\n",
    "    Composes a piece of music (in the format of a music21.stream.Stream object).\n",
    "    \n",
    "    Arguments:\n",
    "        pitch_model (tf.keras.Model): The trained model for pitch predictions.\n",
    "        duration_model (tf.keras.Model): The trained model for duration predictions.\n",
    "        pitch_prompt (int): The first pitch of the piece (index of the one-hot encoded pitch vector).\n",
    "        duration_prompt (int): The first duration of the piece (index of the one-hot encoded duration vector).\n",
    "        length (int): How many time steps to generate.\n",
    "       \n",
    "       Returns:\n",
    "           music21.stream.Stream(): The composed piece.\n",
    "    '''    \n",
    "    \n",
    "    # the lists that hold the indices of the values to index in to pitches/durations lists\n",
    "    generated_pitches, generated_durations = [pitch_prompt], [duration_prompt]\n",
    "    \n",
    "    current_pitch, current_duration = pitch_prompt, duration_prompt\n",
    "    for t in range(length):\n",
    "        # model only accepts 3D inputs\n",
    "        pitch_vec = timestep_to3d(vectorize_pitch(current_pitch))\n",
    "        duration_vec = timestep_to3d(vectorize_duration(current_duration))\n",
    "        \n",
    "        # predict the output distributions\n",
    "        pitch_pred = pitch_model.predict(pitch_vec)\n",
    "        duration_pred = duration_model.predict(duration_vec)\n",
    "        # sample the distributions (returns the index of the one-hot vectors)\n",
    "        next_pitch = sample_distribution(pitch_pred, pitch_vocab_size)\n",
    "        next_duration = sample_distribution(duration_pred, duration_vocab_size)\n",
    "        generated_pitches.append(next_pitch)\n",
    "        generated_durations.append(next_duration)\n",
    "        \n",
    "        # get ready for next iteration\n",
    "        current_pitch, current_duration = next_pitch, next_duration\n",
    "        \n",
    "    \n",
    "    composed_stream = stream.Stream()\n",
    "    for pair in list(zip(generated_pitches, generated_durations)):\n",
    "        p = pitch.Pitch(midi=pitches[pair[0]])\n",
    "        d = duration.Duration(durations[pair[1]])\n",
    "        n = note.Note()\n",
    "        n.pitch = p\n",
    "        n.duration = d\n",
    "        composed_stream.append(n)\n",
    "    \n",
    "    return composed_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TRyzfq-qB53t"
   },
   "source": [
    "# Generation infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdYQcfwCB53u",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bidirectional_vals = [True, False]\n",
    "lstm_cell_vals = [500, 1000, 2000]\n",
    "temperature_vals = [0.2, 0.5, 1.0, 10.0]\n",
    "\n",
    "def generate_param_sets(start=None, end=None):\n",
    "    \"\"\"\n",
    "    Creates sets of possible parameter combinations that will be tested over.\n",
    "    Optionally allows to pass in indices to return a sub set of param sets in case training in to be done at separate times.\n",
    "    \n",
    "    Parameters:\n",
    "        start (integer): The starting index of the range of sets to return from all possible sets.\n",
    "        end (int): The ending index (inclusive) of the renage of sets to return from all possible sets.\n",
    "        *NOTE that start and end must either both be None or integers; only suppling one argument causes an exception to be raised.\n",
    "    \"\"\"\n",
    "    sets = []\n",
    "    for bidirectional in bidirectional_vals:\n",
    "        for lstm_cells in lstm_cell_vals:\n",
    "            for temperature in temperature_vals:\n",
    "                s = {\n",
    "                    \"bidirectional\": bidirectional,\n",
    "                    \"lstm_cells\": lstm_cells,\n",
    "                    \"temperature\": temperature,\n",
    "                }\n",
    "                sets.append(s)\n",
    "                    \n",
    "    if start is None:\n",
    "      start = 0\n",
    "    if end is None or end > len(sets):\n",
    "      end = len(sets) - 1  # subtract 1 because of the +1 in the end slice\n",
    "\n",
    "    return sets[start:end+1]  # +1 to make the index passed in inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K8FixbskB53x"
   },
   "outputs": [],
   "source": [
    "def add_training_durations_string(dur1, dur2):\n",
    "    \"\"\"\n",
    "    Adds the training duration of two models and returns them in a string format.\n",
    "    \n",
    "    dur1/dur2 (float): floating point representation of training time in seconds\n",
    "    \"\"\"\n",
    "    \n",
    "    total_time = dur1 + dur2\n",
    "    hours = int(total_time // 3600)  # 3600 seconds/hour\n",
    "    minutes = int((total_time - (3600 * hours)) // 60) # subtract the hours from remaining time; 60 sec/min\n",
    "    seconds = (total_time - (3600 * hours)) - (60 * minutes)\n",
    "    return \"{}h {}m {:.2f}s\".format(hours, minutes, seconds)\n",
    "\n",
    "class MetadataModel:\n",
    "    \"\"\"\n",
    "    A wrapper class for LSTM models that is used to gather metadata from training.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, batch_size, lstm_cells, bidirectional, temperature, verbose=0, id=None):\n",
    "        self._vocab_size = vocab_size\n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._batch_size = batch_size\n",
    "        self._lstm_cells = lstm_cells\n",
    "        self._bidirectional = bidirectional\n",
    "        self._temperature = temperature\n",
    "        self.verbose = verbose # no underscore because this should be mutable\n",
    "        self._name = '_'.join([\"bidir\" if bidirectional else \"unidir\", str(lstm_cells), str(temperature)])\n",
    "        if id is not None:\n",
    "            self.name += f\"_{id}\"\n",
    "        self._total_training_time = 0.0 # in seconds; will be updated after training, obviously\n",
    "        self._model = self._get_model()\n",
    "        \n",
    "    \n",
    "    # ---- setting properties so that these attributes are immutable ----\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    \n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "        \n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return self._vocab_size\n",
    "    \n",
    "    @property\n",
    "    def embedding_dim(self):\n",
    "        return self._embedding_dim\n",
    "    \n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self._batch_size\n",
    "    \n",
    "    @property\n",
    "    def lstm_cells(self):\n",
    "        return self._lstm_cells\n",
    "    \n",
    "    @property\n",
    "    def bidirectional(self):\n",
    "        return self._bidirectional\n",
    "    \n",
    "    @property\n",
    "    def temperature(self):\n",
    "        return self._temperature\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def total_training_time(self):\n",
    "        return self._total_training_time\n",
    "    \n",
    "    \n",
    "    # single layer Unidirectional or Bidirectional LSTM; will easily allow us to test various configurations\n",
    "    def _get_model(self, optimizer=\"adam\"):\n",
    "        \"\"\"\n",
    "        Creates and compiles the LSTM model.\n",
    "    \n",
    "        Parameters:\n",
    "            embedding_dim (int): How many different dimensions to encode values over.\n",
    "            lstm_cells (int): The number of LSTM cells in the model.\n",
    "            bidirectional (boolean): Whether to construct a bidirectional LSTM (as opposed to unidirectional).\n",
    "            temperature (float): Value by the Lambda layer to divide output logits by.\n",
    "            optimizer (string | tf.keras.optimizers.Optimizer): Which optimization algorith to use.\n",
    "        \n",
    "        Returns:\n",
    "            tf.keras.Model: A compiled (ready to be trained) LSTM model.\n",
    "        \"\"\"\n",
    "    \n",
    "        model = Sequential()\n",
    "        # NOTE: MIT tutorial used 2d input shape but Keras documentation shoes using 3, so if errors occur, check that out\n",
    "        model.add(Embedding(self.vocab_size, self.embedding_dim, batch_input_shape=[self.batch_size, self.vocab_size]))\n",
    "        # only dif. betwn. bi. LSTM and uni. LSTM is the presence/absence of Bidirectional wrapper\n",
    "        # hidden layer 1; 20  units; input (# timesteps, # features); return a sequence of each time step's outputs\n",
    "        # input_shape first value None makes it variable (we don't have fixed length sequences)\n",
    "        # output of LSTM cell uses tanh activation, recurrent connections use sigmoid\n",
    "        if self.bidirectional:\n",
    "            model.add(Bidirectional(LSTM(self.lstm_cells, input_shape=(None, self.vocab_size), return_sequences=True)))\n",
    "        else:\n",
    "            model.add(LSTM(self.lstm_cells, input_shape=(None, self.vocab_size), return_sequences=True))\n",
    "\n",
    "        # so that we can divibe by temperature before feeding through softmax\n",
    "        model.add(Lambda(lambda x: x / self.temperature))\n",
    "\n",
    "        # TimeDistributed is a wrapper allowing one output per time step; \n",
    "        # ...requires hidden layer to have return_sequences == True\n",
    "        # TODO: Maybe TimeDistributed isn't necessary (MIT didn't use it)\n",
    "        model.add(TimeDistributed(Dense(self.vocab_size, activation='softmax')))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', 'categorical_crossentropy'])\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def _train_model(self, X, bidirectional=True, epochs=5, batch_size=32, verbose=1, model_name='NULL_model_name', model_dataset='unknown_dataset', model_no='NULL_model_no'):\n",
    "        \"\"\"\n",
    "        Trains an LSTM model.\n",
    "\n",
    "        Parameters:\n",
    "            model (tf.keras.Model): The model which is to be trained.\n",
    "            X (np.array): A 3D vector (samples, timesteps, values) to train the network on.\n",
    "            bidirectional (boolean): Indicates whether the model is a bidirectional.\n",
    "            epochs (int): The number of epochs over which to train the model.\n",
    "            batch_size (int): The number of samples tito show the odel before updating weights.\n",
    "            verbose (int): The amount of information to print while training.\n",
    "\n",
    "            Returns: None\n",
    "        \"\"\"\n",
    "        if not os.path.exists(TENSORBOARD_LOGS_DIRECTORY+f'/model_{model_no}'):\n",
    "            os.makedirs(TENSORBOARD_LOGS_DIRECTORY+f'/model_{model_no}')\n",
    "\n",
    "        # Initialize TensorBoard object for logging\\n\",\n",
    "        tensorboard = TensorBoard(log_dir=f'{TENSORBOARD_LOGS_DIRECTORY}/model_{model_no}/{model_name}-{model_dataset}')\n",
    "\n",
    "        Y = deepcopy(X)\n",
    "        if not bidirectional:\n",
    "            X = X[0:-1] # do not input the final time step in unidirectional LSTM\n",
    "            Y = Y[1:] # labels include all time steps but the first one in unidir. LSTM\n",
    "        self.model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=verbose, callbacks=[tensorboard])\n",
    "    \n",
    "    \n",
    "    # returns a string version of training time\n",
    "    @property\n",
    "    def training_duration_string(self):\n",
    "        total_time = self._total_training_time\n",
    "        hours = int(total_time // 3600)  # 3600 seconds/hour\n",
    "        minutes = int((total_time - (3600 * hours)) // 60) # subtract the hours from remaining time; 60 sec/min\n",
    "        seconds = (total_time - (3600 * hours)) - (60 * minutes)\n",
    "        return \"{}h {}m {:.2f}s\".format(hours, minutes, seconds)\n",
    "            \n",
    "    def train(self, X, dataset_name, model_no):\n",
    "        start_time = time.time()\n",
    "        self._train_model(self.model, X, self.bidirectional, self.verbose, model_name=self.name, model_dataset=dataset_name, model_no=model_no)\n",
    "        end_time = time.time()\n",
    "        self._total_training_time += end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w-ikO1pxB53-"
   },
   "outputs": [],
   "source": [
    "def sample_start_pitch():\n",
    "    \"\"\"\n",
    "    Sample from the dictionary containing the probabilities of starting a piece with a given pitch.\n",
    "    \n",
    "    Parameters:\n",
    "        dictionary (dict(int: float)): The dictionary whose values are probabilities, and whose keys are the MIDI pitch.\n",
    "                                       This dictionary must be sorted by key.\n",
    "        \n",
    "    Returns:\n",
    "        int: The index of the MIDI pitch in the pitches list.\n",
    "    \"\"\"\n",
    "    logits = np.array(list(starting_pitch_likelihood.values()))\n",
    "    return np.argmax(np.random.multinomial(1, logits))\n",
    "    \n",
    "def sample_start_duration():\n",
    "    \"\"\"\n",
    "    Sample from the dictionary containing the probabilities of starting a piece with a given duration.\n",
    "    \n",
    "    Parameters:\n",
    "        dictionary (dict(float: float)): The dictionary whose values are probabilities, and whose keys are the quarter length duration.\n",
    "                                         This dictionary must be sorted by key.\n",
    "        \n",
    "    Returns:\n",
    "        np.array: The index of the sampled duration in the durations list.\n",
    "    \"\"\"\n",
    "    logits = np.array(list(starting_duration_likelihood.values()))\n",
    "    return np.argmax(np.random.multinomial(1, logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UT0PniOzB54E"
   },
   "outputs": [],
   "source": [
    "def run_tests(param_set_start=None, param_set_end=None,\\\n",
    "              num_compositions=5, verbose=0):\n",
    "    \"\"\"\n",
    "    Creates, trains, and composes with networks of a multitude of parameter combinations.\n",
    "    \n",
    "    Parameters:\n",
    "        param_set_start (int): The first of the generated param. sets to be tested on.\n",
    "        param_set_end (int): The last of the generated param. sets to be tested on.\n",
    "        num_compositions (int): How many pieces to compose for each model being tested.\n",
    "        verbose (int): The amount of information to print throughout the test.\n",
    "        \n",
    "        Returns: None\n",
    "    \"\"\"\n",
    "    \n",
    "    param_sets = generate_param_sets(param_set_start, param_set_end)\n",
    "    pitch_models, duration_models = [], []\n",
    "    model_no = 0 # which iteration of model we are on\n",
    "    if param_set_start is not None:\n",
    "        model_no = param_set_start\n",
    "            \n",
    "    test_start_time=time.time()            \n",
    "    for params in param_sets:\n",
    "        bidirectional = params[\"bidirectional\"]\n",
    "        lstm_cells = params[\"lstm_cells\"]\n",
    "        temperature = params[\"temperature\"]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Model {model_no}:\\n\\tbidirectional – {bidirectional}\\n\\tlstm cells – {lstm_cells}\\\n",
    "            \\n\\ttemperature – {temperature}\")\n",
    "        \n",
    "        # TODO: determine embedding dimensions to test\n",
    "        embedding_dim = 32\n",
    "        # TODO: determine batch_sizes to test\n",
    "        batch_size=16\n",
    "        #TODO: try different parameter sets for the duration/pitch networks, since they are really learning\n",
    "        #      very different things\n",
    "        pitch_model = MetadataModel(pitch_vocab_size, embedding_dim, batch_size, lstm_cells, bidirectional, temperature, verbose=verbose)\n",
    "        duration_model = MetadataModel(duration_vocab_size, embedding_dim, batch_size, lstm_cells, bidirectional, temperature, verbose=verbose)\n",
    "        \n",
    "        # train the pitch network\n",
    "        if verbose:\n",
    "            print('\\n\\tTraining pitch generation network...')\n",
    "            print('\\t\\tOn short data set:')\n",
    "        pitch_model.train(short_seqs_pitch, 'pitch_short', model_no)\n",
    "        if verbose:\n",
    "            print('\\t\\tOn medium data set:')\n",
    "        pitch_model.train(medium_seqs_pitch, 'pitch_medium', model_no)\n",
    "        if verbose:\n",
    "            print('\\t\\tOn long data set:')\n",
    "        pitch_model.train(long_seqs_pitch, 'pitch_long', model_no)\n",
    "        pitch_model.model.save(f\"{MODELS_DIRECTORY}/{model_no}_pitch_{pitch_model.name}.h5\")\n",
    "        if verbose:\n",
    "            print(f\"\\t\\tPitch model training complete: saved at {MODELS_DIRECTORY}/{model_no}_pitch_{pitch_model.name}.h5\")\n",
    "            print(f\"\\t\\tTotal training time: {pitch_model.training_duration_string}'\")\n",
    "        \n",
    "        # train the duration network\n",
    "        if verbose:\n",
    "            print('\\n\\tTraining rhythm (duration) generation network...')\n",
    "            print('\\t\\tOn short data set:')\n",
    "        duration_model.train(short_seqs_duration, 'duration_short', model_no)\n",
    "        if verbose:\n",
    "            print('\\t\\tOn medium data set:')\n",
    "        duration_model.train(medium_seqs_duration, 'duration_medium', model_no)\n",
    "        if verbose:\n",
    "            print('\\t\\tOn long data set:')\n",
    "        duration_model.train(long_seqs_duration, 'duration_long', model_no)\n",
    "        duration_model.model.save(f\"{MODELS_DIRECTORY}/{model_no}_duration_{duration_model.name}.h5\")\n",
    "        if verbose:\n",
    "            print(f\"\\t\\tDuration model training complete: saved at {MODELS_DIRECTORY}/{model_no}_duration_{duration_model.name}.h5\")\n",
    "            print(f\"\\t\\tTotal training time: {duration_model.training_duration_string}\")\n",
    "        if verbose:\n",
    "            print(f'\\n\\tModel {model_no} training complete')\n",
    "            print(f'\\tTotal time to train pitch and duration models: {add_training_durations_string(duration_model.total_training_time, pitch_model.total_training_time)}')\n",
    "        \n",
    "        # compose outputs and save them\n",
    "        if not os.path.exists(f\"{COMPOSITIONS_DIRECTORY}/model_{model_no}\"):\n",
    "            os.makedirs(f\"{COMPOSITIONS_DIRECTORY}/model_{model_no}\")\n",
    "        comp_count = 1\n",
    "        for c in range(num_compositions):\n",
    "            pitch_prompt = sample_start_pitch()\n",
    "            duration_prompt = sample_start_duration()\n",
    "            composition = compose(pitch_model.model, duration_model.model, pitch_prompt, duration_prompt, length=100)\n",
    "            composition.write('musicxml', f'{COMPOSITIONS_DIRECTORY}/model_{model_no}/composition_{comp_count}.mxl')\n",
    "            composition.write('midi', f'{COMPOSITIONS_DIRECTORY}/model_{model_no}/composition_{comp_count}.mid')\n",
    "            comp_count += 1\n",
    "        print(f\"\\t\\tCompositions successfully written to {COMPOSITIONS_DIRECTORY}/model_{model_no}\")\n",
    "            \n",
    "        model_no = model_no + 1\n",
    "        print('–' * 50 + \"\\n\\n\")\n",
    "        \n",
    "        \n",
    "    test_end_time=time.time()\n",
    "    total_time = test_end_time - test_start_time\n",
    "    hours = int(total_time // 3600)  # 3600 seconds/hour\n",
    "    minutes = int((total_time - (3600 * hours)) // 60) # subtract the hours from remaining time; 60 sec/min\n",
    "    seconds = (total_time - (3600 * hours)) - (60 * minutes)\n",
    "    print(\"TRAINING COMPLETE – elapsed time: {}h {}m {:.2f}s\".format(hours, minutes, seconds))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kVVnQFOsB54J",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0:\n",
      "\tbidirectional – True\n",
      "\tlstm cells – 500            \n",
      "\ttemperature – 0.2\n",
      "\n",
      "\tTraining pitch generation network...\n",
      "\t\tOn short data set:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't pickle _thread._local objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-6be6d843206f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-22f1d797fea2>\u001b[0m in \u001b[0;36mrun_tests\u001b[0;34m(param_set_start, param_set_end, num_compositions, verbose)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\tTraining pitch generation network...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t\\tOn short data set:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mpitch_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshort_seqs_pitch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pitch_short'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t\\tOn medium data set:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-5f3e55f06164>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, dataset_name, model_no)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_no\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_training_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-5f3e55f06164>\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, X, bidirectional, epochs, batch_size, verbose, model_name, model_dataset, model_no)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mtensorboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{TENSORBOARD_LOGS_DIRECTORY}/model_{model_no}/{model_name}-{model_dataset}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbidirectional\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# do not input the final time step in unidirectional LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    167\u001b[0m                     \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce_ex__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreductor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                         \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreductor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                         \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle _thread._local objects"
     ]
    }
   ],
   "source": [
    "run_tests(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

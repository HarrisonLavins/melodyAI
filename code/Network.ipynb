{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eqoqHneHP97F"
   },
   "outputs": [],
   "source": [
    "RUNNING_IN_COLAB = False\n",
    "\n",
    "if RUNNING_IN_COLAB:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k8Y_Z-dgB50P"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Bidirectional, Lambda\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "from music21 import *\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3OiZAScEDQWe"
   },
   "outputs": [],
   "source": [
    "MODELS_DIRECTORY = '../models'\n",
    "PICKLES_DIRECTORY = 'pickles'\n",
    "COMPOSITIONS_DIRECTORY = '../outputs/compositions'\n",
    "TENSORBOARD_LOGS_DIRECTORY = '../tensorboard_logs'\n",
    "\n",
    "if RUNNING_IN_COLAB:  # access the shared drive instead\n",
    "    MODELS_DIRECTORY = '/content/drive/Shared drives/melodyAI/outputs/models'\n",
    "    PICKLES_DIRECTORY = '/content/drive/Shared drives/melodyAI/pickles'\n",
    "    COMPOSITIONS_DIRECTORY = '/content/drive/Shared drives/melodyAI/outputs/compositions'\n",
    "    TENSORBOARD_LOGS_DIRECTORY = '/content/drive/Shared drives/melodyAI/tensorboard_logs'\n",
    "\n",
    "\n",
    "if not os.path.exists(MODELS_DIRECTORY):\n",
    "    os.makedirs(MODELS_DIRECTORY)\n",
    "if not os.path.exists(PICKLES_DIRECTORY):\n",
    "    os.makedirs(PICKLES_DIRECTORY)\n",
    "if not os.path.exists(COMPOSITIONS_DIRECTORY):\n",
    "    os.makedirs(COMPOSITIONS_DIRECTORY)\n",
    "if not os.path.exists(TENSORBOARD_LOGS_DIRECTORY):\n",
    "    os.makedirs(TENSORBOARD_LOGS_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aiFxk9TKCb_O"
   },
   "outputs": [],
   "source": [
    "assert os.path.exists(MODELS_DIRECTORY)\n",
    "assert os.path.exists(PICKLES_DIRECTORY)\n",
    "assert os.path.exists(COMPOSITIONS_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6wjash0PB50T"
   },
   "source": [
    "# Retrieving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thD8OStZB50U"
   },
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "with open(f\"{PICKLES_DIRECTORY}/short_seqs_duration.pickle\", 'rb') as short_duration,\\\n",
    "     open(f\"{PICKLES_DIRECTORY}/short_seqs_pitch.pickle\", 'rb') as short_pitch:\n",
    "    short_seqs_duration = pickle.load(short_duration)\n",
    "    short_seqs_pitch = pickle.load(short_pitch)\n",
    "\n",
    "with open(f\"{PICKLES_DIRECTORY}/medium_seqs_duration.pickle\", 'rb') as medium_duration,\\\n",
    "     open(f\"{PICKLES_DIRECTORY}/medium_seqs_pitch.pickle\", 'rb') as medium_pitch:\n",
    "    medium_seqs_duration = pickle.load(medium_duration)\n",
    "    medium_seqs_pitch = pickle.load(medium_pitch)\n",
    "    \n",
    "with open(f\"{PICKLES_DIRECTORY}/long_seqs_duration.pickle\", 'rb') as long_duration,\\\n",
    "     open(f\"{PICKLES_DIRECTORY}/long_seqs_pitch.pickle\", 'rb') as long_pitch:\n",
    "    long_seqs_duration = pickle.load(long_duration)\n",
    "    long_seqs_pitch = pickle.load(long_pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0TTdX7yGB50l"
   },
   "outputs": [],
   "source": [
    "# retrieve the pitches and durations that were used to build the data set\n",
    "with open(f'{PICKLES_DIRECTORY}/durations.pickle', 'rb') as d, open(f'{PICKLES_DIRECTORY}/pitches.pickle', 'rb') as p:\n",
    "    durations = sorted(pickle.load(d))\n",
    "    pitches = sorted(pickle.load(p))\n",
    "    \n",
    "# retrieve the mapping from pitch/duration values to one-hot vector indices\n",
    "with open(f'{PICKLES_DIRECTORY}/duration_indices.pickle', 'rb') as d, open(f'{PICKLES_DIRECTORY}/pitch_indices.pickle', 'rb') as p:\n",
    "    duration_indices = pickle.load(d)\n",
    "    pitch_indices = pickle.load(p)\n",
    "    \n",
    "# retrieve the likelihood of starting with a given pitch/duration\n",
    "# these are used in sampling to find the starting pitch/duration of each composition\n",
    "with open(f'{PICKLES_DIRECTORY}/starting_pitch_likelihood.pickle', 'rb') as p, open(f'{PICKLES_DIRECTORY}/starting_duration_likelihood.pickle', 'rb') as d:\n",
    "    starting_pitch_likelihood = pickle.load(p)\n",
    "    starting_duration_likelihood = pickle.load(d)\n",
    "    \n",
    "num_durations = len(durations)\n",
    "num_pitches = len(pitches)\n",
    "short_seq_len = short_seqs_duration.shape[1]\n",
    "medium_seq_len = medium_seqs_duration.shape[1]\n",
    "long_seq_len = long_seqs_duration.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.25: 0,\n",
       " 0.5: 1,\n",
       " 0.75: 2,\n",
       " 1.0: 3,\n",
       " 1.5: 4,\n",
       " 2.0: 5,\n",
       " 3.0: 6,\n",
       " 4.0: 7,\n",
       " 6.0: 8,\n",
       " 8.0: 9}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_qrT5pl1B50o"
   },
   "source": [
    "# Experimenting with how temperature affects a softmax distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kt2Xjc7rB50o"
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Simply performs the softmax operation on an input vector.\n",
    "    \n",
    "    Parameters:\n",
    "        x: a vector of logits.\n",
    "        \n",
    "    Returns: \n",
    "        np.array: array representing the softmax distribution of the input logits.\n",
    "    \"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "logits = np.array([1,2,3,4])\n",
    "logits_temp_p0 = logits / 0.01\n",
    "logits_temp_p2 = logits / 0.2\n",
    "logits_temp_p4 = logits / 0.4\n",
    "logits_temp_p6 = logits / 0.6\n",
    "logits_temp_p8 = logits / 0.8\n",
    "logits_temp_p10 = logits / 1.0\n",
    "logits_temp_p15 = logits / 1.5\n",
    "logits_temp_p150 = logits / 150\n",
    "\n",
    "print(f\"RAW: {softmax(logits)}\")\n",
    "print(f\"TEMP 0.0: {softmax(logits_temp_p0)}\")\n",
    "print(f\"TEMP 0.2: {softmax(logits_temp_p2)}\")\n",
    "print(f\"TEMP 0.4: {softmax(logits_temp_p4)}\")\n",
    "print(f\"TEMP 0.6: {softmax(logits_temp_p6)}\")\n",
    "print(f\"TEMP 0.8: {softmax(logits_temp_p8)}\")\n",
    "print(f\"TEMP 1.0: {softmax(logits_temp_p10)}\")\n",
    "print(f\"TEMP 1.5: {softmax(logits_temp_p15)}\")\n",
    "print(f\"TEMP 150: {softmax(logits_temp_p150)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3QGHJt8vB50y"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-fVTzMStB50y"
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mrxg1G8RB50z"
   },
   "outputs": [],
   "source": [
    "def timestep_to3d(x):\n",
    "    \"\"\"\n",
    "    Takes a 1D vector (a vector representing a single timestep) and converts it to a 3D vector (which is required by an LSTM network).\n",
    "    \n",
    "    Parameters:\n",
    "        x: a 1D vector which is the one-hot encoding of a value at a single timestep.\n",
    "        \n",
    "    Returns: \n",
    "        np.array: a 3D vector corresponding to a one-hot encoding of a single timestep.\n",
    "    \"\"\"\n",
    "    return np.reshape(x, (1, 1, x.shape[0]))\n",
    "\n",
    "\n",
    "def vectorize(index, vec_size):\n",
    "    \"\"\"\n",
    "    Creates a one-hot vector representation for a single time step given the index position of the value to encode.\n",
    "    \n",
    "    Parameters:\n",
    "        index: the index of the returned vector which should be set to 1.\n",
    "        vec_size: how large the returned vector should be (how many possible values for the feature).\n",
    "        \n",
    "    Returns: \n",
    "        np.array: a 1D array which is the resulting one-hot encoding of a value at a single time step.\n",
    "    \"\"\"\n",
    "    index = int(index)\n",
    "    vec = np.zeros(vec_size, np.float32)\n",
    "    vec[index] = 1.0\n",
    "    return vec\n",
    "\n",
    "\n",
    "def unvectorize(x):\n",
    "    \"\"\"\n",
    "    Returns the index of the one-hot encoded value.\n",
    "    This works because only one value will be nonzero in a vector, so argmax will return this index of the encoded value.\n",
    "    \n",
    "    Parameters:\n",
    "        x: a one-hot encoded vector.\n",
    "        \n",
    "    Returns: \n",
    "        integer: an index corresponding to the values which is encoded by the vector.\n",
    "    \"\"\"\n",
    "    return np.argmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i9eMfJT0B511"
   },
   "source": [
    "### Model building and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H3mCUGnUB512"
   },
   "outputs": [],
   "source": [
    "# single layer Unidirectional or Bidirectional LSTM; will easily allow us to test various configurations\n",
    "def get_model(num_values, lstm_cells=500, bidirectional=True, temperature=1.0, optimizer=\"adam\"):\n",
    "    \"\"\"\n",
    "    Creates and compiles the LSTM model.\n",
    "    \n",
    "    Parameters:\n",
    "        num_values (int): The size of the one-hot vector at a time step.\n",
    "        lstm_cells (int): The number of LSTM cells in the model.\n",
    "        bidirectional (boolean): Whether to construct a bidirectional LSTM (as opposed to unidirectional).\n",
    "        temperature (float): Value by the Lambda layer to divide output logits by.\n",
    "        optimizer (string | tf.keras.optimizers.Optimizer): Which optimization algorith to use.\n",
    "        \n",
    "    Returns:\n",
    "        tf.keras.Model: A compiled LSTM model.\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    # only dif. betwn. bi. LSTM and uni. LSTM is the presence/absence of Bidirectional wrapper\n",
    "    # hidden layer 1; 20  units; input (# timesteps, # features); return a sequence of each time step's outputs\n",
    "    # input_shape first value None makes it variable (we don't have fixed length sequences)\n",
    "    # output of LSTM cell uses tanh activation, recurrent connections use sigmoid\n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(LSTM(lstm_cells, input_shape=(None, num_values), return_sequences=True)))\n",
    "    else:\n",
    "        model.add(LSTM(lstm_cells, input_shape=(None, num_values), return_sequences=True))\n",
    "        \n",
    "    # so that we can divibe by temperature before feeding through softmax\n",
    "    model.add(Lambda(lambda x: x / temperature))\n",
    "        \n",
    "    # TimeDistributed is a wrapper allowing one output per time step; \n",
    "    # ...requires hidden layer to have return_sequences == True\n",
    "    model.add(TimeDistributed(Dense(num_values, activation='softmax')))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', 'categorical_crossentropy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oRpQA6NyB52K"
   },
   "outputs": [],
   "source": [
    "def train_model(model, X, bidirectional=True, epochs=5, batch_size=32, verbose=1, model_name='NULL_model_name', model_dataset='unknown_dataset', model_no='NULL_model_no'):\n",
    "    \"\"\"\n",
    "    Trains an LSTM model.\n",
    "    \n",
    "    Parameters:\n",
    "        model (tf.keras.Model): The model which is to be trained.\n",
    "        X (np.array): A 3D vector (samples, timesteps, values) to train the network on.\n",
    "        bidirectional (boolean): Indicates whether the model is a bidirectional.\n",
    "        epochs (int): The number of epochs over which to train the model.\n",
    "        batch_size (int): The number of samples tito show the odel before updating weights.\n",
    "        verbose (int): The amount of information to print while training.\n",
    "        \n",
    "        Returns: None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(TENSORBOARD_LOGS_DIRECTORY+f'/model_{model_no}'):\n",
    "        os.makedirs(TENSORBOARD_LOGS_DIRECTORY+f'/model_{model_no}')\n",
    "    \n",
    "    # Initialize TensorBoard object for logging\\n\",\n",
    "    tensorboard = TensorBoard(log_dir=f'{TENSORBOARD_LOGS_DIRECTORY}/model_{model_no}/{model_name}-{model_dataset}')\n",
    "    \n",
    "    Y = deepcopy(X)\n",
    "    if not bidirectional:\n",
    "        X = X[0:-1] # do not input the final time step in unidirectional LSTM\n",
    "        Y = Y[1:] # labels include all time steps but the first one in unidir. LSTM\n",
    "    model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=verbose, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PgYZ8dftB52M"
   },
   "source": [
    "# Composing with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-HrHl_rB52N"
   },
   "outputs": [],
   "source": [
    "def sample_distribution(dist_vec, num_categories):\n",
    "    \"\"\"\n",
    "    Sample a softmax distribution vector.\n",
    "    \n",
    "    Parameters:\n",
    "        dist_vec (np.array): A logit vector from which to take a sample from.\n",
    "        num_categories (int): Number of categories to sample from (used for reshaping).\n",
    "        \n",
    "    Returns:\n",
    "        int: The index of the output value which was sampled.\n",
    "    \"\"\"\n",
    "    return tf.random.categorical(dist_vec.reshape(1, num_categories), 1).numpy().flatten()[0]\n",
    "\n",
    "def compose(pitch_model, duration_model, pitch_prompt, duration_prompt, length=50):\n",
    "    '''\n",
    "    Composes a piece of music (in the format of a music21.stream.Stream object).\n",
    "    \n",
    "    Arguments:\n",
    "        pitch_model (tf.keras.Model): The trained model for pitch predictions.\n",
    "        duration_model (tf.keras.Model): The trained model for duration predictions.\n",
    "        pitch_prompt (int): The first pitch of the piece (index of the one-hot encoded pitch vector).\n",
    "        duration_prompt (int): The first duration of the piece (index of the one-hot encoded duration vector).\n",
    "        length (int): How many time steps to generate.\n",
    "       \n",
    "       Returns:\n",
    "           music21.stream.Stream(): The composed piece.\n",
    "    '''    \n",
    "    \n",
    "    # the lists that hold the indices of the values to index in to pitches/durations lists\n",
    "    generated_pitches, generated_durations = [pitch_prompt], [duration_prompt]\n",
    "    \n",
    "    current_pitch, current_duration = pitch_prompt, duration_prompt\n",
    "    for t in range(length):\n",
    "        # model only accepts 3D inputs\n",
    "        pitch_vec = timestep_to3d(vectorize(current_pitch, num_pitches))\n",
    "        duration_vec = timestep_to3d(vectorize(current_duration, num_durations))\n",
    "        \n",
    "        # predict the output distributions\n",
    "        pitch_pred = pitch_model.predict(pitch_vec)\n",
    "        duration_pred = duration_model.predict(duration_vec)\n",
    "        # sample the distributions (returns the index of the one-hot vectors)\n",
    "        next_pitch = sample_distribution(pitch_pred, num_pitches)\n",
    "        next_duration = sample_distribution(duration_pred, num_durations)\n",
    "        generated_pitches.append(next_pitch)\n",
    "        generated_durations.append(next_duration)\n",
    "        \n",
    "        # get ready for next iteration\n",
    "        current_pitch, current_duration = next_pitch, next_duration\n",
    "        \n",
    "    \n",
    "    composed_stream = stream.Stream()\n",
    "    for pair in list(zip(generated_pitches, generated_durations)):\n",
    "        p = pitch.Pitch(midi=pitches[pair[0]])\n",
    "        d = duration.Duration(durations[pair[1]])\n",
    "        n = note.Note()\n",
    "        n.pitch = p\n",
    "        n.duration = d\n",
    "        composed_stream.append(n)\n",
    "    \n",
    "    return composed_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TRyzfq-qB53t"
   },
   "source": [
    "# Generation infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdYQcfwCB53u",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bidirectional_vals = [True, False]\n",
    "lstm_cell_vals = [500, 1000, 2000]\n",
    "temperature_vals = [0.2, 0.5, 1.0, 10.0]\n",
    "\n",
    "def generate_param_sets(start=None, end=None):\n",
    "    \"\"\"\n",
    "    Creates sets of possible parameter combinations that will be tested over.\n",
    "    Optionally allows to pass in indices to return a sub set of param sets in case training in to be done at separate times.\n",
    "    \n",
    "    Parameters:\n",
    "        start (integer): The starting index of the range of sets to return from all possible sets.\n",
    "        end (int): The ending index (inclusive) of the renage of sets to return from all possible sets.\n",
    "        *NOTE that start and end must either both be None or integers; only suppling one argument causes an exception to be raised.\n",
    "    \"\"\"\n",
    "    sets = []\n",
    "    for bidirectional in bidirectional_vals:\n",
    "        for lstm_cells in lstm_cell_vals:\n",
    "            for temperature in temperature_vals:\n",
    "                s = {\n",
    "                    \"bidirectional\": bidirectional,\n",
    "                    \"lstm_cells\": lstm_cells,\n",
    "                    \"temperature\": temperature,\n",
    "                }\n",
    "                sets.append(s)\n",
    "                    \n",
    "    if start is None:\n",
    "      start = 0\n",
    "    if end is None or end > len(sets):\n",
    "      end = len(sets) - 1  # subtract 1 because of the +1 in the end slice\n",
    "\n",
    "    return sets[start:end+1]  # +1 to make the index passed in inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K8FixbskB53x"
   },
   "outputs": [],
   "source": [
    "def add_training_durations_string(dur1, dur2):\n",
    "    \"\"\"\n",
    "    Adds the training duration of two models and returns them in a string format.\n",
    "    \n",
    "    dur1/dur2 (float): floating point representation of training time in seconds\n",
    "    \"\"\"\n",
    "    \n",
    "    total_time = dur1 + dur2\n",
    "    hours = int(total_time // 3600)  # 3600 seconds/hour\n",
    "    minutes = int((total_time - (3600 * hours)) // 60) # subtract the hours from remaining time; 60 sec/min\n",
    "    seconds = (total_time - (3600 * hours)) - (60 * minutes)\n",
    "    return \"{}h {}m {:.2f}s\".format(hours, minutes, seconds)\n",
    "\n",
    "class MetadataModel:\n",
    "    \"\"\"\n",
    "    A wrapper class for LSTM models that is used to gather metadata from training.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_features, lstm_cells, bidirectional, temperature, verbose=0, id=None):\n",
    "        self._model = get_model(num_features, lstm_cells, bidirectional, temperature)\n",
    "        self._num_features = num_features\n",
    "        self._lstm_cells = lstm_cells\n",
    "        self._bidirectional = bidirectional\n",
    "        self._temperature = temperature\n",
    "        self.verbose = verbose # no underscore because this should be mutable\n",
    "        self._name = '_'.join([\"bidir\" if bidirectional else \"unidir\", str(lstm_cells), str(temperature)])\n",
    "        if id is not None:\n",
    "            self.name += f\"_{id}\"\n",
    "        self._total_training_time = 0.0 # in seconds\n",
    "    \n",
    "    # ---- setting properties so that these attributes are immutable ----\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    \n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "        \n",
    "    @property\n",
    "    def num_features(self):\n",
    "        return self._num_features\n",
    "    \n",
    "    @property\n",
    "    def lstm_cells(self):\n",
    "        return self._lstm_cells\n",
    "    \n",
    "    @property\n",
    "    def bidirectional(self):\n",
    "        return self._bidirectional\n",
    "    \n",
    "    @property\n",
    "    def temperature(self):\n",
    "        return self._temperature\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def total_training_time(self):\n",
    "        return self._total_training_time\n",
    "    \n",
    "    # returns a string version of training time\n",
    "    @property\n",
    "    def training_duration_string(self):\n",
    "        total_time = self._total_training_time\n",
    "        hours = int(total_time // 3600)  # 3600 seconds/hour\n",
    "        minutes = int((total_time - (3600 * hours)) // 60) # subtract the hours from remaining time; 60 sec/min\n",
    "        seconds = (total_time - (3600 * hours)) - (60 * minutes)\n",
    "        return \"{}h {}m {:.2f}s\".format(hours, minutes, seconds)\n",
    "            \n",
    "    def train(self, X, dataset_name, model_no):\n",
    "        start_time = time.time()\n",
    "        train_model(self.model, X, self.bidirectional, self.verbose, model_name=self.name, model_dataset=dataset_name, model_no=model_no)\n",
    "        end_time = time.time()\n",
    "        self._total_training_time += end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w-ikO1pxB53-"
   },
   "outputs": [],
   "source": [
    "def sample_start_pitch():\n",
    "    \"\"\"\n",
    "    Sample from the dictionary containing the probabilities of starting a piece with a given pitch.\n",
    "    \n",
    "    Parameters:\n",
    "        dictionary (dict(int: float)): The dictionary whose values are probabilities, and whose keys are the MIDI pitch.\n",
    "                                       This dictionary must be sorted by key.\n",
    "        \n",
    "    Returns:\n",
    "        int: The index of the MIDI pitch in the pitches list.\n",
    "    \"\"\"\n",
    "    logits = np.array(list(starting_pitch_likelihood.values()))\n",
    "    return np.argmax(np.random.multinomial(1, logits))\n",
    "    \n",
    "def sample_start_duration():\n",
    "    \"\"\"\n",
    "    Sample from the dictionary containing the probabilities of starting a piece with a given duration.\n",
    "    \n",
    "    Parameters:\n",
    "        dictionary (dict(float: float)): The dictionary whose values are probabilities, and whose keys are the quarter length duration.\n",
    "                                         This dictionary must be sorted by key.\n",
    "        \n",
    "    Returns:\n",
    "        np.array: The index of the sampled duration in the durations list.\n",
    "    \"\"\"\n",
    "    logits = np.array(list(starting_duration_likelihood.values()))\n",
    "    return np.argmax(np.random.multinomial(1, logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UT0PniOzB54E"
   },
   "outputs": [],
   "source": [
    "def run_tests(pitch_short, pitch_medium, pitch_long, duration_short, duration_medium,\\\n",
    "              duration_long, param_set_start=None, param_set_end=None,\\\n",
    "              num_compositions=5, verbose=0):\n",
    "    \"\"\"\n",
    "    Creates, trains, and composes with networks of a multitude of parameter combinations.\n",
    "    \n",
    "    Parameters:\n",
    "        pitch_short (np.array): The short pitch sequences.\n",
    "        pitch_medium (np.array): The medium pitch sequences.\n",
    "        pitch_long (np.array): The long pitch sequences.\n",
    "        duration_short (np.array): The short duration sequences.\n",
    "        duration_medium (np.array): The medium duration sequences.\n",
    "        duration_long (np.array): The long duration sequences.\n",
    "        param_set_start (int): The first of the generated param. sets to be tested on.\n",
    "        param_set_end (int): The last of the generated param. sets to be tested on.\n",
    "        num_compositions (int): How many pieces to compose for each model being tested.\n",
    "        verbose (int): The amount of information to print throughout the test.\n",
    "        \n",
    "        Returns: None\n",
    "    \"\"\"\n",
    "    \n",
    "    param_sets = generate_param_sets(param_set_start, param_set_end)\n",
    "    pitch_models, duration_models = [], []\n",
    "    model_no = 0 # which iteration of model we are on\n",
    "    if param_set_start is not None:\n",
    "        model_no = param_set_start\n",
    "            \n",
    "    test_start_time=time.time()            \n",
    "    for params in param_sets:\n",
    "        bidirectional = params[\"bidirectional\"]\n",
    "        lstm_cells = params[\"lstm_cells\"]\n",
    "        temperature = params[\"temperature\"]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Model {model_no}:\\n\\tbidirectional – {bidirectional}\\n\\tlstm cells – {lstm_cells}\\\n",
    "            \\n\\ttemperature – {temperature}\")\n",
    "        \n",
    "        pitch_model = MetadataModel(num_pitches, lstm_cells, bidirectional, temperature, verbose)\n",
    "        duration_model = MetadataModel(num_durations, lstm_cells, bidirectional, temperature, verbose)\n",
    "        \n",
    "        # train the pitch network\n",
    "        if verbose:\n",
    "            print('\\n\\tTraining pitch generation network...')\n",
    "            print('\\t\\tOn short data set:')\n",
    "        pitch_model.train(pitch_short, 'pitch_short', model_no)\n",
    "        if verbose:\n",
    "            print('\\t\\tOn medium data set:')\n",
    "        pitch_model.train(pitch_medium, 'pitch_medium', model_no)\n",
    "        if verbose:\n",
    "            print('\\t\\tOn long data set:')\n",
    "        pitch_model.train(pitch_long, 'pitch_long', model_no)\n",
    "        pitch_model.model.save(f\"{MODELS_DIRECTORY}/{model_no}_pitch_{pitch_model.name}.h5\")\n",
    "        if verbose:\n",
    "            print(f\"\\t\\tPitch model training complete: saved at {MODELS_DIRECTORY}/{model_no}_pitch_{pitch_model.name}.h5\")\n",
    "            print(f\"\\t\\tTotal training time: {pitch_model.training_duration_string}'\")\n",
    "        \n",
    "        # train the duration network\n",
    "        if verbose:\n",
    "            print('\\n\\tTraining rhythm (duration) generation network...')\n",
    "            print('\\t\\tOn short data set:')\n",
    "        duration_model.train(duration_short, 'duration_short', model_no)\n",
    "        if verbose:\n",
    "            print('\\t\\tOn medium data set:')\n",
    "        duration_model.train(duration_medium, 'duration_medium', model_no)\n",
    "        if verbose:\n",
    "            print('\\t\\tOn long data set:')\n",
    "        duration_model.train(duration_long, 'duration_long', model_no)\n",
    "        duration_model.model.save(f\"{MODELS_DIRECTORY}/{model_no}_duration_{duration_model.name}.h5\")\n",
    "        if verbose:\n",
    "            print(f\"\\t\\tDuration model training complete: saved at {MODELS_DIRECTORY}/{model_no}_duration_{duration_model.name}.h5\")\n",
    "            print(f\"\\t\\tTotal training time: {duration_model.training_duration_string}\")\n",
    "        if verbose:\n",
    "            print(f'\\n\\tModel {model_no} training complete')\n",
    "            print(f'\\tTotal time to train pitch and duration models: {add_training_durations_string(duration_model.total_training_time, pitch_model.total_training_time)}')\n",
    "        \n",
    "        # compose outputs and save them\n",
    "        if not os.path.exists(f\"{COMPOSITIONS_DIRECTORY}/model_{model_no}\"):\n",
    "            os.makedirs(f\"{COMPOSITIONS_DIRECTORY}/model_{model_no}\")\n",
    "        comp_count = 1\n",
    "        for c in range(num_compositions):\n",
    "            pitch_prompt = sample_start_pitch()\n",
    "            duration_prompt = sample_start_duration()\n",
    "            composition = compose(pitch_model.model, duration_model.model, pitch_prompt, duration_prompt, length=100)\n",
    "            composition.write('musicxml', f'{COMPOSITIONS_DIRECTORY}/model_{model_no}/composition_{comp_count}.mxl')\n",
    "            composition.write('midi', f'{COMPOSITIONS_DIRECTORY}/model_{model_no}/composition_{comp_count}.mid')\n",
    "            comp_count += 1\n",
    "        print(f\"\\t\\tCompositions successfully written to {COMPOSITIONS_DIRECTORY}/model_{model_no}\")\n",
    "            \n",
    "        model_no = model_no + 1\n",
    "        print('–' * 50 + \"\\n\\n\")\n",
    "        \n",
    "        \n",
    "    test_end_time=time.time()\n",
    "    total_time = test_end_time - test_start_time\n",
    "    hours = int(total_time // 3600)  # 3600 seconds/hour\n",
    "    minutes = int((total_time - (3600 * hours)) // 60) # subtract the hours from remaining time; 60 sec/min\n",
    "    seconds = (total_time - (3600 * hours)) - (60 * minutes)\n",
    "    print(\"TRAINING COMPLETE – elapsed time: {}h {}m {:.2f}s\".format(hours, minutes, seconds))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kVVnQFOsB54J",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_tests(short_seqs_pitch, medium_seqs_pitch, long_seqs_pitch, short_seqs_duration, medium_seqs_duration, long_seqs_duration, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

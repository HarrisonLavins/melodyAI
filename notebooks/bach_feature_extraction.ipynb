{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from math import ceil, floor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "- chord_names (nominal)\n",
    "        - Label encoding (C major -> 0, A major -> 13)\n",
    "        - One-hot encoding?\n",
    "        - Feature hashing\n",
    "- roman_numerals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myChord = chord.Chord([\"E-5\",\"C4\",\"G4\"])\n",
    "myChord.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myChord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitches = myChord.pitches\n",
    "pitches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melody = pitches[-1]\n",
    "melody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myChord.sortAscending(inPlace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bach_corpus = corpus.search('bach', 'composer')\n",
    "bach_corpus[-23].parse().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load corpus of Bach chorales\n",
    "bach_corpus = corpus.search('bach', 'composer')\n",
    "\n",
    "\n",
    "for chorale in bach_corpus:\n",
    "    chorale = chorale.parse()\n",
    "    print('Processing chorale: {}'.format(chorale.metadata.title))\n",
    "    sopranoPart = chorale.getElementsByClass('Part')[0]\n",
    "    \n",
    "    for keychange in sopranoPart.recurse().getElementsByClass(key.Key):\n",
    "        #Get key information and offset location\n",
    "        print(keychange, keychange.offset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through soprano part and print all key changes\n",
    "print('Key Changes:')\n",
    "for keychange in soprano.recurse().getElementsByClass(key.Key):\n",
    "    #Get key information and offset location\n",
    "    print(keychange, keychange.offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bachFeatures = pd.DataFrame(np.zeros((len(bach),2)), columns = ['roman_numerals', 'mel_notes'], dtype='object')\n",
    "bachFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bachFeatures.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = key.Key('f#')  # 3-sharps minor\n",
    "rn = roman.RomanNumeral('V', k)\n",
    "rn.key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn.pitchedCommonName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the notes from each piece in the corpus and place in in the x_train variable\n",
    "\n",
    "bach_corpus = corpus.getComposer('bach')\n",
    "pitch_train = []  # training data for the sequence of pitches (MIDI number)\n",
    "duration_train = []  # training data for the sequence of note durations\n",
    "\n",
    "pitches = [50, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74,\n",
    "           75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88] # all MIDI pitches found in the Bach corpus\n",
    "pitch_one_hot_indices = {pitches[i]: i for i in range(len(pitches))}  # for the one-hot vector encoding\n",
    "durations = [0.125, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 6.0, 8.0]  # all durations found in the Bach corpus\n",
    "duration_one_hot_indices = {durations[i]: i for i in range(len(durations))}  # for the one-hot vector encoding\n",
    "\n",
    "for piece in bach_corpus:\n",
    "    pitch_sequence = []  # the sequence of pitches for this piece\n",
    "    duration_sequence = []  # the sequence of note durations for this piece\n",
    "    \n",
    "    piece_score = corpus.parse(piece)  # stream.Score object\n",
    "    melody_part = piece_score.getElementsByClass('Part')[0]  # melody parts are always the first part in the score\n",
    "    melody_notes = melody_part.flat.getElementsByClass(['Note', 'Rest'])\n",
    "    \n",
    "    # DON'T CHANGE n to Note or note (namespace conflict)\n",
    "    # builds the feature vectors by One-Hot encoding MIDI numbers and durations\n",
    "    for n in melody_notes.recurse():  # iterates through all notes in the piece\n",
    "        this_duration = np.zeros(len(durations))\n",
    "        this_pitch = np.zeros(len(pitches))\n",
    "        \n",
    "        note_duration = n.duration.quarterLength\n",
    "        if note_duration == 0.0:\n",
    "            continue  # this is a grace note, toss it and move to next note\n",
    "        else:\n",
    "            this_duration[duration_one_hot_indices[note_duration]] = 1\n",
    "\n",
    "        if n.isNote:  # and is therefore not a rest; has pitch\n",
    "            midi_pitch = n.pitch.midi\n",
    "            this_pitch[pitch_one_hot_indices[midi_pitch]] = 1\n",
    "            \n",
    "            pitch_sequence.append(this_pitch)\n",
    "            duration_sequence.append(this_duration)\n",
    "        \n",
    "    pitch_train.append(pitch_sequence)\n",
    "    duration_train.append(duration_sequence)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples with 17 ≤ len ≤ 94 = 388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(7, 1),\n",
       " (23, 2),\n",
       " (25, 1),\n",
       " (26, 2),\n",
       " (28, 1),\n",
       " (29, 2),\n",
       " (30, 2),\n",
       " (31, 4),\n",
       " (32, 9),\n",
       " (33, 8),\n",
       " (34, 8),\n",
       " (35, 9),\n",
       " (36, 6),\n",
       " (37, 11),\n",
       " (38, 8),\n",
       " (39, 10),\n",
       " (40, 11),\n",
       " (41, 17),\n",
       " (42, 8),\n",
       " (43, 20),\n",
       " (44, 15),\n",
       " (45, 13),\n",
       " (46, 24),\n",
       " (47, 12),\n",
       " (48, 11),\n",
       " (49, 10),\n",
       " (50, 9),\n",
       " (51, 17),\n",
       " (52, 12),\n",
       " (53, 10),\n",
       " (54, 6),\n",
       " (55, 9),\n",
       " (56, 3),\n",
       " (57, 7),\n",
       " (58, 4),\n",
       " (59, 10),\n",
       " (60, 5),\n",
       " (61, 5),\n",
       " (62, 4),\n",
       " (63, 6),\n",
       " (64, 8),\n",
       " (65, 5),\n",
       " (66, 4),\n",
       " (67, 4),\n",
       " (68, 4),\n",
       " (69, 2),\n",
       " (70, 6),\n",
       " (71, 4),\n",
       " (72, 1),\n",
       " (73, 1),\n",
       " (74, 1),\n",
       " (76, 2),\n",
       " (77, 1),\n",
       " (78, 1),\n",
       " (79, 1),\n",
       " (80, 1),\n",
       " (81, 2),\n",
       " (82, 2),\n",
       " (86, 1),\n",
       " (87, 3),\n",
       " (88, 1),\n",
       " (89, 2),\n",
       " (97, 2),\n",
       " (98, 1),\n",
       " (99, 2),\n",
       " (101, 1),\n",
       " (103, 1),\n",
       " (104, 2),\n",
       " (105, 1),\n",
       " (109, 2),\n",
       " (114, 1),\n",
       " (116, 1),\n",
       " (132, 1),\n",
       " (135, 1),\n",
       " (153, 1),\n",
       " (155, 1),\n",
       " (168, 1),\n",
       " (186, 1),\n",
       " (358, 1),\n",
       " (400, 1),\n",
       " (558, 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length_counts = {}\n",
    "all_sequence_lengths = []\n",
    "for sequence in pitch_train:\n",
    "    if len(sequence) == 0:\n",
    "        continue\n",
    "    if len(sequence) in sequence_length_counts.keys():\n",
    "        sequence_length_counts[len(sequence)] += 1\n",
    "    else:\n",
    "        sequence_length_counts[len(sequence)] = 1\n",
    "    all_sequence_lengths.append(len(sequence))\n",
    "        \n",
    "all_sequence_lengths = np.array(all_sequence_lengths)\n",
    "mean_len = np.mean(all_sequence_lengths)\n",
    "std_len = np.std(all_sequence_lengths)\n",
    "\n",
    "#print(f\"Mean: {mean_len}\\nStdev: {std_len}\\nMean ± 1 stdev: {mean_len - std_len} – {mean_len + std_len}\\nMean ± 1.5 stdev: {mean_len - 1.5*std_len} {mean_len + 1.5*std_len}\")\n",
    "lower_seq_len, upper_seq_len = ceil(mean_len - std_len), floor(mean_len + std_len)\n",
    "num_samples_in_range = sum([sequence_length_counts[length] for length in sequence_length_counts.keys()\\\n",
    "                            if length in range(lower_seq_len, upper_seq_len + 1)])\n",
    "print(f\"Number of samples with {lower_seq_len} ≤ len ≤ {upper_seq_len} = {num_samples_in_range}\")\n",
    "[(num, sequence_length_counts[num]) for num in sorted(sequence_length_counts.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len before 433\n",
      "len after 388\n"
     ]
    }
   ],
   "source": [
    "# prune the data set\n",
    "print(f\"len before {len(pitch_train)}\")\n",
    "drop_indices = []  # indices of sequences which we are pruning\n",
    "\n",
    "for seq_num in range(len(pitch_train)):\n",
    "    # the sequence doesn't fall in the length range we determined\n",
    "    if (not len(pitch_train[seq_num]) >= lower_seq_len) or (not len(pitch_train[seq_num]) <= upper_seq_len):\n",
    "        drop_indices.append(seq_num)\n",
    "        \n",
    "for i in sorted(drop_indices, reverse=True):\n",
    "    pitch_train.pop(i)\n",
    "    duration_train.pop(i)\n",
    "        \n",
    "print(f\"len after {len(pitch_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pad sequences\n",
    "pitch_train = pad_sequences(pitch_train, padding=\"post\")\n",
    "duration_train = pad_sequences(duration_train, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388 387\n"
     ]
    }
   ],
   "source": [
    "# generate label sequences\n",
    "pitch_labels = pitch_train[1:]\n",
    "duration_labels = duration_labels = duration_train[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize training data and labels for use in another script\n",
    "with open('datasetspitch_train.pickle', 'wb') as f:\n",
    "    pickle.dump(pitch_train, f)\n",
    "    \n",
    "with open('duration_train.pickle', 'wb') as f:\n",
    "    pickle.dump(duration_train, f)\n",
    "    \n",
    "with open('pitch_labels.pickle', 'wb') as f:\n",
    "    pickle.dump(pitch_labels, f)\n",
    "    \n",
    "with open('duration_labels.pickle', 'wb') as f:\n",
    "    pickle.dump(duration_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

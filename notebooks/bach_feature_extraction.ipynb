{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from math import ceil, floor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the notes from each piece in the corpus and place in in the x_train variable\n",
    "\n",
    "bach_corpus = corpus.getComposer('bach')\n",
    "# pitch_train/duration_train are NOT one-hot encoded, but hold data that will be transformed to one-hot later\n",
    "pitch_train = []  # training data for the sequence of pitches (MIDI number)\n",
    "duration_train = []  # training data for the sequence of note durations (floats)\n",
    "pitch_freq = {} # how often a given pitch occurs (will be normalized after all pieces have been analyzed)\n",
    "duration_freq = {}  # how often each pitch occurs (will be normalized after all pieces have been analyzed)\n",
    "starting_pitch_likelihood = {}  # how likely a piece is to start with a given MIDI pitch \n",
    "starting_duration_likelihood = {}  # how likely a piece is to start with a given duration\n",
    "\n",
    "for piece in bach_corpus:\n",
    "    piece_score = corpus.parse(piece)  # stream.Score object\n",
    "    melody_part = piece_score.getElementsByClass('Part')[0]  # melody parts are always the first part in the score\n",
    "    melody_notes = melody_part.flat.getElementsByClass(['Note', 'Rest'])\n",
    "    \n",
    "    # transpose all pitches within the range of +6 to -5 half steps (including the unaltered version)\n",
    "    for i in range(6,-6,-1):\n",
    "        # transpose the melody part\n",
    "        melody_transposed = melody_notes.transpose(i)\n",
    "        pitch_sequence = []  # the sequence of MIDI pitches for this piece\n",
    "        duration_sequence = []  # the sequence of quarter length note durations for this piece\n",
    "    \n",
    "        is_first_note = True # used to build the prob. dist of starting pitch/duration\n",
    "        # builds the feature vectors by One-Hot encoding MIDI numbers and durations\n",
    "        for n in melody_transposed.recurse():  # iterates through all notes in the piece\n",
    "            note_duration = n.duration.quarterLength\n",
    "            if note_duration < 0.25 or note_duration >= 6.0:\n",
    "                continue  # discard all notes less than 16th notes\n",
    "            else:\n",
    "                duration_sequence.append(note_duration)\n",
    "                if note_duration not in duration_freq.keys():\n",
    "                    duration_freq[note_duration] = 1\n",
    "                else:\n",
    "                    duration_freq[note_duration] += 1\n",
    "                duration_sequence.append(note_duration)\n",
    "\n",
    "            if n.isNote:  # and is therefore not a rest; has pitch\n",
    "                midi_pitch = n.pitch.midi\n",
    "                pitch_sequence.append(midi_pitch)\n",
    "                if midi_pitch not in pitch_freq.keys():\n",
    "                    pitch_freq[midi_pitch] = 1\n",
    "                else:\n",
    "                    pitch_freq[midi_pitch] += 1\n",
    "            else:  # is a rest\n",
    "                if -1 not in pitch_freq.keys():\n",
    "                    pitch_freq[-1] = 1\n",
    "                else:\n",
    "                    pitch_freq[-1] += 1\n",
    "                pitch_sequence.append(-1) # -1 pitch indicates it is a rest (will one-hot encode to 0 vector)\n",
    "                \n",
    "            if is_first_note: # save the note info to keep track of how often each pitch/duration starts a piece\n",
    "                if midi_pitch in starting_pitch_likelihood.keys():\n",
    "                    starting_pitch_likelihood[midi_pitch] += 1\n",
    "                else:\n",
    "                    starting_pitch_likelihood[midi_pitch] = 1\n",
    "                    \n",
    "                if note_duration in starting_duration_likelihood:\n",
    "                    starting_duration_likelihood[note_duration] += 1\n",
    "                else:\n",
    "                    starting_duration_likelihood[note_duration] = 1\n",
    "                    \n",
    "                is_first_note = False\n",
    "        \n",
    "        pitch_train.append(pitch_sequence)\n",
    "        duration_train.append(duration_sequence) \n",
    "        \n",
    "pitches, durations = sorted(list(pitch_freq.keys())), sorted(list(duration_freq.keys()))\n",
    "num_pitches, num_durations = len(pitches), len(durations)\n",
    "# dictionary to map possible pitch/duration to a one-hot vector index\n",
    "pitch_indices = {p: i for (i, p) in enumerate(pitches)}\n",
    "duration_indices = {d: i for (i, d) in enumerate(durations)}\n",
    "# normalize the frequency of ALL pitches/duration\n",
    "pitch_freq = {p: float(pitch_freq[p]/sum(pitch_freq.values())) for p in sorted(pitch_freq.keys())}\n",
    "duration_freq = {d: float(duration_freq[d]/sum(duration_freq.values())) for d in sorted(duration_freq.keys())}\n",
    "# normalize the occurrences of STARTING pitches/durations\n",
    "starting_pitch_likelihood = {p: float(starting_pitch_likelihood[p]/sum(starting_pitch_likelihood.values())) for p in sorted(starting_pitch_likelihood.keys())}\n",
    "starting_duration_likelihood = {d: float(starting_duration_likelihood[d]/sum(starting_duration_likelihood.values())) for d in sorted(starting_duration_likelihood.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length_counts = {}\n",
    "all_sequence_lengths = []\n",
    "for sequence in pitch_train:\n",
    "    if len(sequence) == 0:\n",
    "        continue\n",
    "    if len(sequence) in sequence_length_counts.keys():\n",
    "        sequence_length_counts[len(sequence)] += 1\n",
    "    else:\n",
    "        sequence_length_counts[len(sequence)] = 1\n",
    "\n",
    "sequence_length_counts = {key: sequence_length_counts[key] for key in sorted(sequence_length_counts.keys())}\n",
    "\n",
    "sequence_length_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrarily decide on ceiling/floor of lengths that we will consider for training\n",
    "# this is a bit clunky, but I'm trying to make it an general as possible (in case the corpus somehow drastically changes)\n",
    "min_length, max_length = 40, 70\n",
    "range_size = ceil((max_length - min_length) / 3)\n",
    "short_range = range(min_length, min_length + range_size)\n",
    "medium_range = range(min_length + range_size, max_length - range_size) \n",
    "long_range = range(max_length - range_size, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prune the data set\n",
    "print(f\"Number of sequences before pruning: {len(pitch_train)}\")\n",
    "short_sequences_duration = []\n",
    "short_sequences_pitch = []\n",
    "medium_sequences_duration = []\n",
    "medium_sequences_pitch = []\n",
    "long_sequences_duration = []\n",
    "long_sequences_pitch = []\n",
    "\n",
    "for seq_index in range(len(pitch_train)):\n",
    "    # the sequence must fall in one of the ranges we have determined\n",
    "    if len(pitch_train[seq_index]) in short_range:\n",
    "        short_sequences_duration.append(duration_train[seq_index])\n",
    "        short_sequences_pitch.append(pitch_train[seq_index])\n",
    "    elif len(pitch_train[seq_index]) in medium_range:\n",
    "        medium_sequences_duration.append(duration_train[seq_index])\n",
    "        medium_sequences_pitch.append(pitch_train[seq_index])\n",
    "    elif len(pitch_train[seq_index]) in long_range:\n",
    "        long_sequences_duration.append(duration_train[seq_index])\n",
    "        long_sequences_pitch.append(pitch_train[seq_index])\n",
    "    # else we don't use the sample\n",
    "        \n",
    "print(f\"Number of sequences (short, medium, long) after pruning: {len(short_sequences_duration), len(medium_sequences_duration), len(long_sequences_duration)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode the samples we are keeping\n",
    "\n",
    "# short sequences\n",
    "one_hot_short_seqs_pitch = []\n",
    "one_hot_short_seqs_duration = []\n",
    "for seq in short_sequences_pitch:\n",
    "    encoded_seq = []\n",
    "    for p in seq:\n",
    "        vec = np.zeros(num_pitches)\n",
    "        if p != -1:  # is a rest, all 0 vector will indicate this\n",
    "            vec[pitch_indices[p]] = 1.0\n",
    "        encoded_seq.append(vec)\n",
    "    one_hot_short_seqs_pitch.append(encoded_seq)\n",
    "    \n",
    "for seq in short_sequences_duration:\n",
    "    encoded_seq = []\n",
    "    for d in seq:\n",
    "        vec = np.zeros(num_durations)\n",
    "        vec[duration_indices[d]] = 1.0\n",
    "        encoded_seq.append(vec)\n",
    "    one_hot_short_seqs_duration.append(encoded_seq)\n",
    "    \n",
    "\n",
    "# medium sequences\n",
    "one_hot_medium_seqs_pitch = []\n",
    "one_hot_medium_seqs_duration = []\n",
    "for seq in medium_sequences_pitch:\n",
    "    encoded_seq = []\n",
    "    for p in seq:\n",
    "        vec = np.zeros(num_pitches)\n",
    "        if p != -1:  # is a rest, all 0 vector will indicate this\n",
    "            vec[pitch_indices[p]] = 1.0\n",
    "        encoded_seq.append(vec)\n",
    "    one_hot_medium_seqs_pitch.append(encoded_seq)\n",
    "    \n",
    "for seq in medium_sequences_duration:\n",
    "    encoded_seq = []\n",
    "    for d in seq:\n",
    "        vec = np.zeros(num_durations)\n",
    "        vec[duration_indices[d]] = 1.0\n",
    "        encoded_seq.append(vec)\n",
    "    one_hot_medium_seqs_duration.append(encoded_seq)\n",
    "    \n",
    "# long sequences\n",
    "one_hot_long_seqs_pitch = []\n",
    "one_hot_long_seqs_duration = []\n",
    "for seq in long_sequences_pitch:\n",
    "    encoded_seq = []\n",
    "    for p in seq:\n",
    "        vec = np.zeros(num_pitches)\n",
    "        if p != -1:  # is a rest, all 0 vector will indicate this\n",
    "            vec[pitch_indices[p]] = 1.0\n",
    "        encoded_seq.append(vec)\n",
    "    one_hot_long_seqs_pitch.append(encoded_seq)\n",
    "    \n",
    "for seq in long_sequences_duration:\n",
    "    encoded_seq = []\n",
    "    for d in seq:\n",
    "        vec = np.zeros(num_durations)\n",
    "        vec[duration_indices[d]] = 1.0\n",
    "        encoded_seq.append(vec)\n",
    "    one_hot_long_seqs_duration.append(encoded_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pad sequences\n",
    "short_sequences_duration = pad_sequences(one_hot_short_seqs_duration, padding=\"post\", dtype='float32')\n",
    "short_sequences_pitch = pad_sequences(one_hot_short_seqs_pitch, padding=\"post\", dtype='float32')\n",
    "medium_sequences_duration = pad_sequences(one_hot_medium_seqs_duration, padding=\"post\", dtype='float32')\n",
    "medium_sequences_pitch = pad_sequences(one_hot_medium_seqs_pitch, padding=\"post\", dtype='float32')\n",
    "long_sequences_duration = pad_sequences(one_hot_long_seqs_duration, padding=\"post\", dtype='float32')\n",
    "long_sequences_pitch = pad_sequences(one_hot_long_seqs_pitch, padding=\"post\", dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(short_sequences_duration.shape, short_sequences_pitch.shape)\n",
    "print(medium_sequences_duration.shape, medium_sequences_pitch.shape)\n",
    "print(long_sequences_duration.shape, long_sequences_pitch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize training data and labels for use in another script\n",
    "with open('pickles/short_seqs_duration.pickle', 'wb') as f:\n",
    "    pickle.dump(short_sequences_duration, f)\n",
    "    \n",
    "with open('pickles/short_seqs_pitch.pickle', 'wb') as f:\n",
    "    pickle.dump(short_sequences_pitch, f)\n",
    "    \n",
    "with open('pickles/medium_seqs_duration.pickle', 'wb') as f:\n",
    "    pickle.dump(medium_sequences_duration, f)\n",
    "    \n",
    "with open('pickles/medium_seqs_pitch.pickle', 'wb') as f:\n",
    "    pickle.dump(medium_sequences_pitch, f)\n",
    "    \n",
    "with open('pickles/long_seqs_duration.pickle', 'wb') as f:\n",
    "    pickle.dump(long_sequences_duration, f)\n",
    "    \n",
    "with open('pickles/long_seqs_pitch.pickle', 'wb') as f:\n",
    "    pickle.dump(long_sequences_pitch, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the relevant pitches/durations so we can get the respective values from the prediction output vectors\n",
    "with open('pickles/pitches.pickle', 'wb') as f:\n",
    "    pickle.dump(pitches, f)\n",
    "\n",
    "with open('pickles/durations.pickle', 'wb') as f:\n",
    "    pickle.dump(durations, f)\n",
    "    \n",
    "# serialize the mapping from pitch/duration to one hot indices\n",
    "with open('pickles/pitch_indices.pickle', 'wb') as f:\n",
    "    pickle.dump(pitch_indices, f)\n",
    "    \n",
    "with open('pickles/duration_indices.pickle', 'wb') as f:\n",
    "    pickle.dump(duration_indices, f)\n",
    "    \n",
    "with open('pickles/starting_pitch_likelihood.pickle', 'wb') as f:\n",
    "    pickle.dump(starting_pitch_likelihood, f)\n",
    "    \n",
    "with open('pickles/starting_duration_likelihood.pickle', 'wb') as f:\n",
    "    pickle.dump(starting_duration_likelihood, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

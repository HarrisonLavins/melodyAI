{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from music21 import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from math import ceil, floor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the notes from each piece in the corpus and place in in the x_train variable\n",
    "\n",
    "bach_corpus = corpus.getComposer('bach')\n",
    "pitch_train = []  # training data for the sequence of pitches (MIDI number)\n",
    "duration_train = []  # training data for the sequence of note durations\n",
    "\n",
    "pitches = [50, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74,\n",
    "           75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88] # all MIDI pitches found in the Bach corpus\n",
    "pitch_one_hot_indices = {pitches[i]: i for i in range(len(pitches))}  # for the one-hot vector encoding\n",
    "durations = [0.125, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 6.0, 8.0]  # all durations found in the Bach corpus\n",
    "duration_one_hot_indices = {durations[i]: i for i in range(len(durations))}  # for the one-hot vector encoding\n",
    "\n",
    "for piece in bach_corpus:\n",
    "    pitch_sequence = []  # the sequence of pitches for this piece\n",
    "    duration_sequence = []  # the sequence of note durations for this piece\n",
    "    \n",
    "    piece_score = corpus.parse(piece)  # stream.Score object\n",
    "    melody_part = piece_score.getElementsByClass('Part')[0]  # melody parts are always the first part in the score\n",
    "    melody_notes = melody_part.flat.getElementsByClass(['Note', 'Rest'])\n",
    "    \n",
    "    # DON'T CHANGE n to Note or note (namespace conflict)\n",
    "    # builds the feature vectors by One-Hot encoding MIDI numbers and durations\n",
    "    for n in melody_notes.recurse():  # iterates through all notes in the piece\n",
    "        this_duration = np.zeros(len(durations))\n",
    "        this_pitch = np.zeros(len(pitches))\n",
    "        \n",
    "        note_duration = n.duration.quarterLength\n",
    "        if note_duration == 0.0:\n",
    "            continue  # this is a grace note, toss it and move to next note\n",
    "        else:\n",
    "            this_duration[duration_one_hot_indices[note_duration]] = 1\n",
    "\n",
    "        if n.isNote:  # and is therefore not a rest; has pitch\n",
    "            midi_pitch = n.pitch.midi\n",
    "            this_pitch[pitch_one_hot_indices[midi_pitch]] = 1\n",
    "            \n",
    "            pitch_sequence.append(this_pitch)\n",
    "            duration_sequence.append(this_duration)\n",
    "        \n",
    "    pitch_train.append(pitch_sequence)\n",
    "    duration_train.append(duration_sequence)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length_counts = {}\n",
    "all_sequence_lengths = []\n",
    "for sequence in pitch_train:\n",
    "    if len(sequence) == 0:\n",
    "        continue\n",
    "    if len(sequence) in sequence_length_counts.keys():\n",
    "        sequence_length_counts[len(sequence)] += 1\n",
    "    else:\n",
    "        sequence_length_counts[len(sequence)] = 1\n",
    "\n",
    "sequence_length_counts = {key: sequence_length_counts[key] for key in sorted(sequence_length_counts.keys())}\n",
    "#sequence_length_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrarily decide on ceiling/floor of lengths that we will consider for training\n",
    "# this is a bit clunky, but I'm trying to make it an general as possible (in case the corpus somehow drastically changes)\n",
    "min_length, max_length = 40, 70\n",
    "range_size = ceil((max_length - min_length) / 3)\n",
    "short_range = range(min_length, min_length + range_size)\n",
    "medium_range = range(min_length + range_size, max_length - range_size) \n",
    "long_range = range(max_length - range_size, max_length)\n",
    "short_samples, med_samples, long_samples = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences before pruning: 433\n",
      "Number of sequences (short, medium, long) after pruning: (141, 87, 47)\n"
     ]
    }
   ],
   "source": [
    "# prune the data set\n",
    "print(f\"Number of sequences before pruning: {len(pitch_train)}\")\n",
    "short_sequences_duration = []\n",
    "short_sequences_pitch = []\n",
    "medium_sequences_duration = []\n",
    "medium_sequences_pitch = []\n",
    "long_sequences_duration = []\n",
    "long_sequences_pitch = []\n",
    "\n",
    "for seq_index in range(len(pitch_train)):\n",
    "    # the sequence doesn't fall in the length range we determined\n",
    "    if len(pitch_train[seq_index]) in short_range:\n",
    "        short_sequences_duration.append(duration_train[seq_index])\n",
    "        short_sequences_pitch.append(pitch_train[seq_index])\n",
    "    elif len(pitch_train[seq_index]) in medium_range:\n",
    "        medium_sequences_duration.append(duration_train[seq_index])\n",
    "        medium_sequences_pitch.append(pitch_train[seq_index])\n",
    "    elif len(pitch_train[seq_index]) in long_range:\n",
    "        long_sequences_duration.append(duration_train[seq_index])\n",
    "        long_sequences_pitch.append(pitch_train[seq_index])\n",
    "    # else we don't use the sample\n",
    "        \n",
    "print(f\"Number of sequences (short, medium, long) after pruning: {len(short_sequences_duration), len(medium_sequences_duration), len(long_sequences_duration)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pad sequences\n",
    "short_sequences_duration = pad_sequences(short_sequences_duration, padding=\"post\", dtype='float32')\n",
    "short_sequences_pitch = pad_sequences(short_sequences_pitch, padding=\"post\", dtype='float32')\n",
    "medium_sequences_duration = pad_sequences(medium_sequences_duration, padding=\"post\", dtype='float32')\n",
    "medium_sequences_pitch = pad_sequences(medium_sequences_pitch, padding=\"post\", dtype='float32')\n",
    "long_sequences_duration = pad_sequences(long_sequences_duration, padding=\"post\", dtype='float32')\n",
    "long_sequences_pitch = pad_sequences(long_sequences_pitch, padding=\"post\", dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize training data and labels for use in another script\n",
    "with open('pickles/short_sequences_duration.pickle', 'wb') as f:\n",
    "    pickle.dump(short_sequences_duration, f)\n",
    "    \n",
    "with open('pickles/short_sequences_pitch.pickle', 'wb') as f:\n",
    "    pickle.dump(short_sequences_pitch, f)\n",
    "    \n",
    "with open('pickles/medium_sequences_duration.pickle', 'wb') as f:\n",
    "    pickle.dump(medium_sequences_duration, f)\n",
    "    \n",
    "with open('pickles/medium_sequences_pitch.pickle', 'wb') as f:\n",
    "    pickle.dump(medium_sequences_pitch, f)\n",
    "    \n",
    "with open('pickles/long_sequences_duration.pickle', 'wb') as f:\n",
    "    pickle.dump(long_sequences_duration, f)\n",
    "    \n",
    "with open('pickles/long_sequences_pitch.pickle', 'wb') as f:\n",
    "    pickle.dump(long_sequences_pitch, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the relevant pitches/durations so we can get the respective values from the prediction output vectors\n",
    "with open('pickles/pitches.pickle', 'wb') as f:\n",
    "    pickle.dump(pitches, f)\n",
    "\n",
    "with open('pickles/durations.pickle', 'wb') as f:\n",
    "    pickle.dump(durations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

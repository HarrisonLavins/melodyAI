{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import numpy as np\n",
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets and then split in to train/test data sets\n",
    "# this all has to be done at the same time to ensure that the durations/pitches are from the same samples\n",
    "with open(\"pickles/duration_X_train.pickle\", 'rb') as duration_x, open('pickles/duration_Y_train.pickle', 'rb') as duration_y,\\\n",
    "    open(\"pickles/pitch_X_train.pickle\", 'rb') as pitch_x, open('pickles/pitch_Y_train.pickle', 'rb') as pitch_y:\n",
    "    duration_X_train, duration_X_test, duration_Y_train, duration_Y_test,\\\n",
    "    pitch_X_train, pitch_X_test, pitch_Y_train, pitch_Y_test\\\n",
    "    = train_test_split(pickle.load(duration_x), pickle.load(duration_y),\\\n",
    "                       pickle.load(pitch_x), pickle.load(pitch_y), train_size=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the pitches and durations that were used to build the data set\n",
    "# these will be used to convert the output one-hot vectors back to actual pitch/duration values\n",
    "with open('pickles/durations.pickle', 'rb') as d, open('pickles/pitches.pickle', 'rb') as p:\n",
    "    durations = pickle.load(d)\n",
    "    pitches = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = duration_X_train.shape[0]  # applies to both pitch and duration data sets\n",
    "timesteps = duration_X_train.shape[1]  # applies to both pitch and duration data sets\n",
    "duration_num_features = duration_X_train.shape[2]\n",
    "pitch_num_features = pitch_X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single layer Unidirectional or Bidirectional LSTM; will easily allow us to test various configurations\n",
    "def getModel(t, num_features, bidirectional=True):\n",
    "    model = Sequential()\n",
    "    # only dif. betwn. bi. LSTM and uni. LSTM is the presence/absence of Bidirectional wrapper\n",
    "    # hidden layer 1; 20  units; input (# timesteps, # features); return a sequence of each time step's outputs\n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(LSTM(20, input_shape=(t, num_features), return_sequences=True)))\n",
    "    else:\n",
    "        model.add(LSTM(20, input_shape=(t, num_features), return_sequences=True))\n",
    "        \n",
    "    # TimeDistributed is a wrapper allowing one output per time step; \n",
    "    # ...requires hidden layer to have return_sequences == True\n",
    "    model.add(TimeDistributed(Dense(num_features, activation='softmax')))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'categorical_crossentropy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train LSTM\n",
    "def trainModel(model, X, Y, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        # generate new random sequence\n",
    "        # fit model for one epoch on this sequence\n",
    "        model.fit(X, Y, epochs=epochs, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_bidirectional = getModel(timesteps, duration_num_features, bidirectional=True)\n",
    "trainModel(duration_bidirectional, duration_X_train, duration_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_bidirectional = getModel(timesteps, pitch_num_features, bidirectional=True)\n",
    "trainModel(pitch_bidirectional, pitch_X_train, pitch_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict requires 3D vector, so this reshapes a 2D input to 3D so it can be fed through the network\n",
    "def to_3D(sample):\n",
    "    return sample.reshape(1, sample.shape[0], sample.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts output one-hot vectors to its respective quarter length value (based on durations seen in data set)\n",
    "def duration_one_hot_to_quarter_length(prediction):\n",
    "    new_durations = []\n",
    "    for timestep in prediction:\n",
    "        index = np.argmax(timestep)\n",
    "        new_durations.append(durations[index])\n",
    "    \n",
    "    return new_durations\n",
    "\n",
    "# converts output one-hot vectors to its respective MIDI pitch value (based on durations seen in data set)\n",
    "def pitch_one_hot_to_MIDI(prediction):\n",
    "    new_pitches = []\n",
    "    for timestep in prediction:\n",
    "        index = np.argmax(timestep)\n",
    "        new_pitches.append(pitches[index])\n",
    "    \n",
    "    return new_pitches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "duration_pred = duration_bidirectional.predict(to_3D(duration_X_test[0])).reshape(timesteps, duration_num_features)\n",
    "composed_durations = duration_one_hot_to_quarter_length(duration_pred)\n",
    "\n",
    "pitch_pred = pitch_bidirectional.predict(to_3D(pitch_X_test[0])).reshape(timesteps, pitch_num_features)\n",
    "composed_pitches = pitch_one_hot_to_MIDI(pitch_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_stream = stream.Stream()\n",
    "for pair in composed_pairs:\n",
    "    p = pitch.Pitch(midi=pair[0])\n",
    "    d = duration.Duration(pair[1])\n",
    "    n = note.Note()\n",
    "    n.pitch = p\n",
    "    n.duration = d\n",
    "    composed_stream.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "composed_stream.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Bidirectional, Lambda\n",
    "import numpy as np\n",
    "from music21 import *\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "TRAIN_MODELS = True  # whether the network should be retrained when running\n",
    "                     # (the alternative being to load in saved weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "with open(\"pickles/short_seqs_duration.pickle\", 'rb') as short_duration,\\\n",
    "     open(\"pickles/short_seqs_pitch.pickle\", 'rb') as short_pitch:\n",
    "    short_seqs_duration = pickle.load(short_duration)\n",
    "    short_seqs_pitch = pickle.load(short_pitch)\n",
    "\n",
    "with open(\"pickles/medium_seqs_duration.pickle\", 'rb') as medium_duration,\\\n",
    "     open(\"pickles/medium_seqs_pitch.pickle\", 'rb') as medium_pitch:\n",
    "    medium_seqs_duration = pickle.load(medium_duration)\n",
    "    medium_seqs_pitch = pickle.load(medium_pitch)\n",
    "    \n",
    "with open(\"pickles/long_seqs_duration.pickle\", 'rb') as long_duration,\\\n",
    "     open(\"pickles/long_seqs_pitch.pickle\", 'rb') as long_pitch:\n",
    "    long_seqs_duration = pickle.load(long_duration)\n",
    "    long_seqs_pitch = pickle.load(long_pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the pitches and durations that were used to build the data set\n",
    "with open('pickles/durations.pickle', 'rb') as d, open('pickles/pitches.pickle', 'rb') as p:\n",
    "    durations = pickle.load(d)\n",
    "    pitches = pickle.load(p)\n",
    "    \n",
    "# retrieve the mapping from pitch/duration values to one-hot vector indices\n",
    "with open('pickles/duration_indices.pickle', 'rb') as d, open('pickles/pitch_indices.pickle', 'rb') as p:\n",
    "    duration_indices = pickle.load(d)\n",
    "    pitch_indices = pickle.load(p)\n",
    "    \n",
    "num_durations = len(durations)\n",
    "num_pitches = len(pitches)\n",
    "short_seq_len = short_seqs_duration.shape[1]\n",
    "medium_seq_len = medium_seqs_duration.shape[1]\n",
    "long_seq_len = long_seqs_duration.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with how temperature affects a softmax distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "logits = np.array([1,2,3,4])\n",
    "logits_temp_p0 = logits / 0.01\n",
    "logits_temp_p2 = logits / 0.2\n",
    "logits_temp_p4 = logits / 0.4\n",
    "logits_temp_p6 = logits / 0.6\n",
    "logits_temp_p8 = logits / 0.8\n",
    "logits_temp_p10 = logits / 1.0\n",
    "logits_temp_p15 = logits / 1.5\n",
    "logits_temp_p150 = logits / 150\n",
    "\n",
    "print(f\"RAW: {softmax(logits)}\")\n",
    "print(f\"TEMP 0.0: {softmax(logits_temp_p0)}\")\n",
    "print(f\"TEMP 0.2: {softmax(logits_temp_p2)}\")\n",
    "print(f\"TEMP 0.4: {softmax(logits_temp_p4)}\")\n",
    "print(f\"TEMP 0.6: {softmax(logits_temp_p6)}\")\n",
    "print(f\"TEMP 0.8: {softmax(logits_temp_p8)}\")\n",
    "print(f\"TEMP 1.0: {softmax(logits_temp_p10)}\")\n",
    "print(f\"TEMP 1.5: {softmax(logits_temp_p15)}\")\n",
    "print(f\"TEMP 150: {softmax(logits_temp_p150)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a 1D vector (a single sam) and converts it to 3D for input to the network\n",
    "def timestep_to3d(x):\n",
    "    return np.reshape(x, (1, 1, x.shape[0]))\n",
    "\n",
    "# create one-hot vector representation for a time step given the index position of the encoded value\n",
    "def vectorize(index, vec_size):\n",
    "    index = int(index)\n",
    "    vec = np.zeros(vec_size, np.float32)\n",
    "    vec[index] = 1.0\n",
    "    return vec\n",
    "\n",
    "# returns the index of the one-hot encoded value\n",
    "def unvectorize(x):\n",
    "    return np.argmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single layer Unidirectional or Bidirectional LSTM; will easily allow us to test various configurations\n",
    "def get_model(num_features, lstm_cells=500, bidirectional=True, temperature=1.0, optimizer=\"adam\"):\n",
    "    model = Sequential()\n",
    "    # only dif. betwn. bi. LSTM and uni. LSTM is the presence/absence of Bidirectional wrapper\n",
    "    # hidden layer 1; 20  units; input (# timesteps, # features); return a sequence of each time step's outputs\n",
    "    # input_shape first value None makes it variable (we don't have fixed length sequences)\n",
    "    # output of LSTM cell uses tanh activation, recurrent connections use sigmoid\n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(LSTM(lstm_cells, input_shape=(None, num_features), return_sequences=True)))\n",
    "    else:\n",
    "        model.add(LSTM(lstm_cells, input_shape=(None, num_features), return_sequences=True))\n",
    "        \n",
    "    # so that we can divibe by temperature before feeding through softmax\n",
    "    model.add(Lambda(lambda x: x / temperature))\n",
    "        \n",
    "    # TimeDistributed is a wrapper allowing one output per time step; \n",
    "    # ...requires hidden layer to have return_sequences == True\n",
    "    model.add(TimeDistributed(Dense(num_features, activation='softmax')))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', 'categorical_crossentropy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train LSTM\n",
    "def train_model(model, X, bidirectional=True, epochs=15, batch_size=32, verbose=1):\n",
    "    Y = deepcopy(X)\n",
    "    if not bidirectional:\n",
    "        X = X[0:-1] # do not input the final time step in unidirectional LSTM\n",
    "        Y = Y[1:] # labels include all time steps but the first one in unidir. LSTM\n",
    "    model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composing with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a single index from a sample of a softmax distribution vector\n",
    "def sample_distribution(dist_vec, num_categories):\n",
    "    return tf.random.categorical(dist_vec.reshape(1, num_categories), 1).numpy().flatten()[0]\n",
    "\n",
    "# use the trained model to compose new music by feeding in a single input and desired length\n",
    "def compose(pitch_model, duration_model, pitch_prompt, duration_prompt, length=50):\n",
    "    '''pitch_model: the trained model for pitch predictions\n",
    "       duration_model: trained model for duration predictions\n",
    "       pitch_prompt: the first pitch of the piece (index of the one-hot encoded pitch vector)\n",
    "       duration_prompt: the first duration of the piece (index of the one-hot encoded duration vector)\n",
    "       length: how many time steps to generate for\n",
    "       \n",
    "       returns a music21.stream.Stream object representing the composition\n",
    "    '''    \n",
    "    # the lists that hold the indices of the values to index in to pitches/durations lists\n",
    "    generated_pitches, generated_durations = [pitch_prompt], [duration_prompt]\n",
    "    \n",
    "    current_pitch, current_duration = pitch_prompt, duration_prompt\n",
    "    for t in range(length):\n",
    "        # model only accepts 3D inputs\n",
    "        pitch_vec = timestep_to3d(vectorize(current_pitch, num_pitches))\n",
    "        duration_vec = timestep_to3d(vectorize(current_duration, num_durations))\n",
    "        \n",
    "        # predict the output distributions\n",
    "        pitch_pred = pitch_model.predict(pitch_vec)\n",
    "        duration_pred = duration_model.predict(duration_vec)\n",
    "        # sample the distributions (returns the index of the one-hot vectors)\n",
    "        next_pitch = sample_distribution(pitch_pred, num_pitches)\n",
    "        print(f'Sampled pitch index {next_pitch}: MIDI no. {pitches[next_pitch]}')\n",
    "        next_duration = sample_distribution(duration_pred, num_durations)\n",
    "        print(f'Sampled duration index {next_duration}: quarter length {durations[next_duration]}')\n",
    "        generated_pitches.append(next_pitch)\n",
    "        generated_durations.append(next_duration)\n",
    "        \n",
    "        # get ready for next iteration\n",
    "        current_pitch, current_duration = next_pitch, next_duration\n",
    "        \n",
    "    \n",
    "    composed_stream = stream.Stream()\n",
    "    for pair in list(zip(generated_pitches, generated_durations)):\n",
    "        p = pitch.Pitch(midi=pitches[pair[0]])\n",
    "        d = duration.Duration(durations[pair[1]])\n",
    "        n = note.Note()\n",
    "        n.pitch = p\n",
    "        n.duration = d\n",
    "        composed_stream.append(n)\n",
    "    \n",
    "    return composed_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train(pitch_train, duration_train, bidirectional=True, temperature=1.0, optimizer=\"adam\", num_layers=20,\\\n",
    "                       epochs=15, batch_size=32, validation_split=0.0, verbose=1):\n",
    "    pitch_model = get_model(bidirectional=bidirectional, temperature=temperature, optimizer=optimizer, num_layers=num_layers)\n",
    "    duration_model = get_model(bidirectional=bidirectional, temperature=temperature, optimizer=optimizer, num_layers=num_layers)\n",
    "    train_model(pitch_train, duration_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split, verbose=verbose)\n",
    "    return compose(pitch_model, duration_model, pitch_seed, duration_seed, length=composition_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bidirectional_vals = [True, False]\n",
    "lstm_cell_vals = [500, 1000, 2000]\n",
    "temperature_vals = [0.2, 0.5, 1.0, 10.0]\n",
    "epoch_batch_vals = [(1, 1), (5, 8), (10, 16), (30, 32)] # [(epochs, batch_size), ...]\n",
    "\n",
    "# generate sets of parameters on which to build/train models for testing purposes\n",
    "def generate_param_sets():\n",
    "    sets = []\n",
    "    for bidirectional in bidirectional_vals:\n",
    "        for lstm_cells in lstm_cell_vals:\n",
    "            for temperature in temperature_vals:\n",
    "                for epochs, batch_size in epoch_batch_vals:\n",
    "                    s = {\n",
    "                        \"bidirectional\": bidirectional,\n",
    "                        \"lstm_cells\": lstm_cells,\n",
    "                        \"temperature\": temperature,\n",
    "                        \"epochs\": epochs,\n",
    "                        \"batch_size\": batch_size\n",
    "                    }\n",
    "                    sets.append(s)\n",
    "                    \n",
    "    return sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetadataModel(self):\n",
    "    def __init__(model, bidirectional):\n",
    "        self.model = model\n",
    "        self.bidirectional = bidirectional\n",
    "        self.trained = False\n",
    "        self._training_duration = -1\n",
    "    \n",
    "    @property\n",
    "    def name():\n",
    "        pass # TODO\n",
    "    \n",
    "    @property\n",
    "    def training_duration():\n",
    "        if not self.trained:\n",
    "            raise Exception(\"Model has not been trained yet\")\n",
    "        # https://stackoverflow.com/questions/21633579/python-time-math\n",
    "    \n",
    "        \n",
    "            \n",
    "    \n",
    "    def train(X, epochs, batch_size, verbose=0):\n",
    "        start_time = time.time()\n",
    "        train_model(self.model, X, self.bidirectional, epochs, batch_size, verbose)\n",
    "        end_time = time.time()\n",
    "        self.trained = True\n",
    "        self._training_duration = end_time - start_time\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    param_sets = generate_param_sets()\n",
    "    models = [] # [(name, model), ...]\n",
    "    \n",
    "    for params in param_sets:\n",
    "        bidirectional = params[\"bidirectional\"]\n",
    "        lstm_cells = params[\"lstm_cells\"]\n",
    "        temperature = params[\"temperature\"]\n",
    "        epochs = params[\"epochs\"]\n",
    "        batch_size = params[\"batch_size\"]\n",
    "        \n",
    "        pitch_model = get_model()\n",
    "        \n",
    "        \n",
    "    start_time = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_model = get_model(num_pitches, num_layers=1024)\n",
    "duration_model = get_model(num_durations, num_layers=1024)\n",
    "\n",
    "train_model(duration_model, short_seqs_duration, epochs=10)\n",
    "train_model(duration_model, medium_seqs_duration, epochs=10)\n",
    "train_model(duration_model, long_seqs_duration, epochs=10)\n",
    "\n",
    "train_model(pitch_model, short_seqs_pitch, epochs=10)\n",
    "train_model(pitch_model, medium_seqs_pitch, epochs=10)\n",
    "train_model(pitch_model, long_seqs_pitch, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece = compose(pitch_model, duration_model, 26, 1, length=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "piece.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_model.save('models/pitch_test.h5')\n",
    "duration_model.save('models/duration_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreated_pitch = keras.models.load_model('models/pitch_test.h5')\n",
    "recreated_duration = keras.models.load_model('models/duration_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece = compose(recreated_pitch, recreated_duration, 38, 4, length=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "piece.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

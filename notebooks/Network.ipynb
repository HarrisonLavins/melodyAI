{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Bidirectional, Lambda\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "from music21 import *\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "MODELS_DIRECTORY = '../models'\n",
    "if not os.path.exists(MODELS_DIRECTORY):\n",
    "    os.makedirs(MODELS_DIRECTORY)\n",
    "PICKLES_DIRECTORY = 'pickles'\n",
    "if not os.path.exists(PICKLES_DIRECTORY):\n",
    "    os.makedirs(PICKLES_DIRECTORY)\n",
    "COMPOSITIONS_DIRECTORY = '../outputs/compositions'\n",
    "if not os.path.exists(COMPOSITIONS_DIRECTORY):\n",
    "    os.makedirs(COMPOSITIONS_DIRECTORY)\n",
    "TENSORBOARD_LOGS_DIRECTORY = '../tensorboard_logs'\n",
    "if not os.path.exists(TENSORBOARD_LOGS_DIRECTORY):\n",
    "    os.makedirs(TENSORBOARD_LOGS_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "with open(f\"{PICKLES_DIRECTORY}/short_seqs_duration.pickle\", 'rb') as short_duration,\\\n",
    "     open(f\"{PICKLES_DIRECTORY}/short_seqs_pitch.pickle\", 'rb') as short_pitch:\n",
    "    short_seqs_duration = pickle.load(short_duration)\n",
    "    short_seqs_pitch = pickle.load(short_pitch)\n",
    "\n",
    "with open(f\"{PICKLES_DIRECTORY}/medium_seqs_duration.pickle\", 'rb') as medium_duration,\\\n",
    "     open(f\"{PICKLES_DIRECTORY}/medium_seqs_pitch.pickle\", 'rb') as medium_pitch:\n",
    "    medium_seqs_duration = pickle.load(medium_duration)\n",
    "    medium_seqs_pitch = pickle.load(medium_pitch)\n",
    "    \n",
    "with open(f\"{PICKLES_DIRECTORY}/long_seqs_duration.pickle\", 'rb') as long_duration,\\\n",
    "     open(f\"{PICKLES_DIRECTORY}/long_seqs_pitch.pickle\", 'rb') as long_pitch:\n",
    "    long_seqs_duration = pickle.load(long_duration)\n",
    "    long_seqs_pitch = pickle.load(long_pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the pitches and durations that were used to build the data set\n",
    "with open(f'{PICKLES_DIRECTORY}/durations.pickle', 'rb') as d, open(f'{PICKLES_DIRECTORY}/pitches.pickle', 'rb') as p:\n",
    "    durations = pickle.load(d)\n",
    "    pitches = pickle.load(p)\n",
    "    \n",
    "# retrieve the mapping from pitch/duration values to one-hot vector indices\n",
    "with open(f'{PICKLES_DIRECTORY}/duration_indices.pickle', 'rb') as d, open(f'{PICKLES_DIRECTORY}/pitch_indices.pickle', 'rb') as p:\n",
    "    duration_indices = pickle.load(d)\n",
    "    pitch_indices = pickle.load(p)\n",
    "    \n",
    "# retrieve the likelihood of starting with a given pitch/duration\n",
    "# these are used in sampling to find the starting pitch/duration of each composition\n",
    "with open(f'{PICKLES_DIRECTORY}/starting_pitch_likelihood.pickle', 'rb') as p, open(f'{PICKLES_DIRECTORY}/starting_duration_likelihood.pickle', 'rb') as d:\n",
    "    starting_pitch_likelihood = pickle.load(p)\n",
    "    starting_duration_likelihood = pickle.load(d)\n",
    "    \n",
    "num_durations = len(durations)\n",
    "num_pitches = len(pitches)\n",
    "short_seq_len = short_seqs_duration.shape[1]\n",
    "medium_seq_len = medium_seqs_duration.shape[1]\n",
    "long_seq_len = long_seqs_duration.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with how temperature affects a softmax distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW: [0.0320586  0.08714432 0.23688282 0.64391426]\n",
      "TEMP 0.0: [5.14820022e-131 1.38389653e-087 3.72007598e-044 1.00000000e+000]\n",
      "TEMP 0.2: [3.03841168e-07 4.50940275e-05 6.69254708e-03 9.93262055e-01]\n",
      "TEMP 0.4: [5.07707490e-04 6.18514343e-03 7.53504725e-02 9.17956677e-01]\n",
      "TEMP 0.6: [0.00547228 0.02897292 0.15339683 0.81215798]\n",
      "TEMP 0.8: [0.01689363 0.05896455 0.20580651 0.71833531]\n",
      "TEMP 1.0: [0.0320586  0.08714432 0.23688282 0.64391426]\n",
      "TEMP 1.5: [0.07076911 0.13783941 0.26847452 0.52291696]\n",
      "TEMP 150: [0.24750558 0.24916113 0.25082776 0.25250553]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Simply performs the softmax operation on an input vector.\n",
    "    \n",
    "    Parameters:\n",
    "        x: a vector of logits.\n",
    "        \n",
    "    Returns: \n",
    "        np.array: array representing the softmax distribution of the input logits.\n",
    "    \"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "logits = np.array([1,2,3,4])\n",
    "logits_temp_p0 = logits / 0.01\n",
    "logits_temp_p2 = logits / 0.2\n",
    "logits_temp_p4 = logits / 0.4\n",
    "logits_temp_p6 = logits / 0.6\n",
    "logits_temp_p8 = logits / 0.8\n",
    "logits_temp_p10 = logits / 1.0\n",
    "logits_temp_p15 = logits / 1.5\n",
    "logits_temp_p150 = logits / 150\n",
    "\n",
    "print(f\"RAW: {softmax(logits)}\")\n",
    "print(f\"TEMP 0.0: {softmax(logits_temp_p0)}\")\n",
    "print(f\"TEMP 0.2: {softmax(logits_temp_p2)}\")\n",
    "print(f\"TEMP 0.4: {softmax(logits_temp_p4)}\")\n",
    "print(f\"TEMP 0.6: {softmax(logits_temp_p6)}\")\n",
    "print(f\"TEMP 0.8: {softmax(logits_temp_p8)}\")\n",
    "print(f\"TEMP 1.0: {softmax(logits_temp_p10)}\")\n",
    "print(f\"TEMP 1.5: {softmax(logits_temp_p15)}\")\n",
    "print(f\"TEMP 150: {softmax(logits_temp_p150)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestep_to3d(x):\n",
    "    \"\"\"\n",
    "    Takes a 1D vector (a vector representing a single timestep) and converts it to a 3D vector (which is required by an LSTM network).\n",
    "    \n",
    "    Parameters:\n",
    "        x: a 1D vector which is the one-hot encoding of a value at a single timestep.\n",
    "        \n",
    "    Returns: \n",
    "        np.array: a 3D vector corresponding to a one-hot encoding of a single timestep.\n",
    "    \"\"\"\n",
    "    return np.reshape(x, (1, 1, x.shape[0]))\n",
    "\n",
    "\n",
    "def vectorize(index, vec_size):\n",
    "    \"\"\"\n",
    "    Creates a one-hot vector representation for a single time step given the index position of the value to encode.\n",
    "    \n",
    "    Parameters:\n",
    "        index: the index of the returned vector which should be set to 1.\n",
    "        vec_size: how large the returned vector should be (how many possible values for the feature).\n",
    "        \n",
    "    Returns: \n",
    "        np.array: a 1D array which is the resulting one-hot encoding of a value at a single time step.\n",
    "    \"\"\"\n",
    "    index = int(index)\n",
    "    vec = np.zeros(vec_size, np.float32)\n",
    "    vec[index] = 1.0\n",
    "    return vec\n",
    "\n",
    "\n",
    "def unvectorize(x):\n",
    "    \"\"\"\n",
    "    Returns the index of the one-hot encoded value.\n",
    "    This works because only one value will be nonzero in a vector, so argmax will return this index of the encoded value.\n",
    "    \n",
    "    Parameters:\n",
    "        x: a one-hot encoded vector.\n",
    "        \n",
    "    Returns: \n",
    "        integer: an index corresponding to the values which is encoded by the vector.\n",
    "    \"\"\"\n",
    "    return np.argmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single layer Unidirectional or Bidirectional LSTM; will easily allow us to test various configurations\n",
    "def get_model(num_values, lstm_cells=500, bidirectional=True, temperature=1.0, optimizer=\"adam\"):\n",
    "    \"\"\"\n",
    "    Creates and compiles the LSTM model.\n",
    "    \n",
    "    Parameters:\n",
    "        num_values (int): The size of the one-hot vector at a time step.\n",
    "        lstm_cells (int): The number of LSTM cells in the model.\n",
    "        bidirectional (boolean): Whether to construct a bidirectional LSTM (as opposed to unidirectional).\n",
    "        temperature (float): Value by the Lambda layer to divide output logits by.\n",
    "        optimizer (string | tf.keras.optimizers.Optimizer): Which optimization algorith to use.\n",
    "        \n",
    "    Returns:\n",
    "        tf.keras.Model: A compiled LSTM model.\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    # only dif. betwn. bi. LSTM and uni. LSTM is the presence/absence of Bidirectional wrapper\n",
    "    # hidden layer 1; 20  units; input (# timesteps, # features); return a sequence of each time step's outputs\n",
    "    # input_shape first value None makes it variable (we don't have fixed length sequences)\n",
    "    # output of LSTM cell uses tanh activation, recurrent connections use sigmoid\n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(LSTM(lstm_cells, input_shape=(None, num_values), return_sequences=True)))\n",
    "    else:\n",
    "        model.add(LSTM(lstm_cells, input_shape=(None, num_values), return_sequences=True))\n",
    "        \n",
    "    # so that we can divibe by temperature before feeding through softmax\n",
    "    model.add(Lambda(lambda x: x / temperature))\n",
    "        \n",
    "    # TimeDistributed is a wrapper allowing one output per time step; \n",
    "    # ...requires hidden layer to have return_sequences == True\n",
    "    model.add(TimeDistributed(Dense(num_values, activation='softmax')))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', 'categorical_crossentropy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X, bidirectional=True, epochs=15, batch_size=32, verbose=1, model_name='null_name'):\n",
    "    \"\"\"\n",
    "    Trains an LSTM model.\n",
    "    \n",
    "    Parameters:\n",
    "        model (tf.keras.Model): The model which is to be trained.\n",
    "        X (np.array): A 3D vector (samples, timesteps, values) to train the network on.\n",
    "        bidirectional (boolean): Indicates whether the model is a bidirectional.\n",
    "        epochs (int): The number of epochs over which to train the model.\n",
    "        batch_size (int): The number of samples tito show the odel before updating weights.\n",
    "        verbose (int): The amount of information to print while training.\n",
    "        \n",
    "        Returns: None\n",
    "    \"\"\"\n",
    "    \n",
    "    #Initialize TensorBoard object for logging\n",
    "    tensorboard = TensorBoard(log_dir=f'../tensorboard_logs/{model_name}')\n",
    "    \n",
    "    Y = deepcopy(X)\n",
    "    if not bidirectional:\n",
    "        X = X[0:-1] # do not input the final time step in unidirectional LSTM\n",
    "        Y = Y[1:] # labels include all time steps but the first one in unidir. LSTM\n",
    "    model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=verbose, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composing with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_distribution(dist_vec, num_categories):\n",
    "    \"\"\"\n",
    "    Sample a softmax distribution vector.\n",
    "    \n",
    "    Parameters:\n",
    "        dist_vec (np.array): A logit vector from which to take a sample from.\n",
    "        num_categories (int): Number of categories to sample from (used for reshaping).\n",
    "        \n",
    "    Returns:\n",
    "        int: The index of the output value which was sampled.\n",
    "    \"\"\"\n",
    "    return tf.random.categorical(dist_vec.reshape(1, num_categories), 1).numpy().flatten()[0]\n",
    "\n",
    "def compose(pitch_model, duration_model, pitch_prompt, duration_prompt, length=50):\n",
    "    '''\n",
    "    Composes a piece of music (in the format of a music21.stream.Stream object).\n",
    "    \n",
    "    Arguments:\n",
    "        pitch_model (tf.keras.Model): The trained model for pitch predictions.\n",
    "        duration_model (tf.keras.Model): The trained model for duration predictions.\n",
    "        pitch_prompt (int): The first pitch of the piece (index of the one-hot encoded pitch vector).\n",
    "        duration_prompt (int): The first duration of the piece (index of the one-hot encoded duration vector).\n",
    "        length (int): How many time steps to generate.\n",
    "       \n",
    "       Returns:\n",
    "           music21.stream.Stream(): The composed piece.\n",
    "    '''    \n",
    "    \n",
    "    # the lists that hold the indices of the values to index in to pitches/durations lists\n",
    "    generated_pitches, generated_durations = [pitch_prompt], [duration_prompt]\n",
    "    \n",
    "    current_pitch, current_duration = pitch_prompt, duration_prompt\n",
    "    for t in range(length):\n",
    "        # model only accepts 3D inputs\n",
    "        pitch_vec = timestep_to3d(vectorize(current_pitch, num_pitches))\n",
    "        duration_vec = timestep_to3d(vectorize(current_duration, num_durations))\n",
    "        \n",
    "        # predict the output distributions\n",
    "        pitch_pred = pitch_model.predict(pitch_vec)\n",
    "        duration_pred = duration_model.predict(duration_vec)\n",
    "        # sample the distributions (returns the index of the one-hot vectors)\n",
    "        next_pitch = sample_distribution(pitch_pred, num_pitches)\n",
    "        next_duration = sample_distribution(duration_pred, num_durations)\n",
    "        generated_pitches.append(next_pitch)\n",
    "        generated_durations.append(next_duration)\n",
    "        \n",
    "        # get ready for next iteration\n",
    "        current_pitch, current_duration = next_pitch, next_duration\n",
    "        \n",
    "    \n",
    "    composed_stream = stream.Stream()\n",
    "    for pair in list(zip(generated_pitches, generated_durations)):\n",
    "        p = pitch.Pitch(midi=pitches[pair[0]])\n",
    "        d = duration.Duration(durations[pair[1]])\n",
    "        n = note.Note()\n",
    "        n.pitch = p\n",
    "        n.duration = d\n",
    "        composed_stream.append(n)\n",
    "    \n",
    "    return composed_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bidirectional_vals = [True, False]\n",
    "lstm_cell_vals = [500, 1000, 2000]\n",
    "temperature_vals = [0.2, 0.5, 1.0, 10.0]\n",
    "epoch_batch_vals = [(1, 1), (5, 8), (10, 16), (30, 32)] # [(epochs, batch_size), ...]\n",
    "\n",
    "def generate_param_sets(start=None, end=None):\n",
    "    \"\"\"\n",
    "    Creates sets of possible parameter combinations that will be tested over.\n",
    "    Optionally allows to pass in indices to return a sub set of param sets in case training in to be done at separate times.\n",
    "    \n",
    "    Parameters:\n",
    "        start (integer): The starting index of the range of sets to return from all possible sets.\n",
    "        end (int): The ending index (inclusive) of the renage of sets to return from all possible sets.\n",
    "        *NOTE that start and end must either both be None or integers; only suppling one argument causes an exception to be raised.\n",
    "    \"\"\"\n",
    "#     if boolean(start is None) ^ boolean(end is None):  # ^ is XOR; must pass either no arguments or both\n",
    "#         raise ValueError('Must pass no optional arguments or both optional arguments; received one')\n",
    "        \n",
    "    sets = []\n",
    "    for bidirectional in bidirectional_vals:\n",
    "        for lstm_cells in lstm_cell_vals:\n",
    "            for temperature in temperature_vals:\n",
    "                for epochs, batch_size in epoch_batch_vals:\n",
    "                    s = {\n",
    "                        \"bidirectional\": bidirectional,\n",
    "                        \"lstm_cells\": lstm_cells,\n",
    "                        \"temperature\": temperature,\n",
    "                        \"epochs\": epochs,\n",
    "                        \"batch_size\": batch_size\n",
    "                    }\n",
    "                    sets.append(s)\n",
    "                    \n",
    "    if start is None and end is None:\n",
    "        return sets\n",
    "    else:\n",
    "        return sets[start:end+1] # make end index inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetadataModel:\n",
    "    \"\"\"\n",
    "    A wrapper class for LSTM models that is used to gather metadata from training.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_features, lstm_cells, bidirectional, temperature, epochs,\\\n",
    "                 batch_size, verbose=0, id=None):\n",
    "        self._model = get_model(num_features, lstm_cells, bidirectional, temperature)\n",
    "        self._num_features = num_features\n",
    "        self._lstm_cells = lstm_cells\n",
    "        self._bidirectional = bidirectional\n",
    "        self._temperature = temperature\n",
    "        self._epochs = epochs\n",
    "        self._batch_size = batch_size\n",
    "        self.verbose = verbose # no underscore because this should be mutable\n",
    "        self._name = '_'.join([str(bidirectional), str(lstm_cells), str(temperature), str(epochs), str(batch_size)])\n",
    "        if id is not None:\n",
    "            self.name += f\"_{id}\"\n",
    "        self._total_training_time = 0.0 # in seconds\n",
    "    \n",
    "    # ---- setting properties so that these attributes are immutable ----\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    \n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "        \n",
    "    @property\n",
    "    def num_features(self):\n",
    "        return self._num_features\n",
    "    \n",
    "    @property\n",
    "    def lstm_cells(self):\n",
    "        return self._lstm_cells\n",
    "    \n",
    "    @property\n",
    "    def bidirectional(self):\n",
    "        return self._bidirectional\n",
    "    \n",
    "    @property\n",
    "    def temperature(self):\n",
    "        return self._temperature\n",
    "    \n",
    "    @property\n",
    "    def epochs(self):\n",
    "        return self._epochs\n",
    "    \n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self._batch_size\n",
    "        \n",
    "    # returns a string version of training time\n",
    "    @property\n",
    "    def training_duration(self):\n",
    "        total_time = self._total_training_time\n",
    "        hours = int(total_time // 3600)  # 3600 seconds/hour\n",
    "        minutes = int((total_time - (3600 * hours)) // 60) # subtract the hours from remaining time; 60 sec/min\n",
    "        seconds = (total_time - (3600 * hours)) - (60 * minutes)\n",
    "        return \"{}h {}m {:.2f}s\".format(hours, minutes, seconds)\n",
    "    \n",
    "    \n",
    "            \n",
    "    def train(self, X):\n",
    "        start_time = time.time()\n",
    "        train_model(self.model, X, self.bidirectional, self.epochs, self.batch_size, self.verbose, self.name)\n",
    "        end_time = time.time()\n",
    "        self._total_training_time += end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_start_pitch():\n",
    "    \"\"\"\n",
    "    Sample from the dictionary containing the probabilities of starting a piece with a given pitch.\n",
    "    \n",
    "    Parameters:\n",
    "        dictionary (dict(int: float)): The dictionary whose values are probabilities, and whose keys are the MIDI pitch.\n",
    "                                       This dictionary must be sorted by key.\n",
    "        \n",
    "    Returns:\n",
    "        int: The index of the MIDI pitch in the pitches list.\n",
    "    \"\"\"\n",
    "    logits = np.array(list(starting_pitch_likelihood.values()))\n",
    "    return np.argmax(np.random.multinomial(1, logits))\n",
    "    \n",
    "def sample_start_duration():\n",
    "    \"\"\"\n",
    "    Sample from the dictionary containing the probabilities of starting a piece with a given duration.\n",
    "    \n",
    "    Parameters:\n",
    "        dictionary (dict(float: float)): The dictionary whose values are probabilities, and whose keys are the quarter length duration.\n",
    "                                         This dictionary must be sorted by key.\n",
    "        \n",
    "    Returns:\n",
    "        np.array: The index of the sampled duration in the durations list.\n",
    "    \"\"\"\n",
    "    logits = np.array(list(starting_duration_likelihood.values()))\n",
    "    return np.argmax(np.random.multinomial(1, logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests(pitch_short, pitch_medium, pitch_long, duration_short, duration_medium, duration_long,\\\n",
    "              num_compositions=5, verbose=0):\n",
    "    \"\"\"\n",
    "    Creates, trains, and composes with networks of a multitude of parameter combinations.\n",
    "    \n",
    "    Parameters:\n",
    "        pitch_short (np.array): The short pitch sequences.\n",
    "        pitch_medium (np.array): The medium pitch sequences.\n",
    "        pitch_long (np.array): The long pitch sequences.\n",
    "        duration_short (np.array): The short duration sequences.\n",
    "        duration_medium (np.array): The medium duration sequences.\n",
    "        duration_long (np.array): The long duration sequences.\n",
    "        num_compositions (int): How many pieces to compose for each model being tested.\n",
    "        verbose (int): The amount of information to print throughout the test.\n",
    "        \n",
    "        Returns: None\n",
    "    \"\"\"\n",
    "    \n",
    "    param_sets = generate_param_sets(start=0, end=2) #determine which set of parameters to use in model\n",
    "    pitch_models, duration_models = [], []\n",
    "    model_no = 1 # which iteration of model we are on\n",
    "    if not os.path.exists(\"models\"):\n",
    "            os.mkdir(\"models\")\n",
    "            \n",
    "    test_start_time=time.time()            \n",
    "    for params in param_sets:\n",
    "        bidirectional = params[\"bidirectional\"]\n",
    "        lstm_cells = params[\"lstm_cells\"]\n",
    "        temperature = params[\"temperature\"]\n",
    "        epochs = params[\"epochs\"]\n",
    "        batch_size = params[\"batch_size\"]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Model {model_no}:\\n\\tbidirectional – {bidirectional}\\n\\tlstm cells – {lstm_cells}\\\n",
    "            \\n\\ttemperature – {temperature}\\n\\tepochs – {epochs}\\n\\tbatch size – {batch_size}\")\n",
    "        \n",
    "        pitch_model = MetadataModel(num_pitches, lstm_cells, bidirectional, temperature, epochs, batch_size, verbose)\n",
    "        duration_model = MetadataModel(num_durations, lstm_cells, bidirectional, temperature, epochs, batch_size, verbose)\n",
    "        \n",
    "        # train the pitch network\n",
    "        if verbose:\n",
    "            print('\\n\\tTraining pitch generation network...')\n",
    "            print('\\t\\tOn short data set:')\n",
    "        pitch_model.train(pitch_short)\n",
    "        if verbose:\n",
    "            print('\\t\\tOn medium data set:')\n",
    "        pitch_model.train(pitch_medium)\n",
    "        if verbose:\n",
    "            print('\\t\\tOn long data set:')\n",
    "        pitch_model.train(pitch_long)\n",
    "        pitch_model.model.save(f\"{MODELS_DIRECTORY}/{model_no}_pitch_{pitch_model.name}.h5\")\n",
    "        if verbose:\n",
    "            print(f\"\\t\\tPitch model training complete: saved at {MODELS_DIRECTORY}/{model_no}_pitch_{pitch_model.name}.h5\")\n",
    "            print(f\"\\tTotal training time: {pitch_model.training_duration}'\")\n",
    "        \n",
    "        # train the duration network\n",
    "        if verbose:\n",
    "            print('\\n\\tTraining rhythm (duration) generation network...')\n",
    "            print('\\t\\tOn short data set:')\n",
    "        duration_model.train(duration_short)\n",
    "        if verbose:\n",
    "            print('\\t\\tOn medium data set:')\n",
    "        duration_model.train(duration_medium)\n",
    "        if verbose:\n",
    "            print('\\t\\tOn long data set:')\n",
    "        duration_model.train(duration_long)\n",
    "        duration_model.model.save(f\"{MODELS_DIRECTORY}/{model_no}_duration_{duration_model.name}.h5\")\n",
    "        if verbose:\n",
    "            print(f\"\\t\\tPitch model training complete: saved at {MODELS_DIRECTORY}/{model_no}_duration_{duration_model.name}.h5\")\n",
    "            print(f\"\\tTotal training time: {duration_model.training_duration}'\")\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'\\tModel {model_no} training complete')\n",
    "            print(f'\\t\\tTotal time to train pitch and duration models: {duration_model.training_duration + pitch_model.training_duration}')\n",
    "        \n",
    "        # compose outputs and save them\n",
    "        if not os.path.exists(f\"{COMPOSITIONS_DIRECTORY}/model_no_{model_no}\"):\n",
    "            os.makedirs(f\"{COMPOSITIONS_DIRECTORY}/model_no_{model_no}\")\n",
    "        comp_count = 1\n",
    "        for c in range(num_compositions):\n",
    "            pitch_prompt = sample_start_pitch()\n",
    "            duration_prompt = sample_start_duration()\n",
    "            composition = compose(pitch_model.model, duration_model.model, pitch_prompt, duration_prompt, length=100)\n",
    "            composition.write('musicxml', f'composition_{comp_count}.mxl')\n",
    "            composition.write('midi', f'composition_{comp_count}.mid')\n",
    "            \n",
    "        model_no = model_no + 1\n",
    "        print('–' * 50 + \"\\n\\n\")\n",
    "        \n",
    "        \n",
    "    test_end_time=time.time()\n",
    "    total_time = test_end_time - test_start_time\n",
    "    hours = int(total_time // 3600)  # 3600 seconds/hour\n",
    "    minutes = int((total_time - (3600 * hours)) // 60) # subtract the hours from remaining time; 60 sec/min\n",
    "    seconds = (total_time - (3600 * hours)) - (60 * minutes)\n",
    "    print(f\"TRAINING COMPLETE – elapsed time: {hours}h {minutes}m {seconds}s\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1:\n",
      "\tbidirectional – True\n",
      "\tlstm cells – 500            \n",
      "\ttemperature – 0.2\n",
      "\tepochs – 1\n",
      "\tbatch size – 1\n",
      "\n",
      "\tTraining pitch generation network...\n",
      "\t\tOn short data set:\n",
      "Train on 1668 samples\n",
      "1668/1668 [==============================] - 869s 521ms/sample - loss: 0.1311 - accuracy: 0.8772 - categorical_crossentropy: 0.1311\n",
      "\t\tOn medium data set:\n",
      "Train on 972 samples\n",
      "972/972 [==============================] - 602s 619ms/sample - loss: 0.0038 - accuracy: 0.8998 - categorical_crossentropy: 0.0038\n",
      "\t\tOn long data set:\n",
      "Train on 612 samples\n",
      "612/612 [==============================] - 413s 675ms/sample - loss: 0.0072 - accuracy: 0.8995 - categorical_crossentropy: 0.0072\n",
      "\t\tPitch model training complete: saved at ../models/1_pitch_True_500_0.2_1_1.h5\n",
      "\tTotal training time: 0h 31m 32.78s'\n",
      "\n",
      "\tTraining rhythm (duration) generation network...\n",
      "\t\tOn short data set:\n",
      "Train on 1668 samples\n",
      "1668/1668 [==============================] - 765s 458ms/sample - loss: 0.0207 - accuracy: 0.9101 - categorical_crossentropy: 0.0207\n",
      "\t\tOn medium data set:\n",
      "Train on 972 samples\n",
      "972/972 [==============================] - 545s 561ms/sample - loss: 7.0686e-05 - accuracy: 0.9093 - categorical_crossentropy: 7.0686e-05\n",
      "\t\tOn long data set:\n",
      "Train on 612 samples\n",
      "612/612 [==============================] - 416s 679ms/sample - loss: 0.0012 - accuracy: 0.9333 - categorical_crossentropy: 0.0012\n",
      "\t\tPitch model training complete: saved at ../models/1_duration_True_500_0.2_1_1.h5\n",
      "\tTotal training time: 0h 28m 54.85s'\n",
      "\tModel 1 training complete\n",
      "\t\tTotal time to train pitch and duration models: 0h 28m 54.85s0h 31m 32.78s\n",
      "––––––––––––––––––––––––––––––––––––––––––––––––––\n",
      "\n",
      "\n",
      "Model 2:\n",
      "\tbidirectional – True\n",
      "\tlstm cells – 500            \n",
      "\ttemperature – 0.2\n",
      "\tepochs – 5\n",
      "\tbatch size – 8\n",
      "\n",
      "\tTraining pitch generation network...\n",
      "\t\tOn short data set:\n",
      "Train on 1668 samples\n",
      "Epoch 1/5\n",
      "1668/1668 [==============================] - 117s 70ms/sample - loss: 0.4157 - accuracy: 0.8100 - categorical_crossentropy: 0.4157\n",
      "Epoch 2/5\n",
      "1668/1668 [==============================] - 113s 68ms/sample - loss: 0.0103 - accuracy: 0.9027 - categorical_crossentropy: 0.0103\n",
      "Epoch 3/5\n",
      "1668/1668 [==============================] - 114s 68ms/sample - loss: 0.0049 - accuracy: 0.9032 - categorical_crossentropy: 0.0049\n",
      "Epoch 4/5\n",
      "1668/1668 [==============================] - 110s 66ms/sample - loss: 0.0030 - accuracy: 0.9035 - categorical_crossentropy: 0.0030\n",
      "Epoch 5/5\n",
      "1668/1668 [==============================] - 110s 66ms/sample - loss: 0.0018 - accuracy: 0.9037 - categorical_crossentropy: 0.0018\n",
      "\t\tOn medium data set:\n",
      "Train on 972 samples\n",
      "Epoch 1/5\n",
      "972/972 [==============================] - 84s 87ms/sample - loss: 4.4926e-04 - accuracy: 0.9006 - categorical_crossentropy: 4.4926e-04\n",
      "Epoch 2/5\n",
      "972/972 [==============================] - 78s 80ms/sample - loss: 2.6300e-04 - accuracy: 0.9006 - categorical_crossentropy: 2.6300e-04\n",
      "Epoch 3/5\n",
      "972/972 [==============================] - 77s 80ms/sample - loss: 0.0039 - accuracy: 0.9002 - categorical_crossentropy: 0.0039\n",
      "Epoch 4/5\n",
      "972/972 [==============================] - 77s 79ms/sample - loss: 3.5499e-04 - accuracy: 0.9006 - categorical_crossentropy: 3.5499e-04\n",
      "Epoch 5/5\n",
      "972/972 [==============================] - 77s 80ms/sample - loss: 0.0011 - accuracy: 0.9004 - categorical_crossentropy: 0.0011\n",
      "\t\tOn long data set:\n",
      "Train on 612 samples\n",
      "Epoch 1/5\n",
      "612/612 [==============================] - 71s 117ms/sample - loss: 0.0042 - accuracy: 0.9000 - categorical_crossentropy: 0.0042\n",
      "Epoch 2/5\n",
      "612/612 [==============================] - 59s 96ms/sample - loss: 0.0014 - accuracy: 0.9007 - categorical_crossentropy: 0.0014\n",
      "Epoch 3/5\n",
      "612/612 [==============================] - 59s 97ms/sample - loss: 0.0016 - accuracy: 0.9005 - categorical_crossentropy: 0.0016\n",
      "Epoch 4/5\n",
      "612/612 [==============================] - 60s 98ms/sample - loss: 0.0012 - accuracy: 0.9005 - categorical_crossentropy: 0.0012\n",
      "Epoch 5/5\n",
      "612/612 [==============================] - 60s 97ms/sample - loss: 2.4315e-04 - accuracy: 0.9008 - categorical_crossentropy: 2.4315e-04\n",
      "\t\tPitch model training complete: saved at ../models/2_pitch_True_500_0.2_5_8.h5\n",
      "\tTotal training time: 0h 21m 16.48s'\n",
      "\n",
      "\tTraining rhythm (duration) generation network...\n",
      "\t\tOn short data set:\n",
      "Train on 1668 samples\n",
      "Epoch 1/5\n",
      "1668/1668 [==============================] - 116s 70ms/sample - loss: 0.1224 - accuracy: 0.8783 - categorical_crossentropy: 0.1224\n",
      "Epoch 2/5\n",
      "1668/1668 [==============================] - 112s 67ms/sample - loss: 0.0010 - accuracy: 0.9113 - categorical_crossentropy: 0.0010\n",
      "Epoch 3/5\n",
      "1668/1668 [==============================] - 111s 67ms/sample - loss: 3.5314e-04 - accuracy: 0.9113 - categorical_crossentropy: 3.5314e-04\n",
      "Epoch 4/5\n",
      "1668/1668 [==============================] - 111s 66ms/sample - loss: 9.5724e-05 - accuracy: 0.9113 - categorical_crossentropy: 9.5724e-05\n",
      "Epoch 5/5\n",
      "1668/1668 [==============================] - 110s 66ms/sample - loss: 5.4344e-05 - accuracy: 0.9113 - categorical_crossentropy: 5.4344e-05\n",
      "\t\tOn medium data set:\n",
      "Train on 972 samples\n",
      "Epoch 1/5\n",
      "972/972 [==============================] - 85s 87ms/sample - loss: 0.0255 - accuracy: 0.9063 - categorical_crossentropy: 0.0255\n",
      "Epoch 2/5\n",
      "972/972 [==============================] - 79s 81ms/sample - loss: 9.3778e-05 - accuracy: 0.9091 - categorical_crossentropy: 9.3778e-05\n",
      "Epoch 3/5\n",
      "972/972 [==============================] - 79s 81ms/sample - loss: 5.9207e-05 - accuracy: 0.9091 - categorical_crossentropy: 5.9207e-05\n",
      "Epoch 4/5\n",
      "972/972 [==============================] - 79s 81ms/sample - loss: 4.4358e-05 - accuracy: 0.9090 - categorical_crossentropy: 4.4358e-05\n",
      "Epoch 5/5\n",
      "972/972 [==============================] - 78s 81ms/sample - loss: 3.5474e-05 - accuracy: 0.9090 - categorical_crossentropy: 3.5474e-05\n",
      "\t\tOn long data set:\n",
      "Train on 612 samples\n",
      "Epoch 1/5\n",
      "612/612 [==============================] - 64s 105ms/sample - loss: 4.7320e-04 - accuracy: 0.9336 - categorical_crossentropy: 4.7320e-04\n",
      "Epoch 2/5\n",
      "612/612 [==============================] - 59s 97ms/sample - loss: 6.0764e-05 - accuracy: 0.9336 - categorical_crossentropy: 6.0764e-05\n",
      "Epoch 3/5\n",
      "612/612 [==============================] - 58s 95ms/sample - loss: 4.3421e-05 - accuracy: 0.9335 - categorical_crossentropy: 4.3421e-05\n",
      "Epoch 4/5\n",
      "612/612 [==============================] - 58s 95ms/sample - loss: 3.5081e-05 - accuracy: 0.9335 - categorical_crossentropy: 3.5081e-05\n",
      "Epoch 5/5\n",
      "612/612 [==============================] - 58s 94ms/sample - loss: 2.9575e-05 - accuracy: 0.9335 - categorical_crossentropy: 2.9575e-05\n",
      "\t\tPitch model training complete: saved at ../models/2_duration_True_500_0.2_5_8.h5\n",
      "\tTotal training time: 0h 21m 6.27s'\n",
      "\tModel 2 training complete\n",
      "\t\tTotal time to train pitch and duration models: 0h 21m 6.27s0h 21m 16.48s\n",
      "––––––––––––––––––––––––––––––––––––––––––––––––––\n",
      "\n",
      "\n",
      "Model 3:\n",
      "\tbidirectional – True\n",
      "\tlstm cells – 500            \n",
      "\ttemperature – 0.2\n",
      "\tepochs – 10\n",
      "\tbatch size – 16\n",
      "\n",
      "\tTraining pitch generation network...\n",
      "\t\tOn short data set:\n",
      "Train on 1668 samples\n",
      "Epoch 1/10\n",
      "1668/1668 [==============================] - 73s 44ms/sample - loss: 0.6538 - accuracy: 0.7479 - categorical_crossentropy: 0.6538\n",
      "Epoch 2/10\n",
      "1668/1668 [==============================] - 65s 39ms/sample - loss: 0.0176 - accuracy: 0.9022 - categorical_crossentropy: 0.0176\n",
      "Epoch 3/10\n",
      "1668/1668 [==============================] - 65s 39ms/sample - loss: 0.0090 - accuracy: 0.9029 - categorical_crossentropy: 0.0090\n",
      "Epoch 4/10\n",
      "1668/1668 [==============================] - 65s 39ms/sample - loss: 0.0040 - accuracy: 0.9034 - categorical_crossentropy: 0.0040\n",
      "Epoch 5/10\n",
      "1668/1668 [==============================] - 65s 39ms/sample - loss: 0.0019 - accuracy: 0.9037 - categorical_crossentropy: 0.0019\n",
      "Epoch 6/10\n",
      "1668/1668 [==============================] - 64s 38ms/sample - loss: 0.0018 - accuracy: 0.9038 - categorical_crossentropy: 0.0018\n",
      "Epoch 7/10\n",
      "1668/1668 [==============================] - 63s 38ms/sample - loss: 0.0017 - accuracy: 0.9037 - categorical_crossentropy: 0.0017\n",
      "Epoch 8/10\n",
      "1668/1668 [==============================] - 63s 38ms/sample - loss: 6.8705e-04 - accuracy: 0.9039 - categorical_crossentropy: 6.8705e-04\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1668/1668 [==============================] - 63s 38ms/sample - loss: 5.9496e-04 - accuracy: 0.9039 - categorical_crossentropy: 5.9496e-04\n",
      "Epoch 10/10\n",
      "1668/1668 [==============================] - 66s 40ms/sample - loss: 5.3735e-04 - accuracy: 0.9040 - categorical_crossentropy: 5.3735e-04\n",
      "\t\tOn medium data set:\n",
      "Train on 972 samples\n",
      "Epoch 1/10\n",
      "972/972 [==============================] - 50s 52ms/sample - loss: 4.3496e-04 - accuracy: 0.9006 - categorical_crossentropy: 4.3496e-04\n",
      "Epoch 2/10\n",
      "972/972 [==============================] - 44s 45ms/sample - loss: 0.0017 - accuracy: 0.9005 - categorical_crossentropy: 0.0017\n",
      "Epoch 3/10\n",
      "972/972 [==============================] - 44s 46ms/sample - loss: 0.0022 - accuracy: 0.9003 - categorical_crossentropy: 0.0022\n",
      "Epoch 4/10\n",
      "972/972 [==============================] - 44s 45ms/sample - loss: 0.0014 - accuracy: 0.9004 - categorical_crossentropy: 0.0014\n",
      "Epoch 5/10\n",
      "972/972 [==============================] - 44s 45ms/sample - loss: 2.3368e-04 - accuracy: 0.9006 - categorical_crossentropy: 2.3368e-04\n",
      "Epoch 6/10\n",
      "972/972 [==============================] - 45s 46ms/sample - loss: 9.6112e-05 - accuracy: 0.9006 - categorical_crossentropy: 9.6112e-05\n",
      "Epoch 7/10\n",
      "972/972 [==============================] - 44s 45ms/sample - loss: 7.4541e-05 - accuracy: 0.9006 - categorical_crossentropy: 7.4541e-05\n",
      "Epoch 8/10\n",
      "972/972 [==============================] - 44s 46ms/sample - loss: 6.5857e-05 - accuracy: 0.9006 - categorical_crossentropy: 6.5857e-05\n",
      "Epoch 9/10\n",
      "972/972 [==============================] - 44s 45ms/sample - loss: 6.0005e-05 - accuracy: 0.9006 - categorical_crossentropy: 6.0005e-05\n",
      "Epoch 10/10\n",
      "972/972 [==============================] - 44s 45ms/sample - loss: 5.5147e-05 - accuracy: 0.9006 - categorical_crossentropy: 5.5147e-05\n",
      "\t\tOn long data set:\n",
      "Train on 612 samples\n",
      "Epoch 1/10\n",
      "612/612 [==============================] - 40s 66ms/sample - loss: 0.0101 - accuracy: 0.9001 - categorical_crossentropy: 0.0101\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 33s 55ms/sample - loss: 0.0026 - accuracy: 0.9006 - categorical_crossentropy: 0.0026\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 33s 55ms/sample - loss: 0.0011 - accuracy: 0.9007 - categorical_crossentropy: 0.0011\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 33s 54ms/sample - loss: 9.8068e-04 - accuracy: 0.9006 - categorical_crossentropy: 9.8068e-04\n",
      "Epoch 5/10\n",
      "612/612 [==============================] - 33s 55ms/sample - loss: 1.3732e-04 - accuracy: 0.9008 - categorical_crossentropy: 1.3732e-04\n",
      "Epoch 6/10\n",
      "612/612 [==============================] - 33s 54ms/sample - loss: 8.2372e-05 - accuracy: 0.9008 - categorical_crossentropy: 8.2372e-05\n",
      "Epoch 7/10\n",
      "612/612 [==============================] - 33s 54ms/sample - loss: 5.8989e-05 - accuracy: 0.9008 - categorical_crossentropy: 5.8989e-05\n",
      "Epoch 8/10\n",
      "612/612 [==============================] - 33s 54ms/sample - loss: 4.9723e-05 - accuracy: 0.9008 - categorical_crossentropy: 4.9723e-05\n",
      "Epoch 9/10\n",
      "612/612 [==============================] - 33s 55ms/sample - loss: 4.4828e-05 - accuracy: 0.9008 - categorical_crossentropy: 4.4828e-05\n",
      "Epoch 10/10\n",
      "612/612 [==============================] - 33s 54ms/sample - loss: 4.0875e-05 - accuracy: 0.9008 - categorical_crossentropy: 4.0875e-05\n",
      "\t\tPitch model training complete: saved at ../models/3_pitch_True_500_0.2_10_16.h5\n",
      "\tTotal training time: 0h 24m 6.56s'\n",
      "\n",
      "\tTraining rhythm (duration) generation network...\n",
      "\t\tOn short data set:\n",
      "Train on 1668 samples\n",
      "Epoch 1/10\n",
      "1668/1668 [==============================] - 67s 40ms/sample - loss: 0.2272 - accuracy: 0.8548 - categorical_crossentropy: 0.2272\n",
      "Epoch 2/10\n",
      "1668/1668 [==============================] - 65s 39ms/sample - loss: 0.0019 - accuracy: 0.9112 - categorical_crossentropy: 0.0019\n",
      "Epoch 3/10\n",
      "1668/1668 [==============================] - 62s 37ms/sample - loss: 6.1632e-04 - accuracy: 0.9113 - categorical_crossentropy: 6.1632e-04\n",
      "Epoch 4/10\n",
      "1668/1668 [==============================] - 62s 37ms/sample - loss: 3.1256e-04 - accuracy: 0.9113 - categorical_crossentropy: 3.1256e-04\n",
      "Epoch 5/10\n",
      "1668/1668 [==============================] - 62s 37ms/sample - loss: 1.7082e-04 - accuracy: 0.9113 - categorical_crossentropy: 1.7082e-04\n",
      "Epoch 6/10\n",
      "1668/1668 [==============================] - 62s 37ms/sample - loss: 1.3048e-04 - accuracy: 0.9113 - categorical_crossentropy: 1.3048e-04\n",
      "Epoch 7/10\n",
      "1668/1668 [==============================] - 62s 37ms/sample - loss: 1.0082e-04 - accuracy: 0.9113 - categorical_crossentropy: 1.0082e-04\n",
      "Epoch 8/10\n",
      "1668/1668 [==============================] - 61s 37ms/sample - loss: 7.9875e-05 - accuracy: 0.9113 - categorical_crossentropy: 7.9875e-05\n",
      "Epoch 9/10\n",
      "1668/1668 [==============================] - 62s 37ms/sample - loss: 6.5859e-05 - accuracy: 0.9113 - categorical_crossentropy: 6.5859e-05\n",
      "Epoch 10/10\n",
      "1668/1668 [==============================] - 61s 37ms/sample - loss: 5.6084e-05 - accuracy: 0.9113 - categorical_crossentropy: 5.6085e-05\n",
      "\t\tOn medium data set:\n",
      "Train on 972 samples\n",
      "Epoch 1/10\n",
      "972/972 [==============================] - 49s 51ms/sample - loss: 0.0746 - accuracy: 0.8984 - categorical_crossentropy: 0.0746\n",
      "Epoch 2/10\n",
      "972/972 [==============================] - 44s 45ms/sample - loss: 1.7543e-04 - accuracy: 0.9090 - categorical_crossentropy: 1.7543e-04\n",
      "Epoch 3/10\n",
      "972/972 [==============================] - 43s 45ms/sample - loss: 1.1540e-04 - accuracy: 0.9090 - categorical_crossentropy: 1.1540e-04\n",
      "Epoch 4/10\n",
      "972/972 [==============================] - 43s 44ms/sample - loss: 9.0947e-05 - accuracy: 0.9090 - categorical_crossentropy: 9.0947e-05\n",
      "Epoch 5/10\n",
      "972/972 [==============================] - 43s 44ms/sample - loss: 7.5528e-05 - accuracy: 0.9090 - categorical_crossentropy: 7.5528e-05\n",
      "Epoch 6/10\n",
      "972/972 [==============================] - 43s 44ms/sample - loss: 6.4685e-05 - accuracy: 0.9090 - categorical_crossentropy: 6.4685e-05\n",
      "Epoch 7/10\n",
      "972/972 [==============================] - 43s 44ms/sample - loss: 5.6528e-05 - accuracy: 0.9090 - categorical_crossentropy: 5.6528e-05\n",
      "Epoch 8/10\n",
      "972/972 [==============================] - 43s 44ms/sample - loss: 5.0295e-05 - accuracy: 0.9090 - categorical_crossentropy: 5.0295e-05\n",
      "Epoch 9/10\n",
      "972/972 [==============================] - 43s 44ms/sample - loss: 4.5107e-05 - accuracy: 0.9090 - categorical_crossentropy: 4.5107e-05\n",
      "Epoch 10/10\n",
      "972/972 [==============================] - 43s 44ms/sample - loss: 4.0883e-05 - accuracy: 0.9090 - categorical_crossentropy: 4.0883e-05\n",
      "\t\tOn long data set:\n",
      "Train on 612 samples\n",
      "Epoch 1/10\n",
      "612/612 [==============================] - 38s 62ms/sample - loss: 9.5225e-04 - accuracy: 0.9336 - categorical_crossentropy: 9.5225e-04\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 33s 53ms/sample - loss: 1.1592e-04 - accuracy: 0.9335 - categorical_crossentropy: 1.1592e-04\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 32s 53ms/sample - loss: 7.8437e-05 - accuracy: 0.9335 - categorical_crossentropy: 7.8437e-05\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 33s 53ms/sample - loss: 6.4038e-05 - accuracy: 0.9335 - categorical_crossentropy: 6.4038e-05\n",
      "Epoch 5/10\n",
      "612/612 [==============================] - 32s 53ms/sample - loss: 5.5236e-05 - accuracy: 0.9335 - categorical_crossentropy: 5.5236e-05\n",
      "Epoch 6/10\n",
      "612/612 [==============================] - 33s 54ms/sample - loss: 4.8882e-05 - accuracy: 0.9335 - categorical_crossentropy: 4.8882e-05\n",
      "Epoch 7/10\n",
      "612/612 [==============================] - 33s 53ms/sample - loss: 4.4054e-05 - accuracy: 0.9335 - categorical_crossentropy: 4.4054e-05\n",
      "Epoch 8/10\n",
      "612/612 [==============================] - 33s 54ms/sample - loss: 4.0117e-05 - accuracy: 0.9335 - categorical_crossentropy: 4.0117e-05\n",
      "Epoch 9/10\n",
      "612/612 [==============================] - 33s 53ms/sample - loss: 3.6949e-05 - accuracy: 0.9335 - categorical_crossentropy: 3.6949e-05\n",
      "Epoch 10/10\n",
      "612/612 [==============================] - 32s 53ms/sample - loss: 3.4211e-05 - accuracy: 0.9335 - categorical_crossentropy: 3.4211e-05\n",
      "\t\tPitch model training complete: saved at ../models/3_duration_True_500_0.2_10_16.h5\n",
      "\tTotal training time: 0h 23m 25.81s'\n",
      "\tModel 3 training complete\n",
      "\t\tTotal time to train pitch and duration models: 0h 23m 25.81s0h 24m 6.56s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "––––––––––––––––––––––––––––––––––––––––––––––––––\n",
      "\n",
      "\n",
      "TRAINING COMPLETE – elapsed time: 2h 36m 21.46427607536316s\n"
     ]
    }
   ],
   "source": [
    "run_tests(short_seqs_pitch, medium_seqs_pitch, long_seqs_pitch, short_seqs_duration, medium_seqs_duration, long_seqs_duration, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

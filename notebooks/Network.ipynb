{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqoqHneHP97F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RUNNING_IN_COLAB = True\n",
        "\n",
        "if RUNNING_IN_COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8Y_Z-dgB50P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Bidirectional, Lambda\n",
        "import numpy as np\n",
        "from music21 import *\n",
        "from copy import deepcopy\n",
        "import random\n",
        "import pickle\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OiZAScEDQWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODELS_DIRECTORY = '../models'\n",
        "PICKLES_DIRECTORY = 'pickles'\n",
        "COMPOSITIONS_DIRECTORY = '../outputs/compositions'\n",
        "\n",
        "if RUNNING_IN_COLAB:  # access the shared drive instead\n",
        "  MODELS_DIRECTORY = '/content/drive/Shared drives/melodyAI/outputs/models'\n",
        "  PICKLES_DIRECTORY = '/content/drive/Shared drives/melodyAI/pickles'\n",
        "  COMPOSITIONS_DIRECTORY = '/content/drive/Shared drives/melodyAI/outputs/compositions'\n",
        "\n",
        "\n",
        "if not os.path.exists(MODELS_DIRECTORY):\n",
        "    os.makedirs(MODELS_DIRECTORY)\n",
        "if not os.path.exists(PICKLES_DIRECTORY):\n",
        "    os.makedirs(PICKLES_DIRECTORY)\n",
        "if not os.path.exists(COMPOSITIONS_DIRECTORY):\n",
        "    os.makedirs(COMPOSITIONS_DIRECTORY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiFxk9TKCb_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert os.path.exists(MODELS_DIRECTORY)\n",
        "assert os.path.exists(PICKLES_DIRECTORY)\n",
        "assert os.path.exists(COMPOSITIONS_DIRECTORY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wjash0PB50T",
        "colab_type": "text"
      },
      "source": [
        "# Retrieving data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thD8OStZB50U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the datasets\n",
        "with open(f\"{PICKLES_DIRECTORY}/short_seqs_duration.pickle\", 'rb') as short_duration,\\\n",
        "     open(f\"{PICKLES_DIRECTORY}/short_seqs_pitch.pickle\", 'rb') as short_pitch:\n",
        "    short_seqs_duration = pickle.load(short_duration)\n",
        "    short_seqs_pitch = pickle.load(short_pitch)\n",
        "\n",
        "with open(f\"{PICKLES_DIRECTORY}/medium_seqs_duration.pickle\", 'rb') as medium_duration,\\\n",
        "     open(f\"{PICKLES_DIRECTORY}/medium_seqs_pitch.pickle\", 'rb') as medium_pitch:\n",
        "    medium_seqs_duration = pickle.load(medium_duration)\n",
        "    medium_seqs_pitch = pickle.load(medium_pitch)\n",
        "    \n",
        "with open(f\"{PICKLES_DIRECTORY}/long_seqs_duration.pickle\", 'rb') as long_duration,\\\n",
        "     open(f\"{PICKLES_DIRECTORY}/long_seqs_pitch.pickle\", 'rb') as long_pitch:\n",
        "    long_seqs_duration = pickle.load(long_duration)\n",
        "    long_seqs_pitch = pickle.load(long_pitch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TTdX7yGB50l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# retrieve the pitches and durations that were used to build the data set\n",
        "with open(f'{PICKLES_DIRECTORY}/durations.pickle', 'rb') as d, open(f'{PICKLES_DIRECTORY}/pitches.pickle', 'rb') as p:\n",
        "    durations = pickle.load(d)\n",
        "    pitches = pickle.load(p)\n",
        "    \n",
        "# retrieve the mapping from pitch/duration values to one-hot vector indices\n",
        "with open(f'{PICKLES_DIRECTORY}/duration_indices.pickle', 'rb') as d, open(f'{PICKLES_DIRECTORY}/pitch_indices.pickle', 'rb') as p:\n",
        "    duration_indices = pickle.load(d)\n",
        "    pitch_indices = pickle.load(p)\n",
        "    \n",
        "# retrieve the likelihood of starting with a given pitch/duration\n",
        "# these are used in sampling to find the starting pitch/duration of each composition\n",
        "with open(f'{PICKLES_DIRECTORY}/starting_pitch_likelihood.pickle', 'rb') as p, open(f'{PICKLES_DIRECTORY}/starting_duration_likelihood.pickle', 'rb') as d:\n",
        "    starting_pitch_likelihood = pickle.load(p)\n",
        "    starting_duration_likelihood = pickle.load(d)\n",
        "    \n",
        "num_durations = len(durations)\n",
        "num_pitches = len(pitches)\n",
        "short_seq_len = short_seqs_duration.shape[1]\n",
        "medium_seq_len = medium_seqs_duration.shape[1]\n",
        "long_seq_len = long_seqs_duration.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qrT5pl1B50o",
        "colab_type": "text"
      },
      "source": [
        "# Experimenting with how temperature affects a softmax distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt2Xjc7rB50o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(x):\n",
        "    \"\"\"\n",
        "    Simply performs the softmax operation on an input vector.\n",
        "    \n",
        "    Parameters:\n",
        "        x: a vector of logits.\n",
        "        \n",
        "    Returns: \n",
        "        np.array: array representing the softmax distribution of the input logits.\n",
        "    \"\"\"\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "logits = np.array([1,2,3,4])\n",
        "logits_temp_p0 = logits / 0.01\n",
        "logits_temp_p2 = logits / 0.2\n",
        "logits_temp_p4 = logits / 0.4\n",
        "logits_temp_p6 = logits / 0.6\n",
        "logits_temp_p8 = logits / 0.8\n",
        "logits_temp_p10 = logits / 1.0\n",
        "logits_temp_p15 = logits / 1.5\n",
        "logits_temp_p150 = logits / 150\n",
        "\n",
        "print(f\"RAW: {softmax(logits)}\")\n",
        "print(f\"TEMP 0.0: {softmax(logits_temp_p0)}\")\n",
        "print(f\"TEMP 0.2: {softmax(logits_temp_p2)}\")\n",
        "print(f\"TEMP 0.4: {softmax(logits_temp_p4)}\")\n",
        "print(f\"TEMP 0.6: {softmax(logits_temp_p6)}\")\n",
        "print(f\"TEMP 0.8: {softmax(logits_temp_p8)}\")\n",
        "print(f\"TEMP 1.0: {softmax(logits_temp_p10)}\")\n",
        "print(f\"TEMP 1.5: {softmax(logits_temp_p15)}\")\n",
        "print(f\"TEMP 150: {softmax(logits_temp_p150)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QGHJt8vB50y",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fVTzMStB50y",
        "colab_type": "text"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrxg1G8RB50z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def timestep_to3d(x):\n",
        "    \"\"\"\n",
        "    Takes a 1D vector (a vector representing a single timestep) and converts it to a 3D vector (which is required by an LSTM network).\n",
        "    \n",
        "    Parameters:\n",
        "        x: a 1D vector which is the one-hot encoding of a value at a single timestep.\n",
        "        \n",
        "    Returns: \n",
        "        np.array: a 3D vector corresponding to a one-hot encoding of a single timestep.\n",
        "    \"\"\"\n",
        "    return np.reshape(x, (1, 1, x.shape[0]))\n",
        "\n",
        "\n",
        "def vectorize(index, vec_size):\n",
        "    \"\"\"\n",
        "    Creates a one-hot vector representation for a single time step given the index position of the value to encode.\n",
        "    \n",
        "    Parameters:\n",
        "        index: the index of the returned vector which should be set to 1.\n",
        "        vec_size: how large the returned vector should be (how many possible values for the feature).\n",
        "        \n",
        "    Returns: \n",
        "        np.array: a 1D array which is the resulting one-hot encoding of a value at a single time step.\n",
        "    \"\"\"\n",
        "    index = int(index)\n",
        "    vec = np.zeros(vec_size, np.float32)\n",
        "    vec[index] = 1.0\n",
        "    return vec\n",
        "\n",
        "\n",
        "def unvectorize(x):\n",
        "    \"\"\"\n",
        "    Returns the index of the one-hot encoded value.\n",
        "    This works because only one value will be nonzero in a vector, so argmax will return this index of the encoded value.\n",
        "    \n",
        "    Parameters:\n",
        "        x: a one-hot encoded vector.\n",
        "        \n",
        "    Returns: \n",
        "        integer: an index corresponding to the values which is encoded by the vector.\n",
        "    \"\"\"\n",
        "    return np.argmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9eMfJT0B511",
        "colab_type": "text"
      },
      "source": [
        "### Model building and training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3mCUGnUB512",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# single layer Unidirectional or Bidirectional LSTM; will easily allow us to test various configurations\n",
        "def get_model(num_values, lstm_cells=500, bidirectional=True, temperature=1.0, optimizer=\"adam\"):\n",
        "    \"\"\"\n",
        "    Creates and compiles the LSTM model.\n",
        "    \n",
        "    Parameters:\n",
        "        num_values (int): The size of the one-hot vector at a time step.\n",
        "        lstm_cells (int): The number of LSTM cells in the model.\n",
        "        bidirectional (boolean): Whether to construct a bidirectional LSTM (as opposed to unidirectional).\n",
        "        temperature (float): Value by the Lambda layer to divide output logits by.\n",
        "        optimizer (string | tf.keras.optimizers.Optimizer): Which optimization algorith to use.\n",
        "        \n",
        "    Returns:\n",
        "        tf.keras.Model: A compiled LSTM model.\n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential()\n",
        "    # only dif. betwn. bi. LSTM and uni. LSTM is the presence/absence of Bidirectional wrapper\n",
        "    # hidden layer 1; 20  units; input (# timesteps, # features); return a sequence of each time step's outputs\n",
        "    # input_shape first value None makes it variable (we don't have fixed length sequences)\n",
        "    # output of LSTM cell uses tanh activation, recurrent connections use sigmoid\n",
        "    if bidirectional:\n",
        "        model.add(Bidirectional(LSTM(lstm_cells, input_shape=(None, num_values), return_sequences=True)))\n",
        "    else:\n",
        "        model.add(LSTM(lstm_cells, input_shape=(None, num_values), return_sequences=True))\n",
        "        \n",
        "    # so that we can divibe by temperature before feeding through softmax\n",
        "    model.add(Lambda(lambda x: x / temperature))\n",
        "        \n",
        "    # TimeDistributed is a wrapper allowing one output per time step; \n",
        "    # ...requires hidden layer to have return_sequences == True\n",
        "    model.add(TimeDistributed(Dense(num_values, activation='softmax')))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', 'categorical_crossentropy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRpQA6NyB52K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, X, bidirectional=True, epochs=15, batch_size=32, verbose=1):\n",
        "    \"\"\"\n",
        "    Trains an LSTM model.\n",
        "    \n",
        "    Parameters:\n",
        "        model (tf.keras.Model): The model which is to be trained.\n",
        "        X (np.array): A 3D vector (samples, timesteps, values) to train the network on.\n",
        "        bidirectional (boolean): Indicates whether the model is a bidirectional.\n",
        "        epochs (int): The number of epochs over which to train the model.\n",
        "        batch_size (int): The number of samples tito show the odel before updating weights.\n",
        "        verbose (int): The amount of information to print while training.\n",
        "        \n",
        "        Returns: None\n",
        "    \"\"\"\n",
        "    Y = deepcopy(X)\n",
        "    if not bidirectional:\n",
        "        X = X[0:-1] # do not input the final time step in unidirectional LSTM\n",
        "        Y = Y[1:] # labels include all time steps but the first one in unidir. LSTM\n",
        "    model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=verbose)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgYZ8dftB52M",
        "colab_type": "text"
      },
      "source": [
        "# Composing with the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-HrHl_rB52N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_distribution(dist_vec, num_categories):\n",
        "    \"\"\"\n",
        "    Sample a softmax distribution vector.\n",
        "    \n",
        "    Parameters:\n",
        "        dist_vec (np.array): A logit vector from which to take a sample from.\n",
        "        num_categories (int): Number of categories to sample from (used for reshaping).\n",
        "        \n",
        "    Returns:\n",
        "        int: The index of the output value which was sampled.\n",
        "    \"\"\"\n",
        "    return tf.random.categorical(dist_vec.reshape(1, num_categories), 1).numpy().flatten()[0]\n",
        "\n",
        "def compose(pitch_model, duration_model, pitch_prompt, duration_prompt, length=50):\n",
        "    '''\n",
        "    Composes a piece of music (in the format of a music21.stream.Stream object).\n",
        "    \n",
        "    Arguments:\n",
        "        pitch_model (tf.keras.Model): The trained model for pitch predictions.\n",
        "        duration_model (tf.keras.Model): The trained model for duration predictions.\n",
        "        pitch_prompt (int): The first pitch of the piece (index of the one-hot encoded pitch vector).\n",
        "        duration_prompt (int): The first duration of the piece (index of the one-hot encoded duration vector).\n",
        "        length (int): How many time steps to generate.\n",
        "       \n",
        "       Returns:\n",
        "           music21.stream.Stream(): The composed piece.\n",
        "    '''    \n",
        "    \n",
        "    # the lists that hold the indices of the values to index in to pitches/durations lists\n",
        "    generated_pitches, generated_durations = [pitch_prompt], [duration_prompt]\n",
        "    \n",
        "    current_pitch, current_duration = pitch_prompt, duration_prompt\n",
        "    for t in range(length):\n",
        "        # model only accepts 3D inputs\n",
        "        pitch_vec = timestep_to3d(vectorize(current_pitch, num_pitches))\n",
        "        duration_vec = timestep_to3d(vectorize(current_duration, num_durations))\n",
        "        \n",
        "        # predict the output distributions\n",
        "        pitch_pred = pitch_model.predict(pitch_vec)\n",
        "        duration_pred = duration_model.predict(duration_vec)\n",
        "        # sample the distributions (returns the index of the one-hot vectors)\n",
        "        next_pitch = sample_distribution(pitch_pred, num_pitches)\n",
        "        next_duration = sample_distribution(duration_pred, num_durations)\n",
        "        generated_pitches.append(next_pitch)\n",
        "        generated_durations.append(next_duration)\n",
        "        \n",
        "        # get ready for next iteration\n",
        "        current_pitch, current_duration = next_pitch, next_duration\n",
        "        \n",
        "    \n",
        "    composed_stream = stream.Stream()\n",
        "    for pair in list(zip(generated_pitches, generated_durations)):\n",
        "        p = pitch.Pitch(midi=pitches[pair[0]])\n",
        "        d = duration.Duration(durations[pair[1]])\n",
        "        n = note.Note()\n",
        "        n.pitch = p\n",
        "        n.duration = d\n",
        "        composed_stream.append(n)\n",
        "    \n",
        "    return composed_stream"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRyzfq-qB53t",
        "colab_type": "text"
      },
      "source": [
        "# Generation infrastructure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xdYQcfwCB53u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bidirectional_vals = [True, False]\n",
        "lstm_cell_vals = [500, 1000, 2000]\n",
        "temperature_vals = [0.2, 0.5, 1.0, 10.0]\n",
        "epoch_batch_vals = [(1, 1), (5, 8), (10, 16), (30, 32)] # [(epochs, batch_size), ...]\n",
        "\n",
        "def generate_param_sets(start=None, end=None):\n",
        "    \"\"\"\n",
        "    Creates sets of possible parameter combinations that will be tested over.\n",
        "    Optionally allows to pass in indices to return a sub set of param sets in case training in to be done at separate times.\n",
        "    \n",
        "    Parameters:\n",
        "        start (integer): The starting index of the range of sets to return from all possible sets.\n",
        "        end (int): The ending index (inclusive) of the renage of sets to return from all possible sets.\n",
        "        *NOTE that start and end must either both be None or integers; only suppling one argument causes an exception to be raised.\n",
        "    \"\"\"\n",
        "    sets = []\n",
        "    for bidirectional in bidirectional_vals:\n",
        "        for lstm_cells in lstm_cell_vals:\n",
        "            for temperature in temperature_vals:\n",
        "                for epochs, batch_size in epoch_batch_vals:\n",
        "                    s = {\n",
        "                        \"bidirectional\": bidirectional,\n",
        "                        \"lstm_cells\": lstm_cells,\n",
        "                        \"temperature\": temperature,\n",
        "                        \"epochs\": epochs,\n",
        "                        \"batch_size\": batch_size\n",
        "                    }\n",
        "                    sets.append(s)\n",
        "                    \n",
        "    if start is None:\n",
        "      start = 0\n",
        "    if end is None or end > len(sets):\n",
        "      end = len(sets) - 1  # subtract 1 because of the +1 in the end slice\n",
        "\n",
        "    return sets[start:end+1]  # +1 to make the index passed in inclusive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8FixbskB53x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MetadataModel:\n",
        "    \"\"\"\n",
        "    A wrapper class for LSTM models that is used to gather metadata from training.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, num_features, lstm_cells, bidirectional, temperature, epochs,\\\n",
        "                 batch_size, verbose=0, id=None):\n",
        "        self._model = get_model(num_features, lstm_cells, bidirectional, temperature)\n",
        "        self._num_features = num_features\n",
        "        self._lstm_cells = lstm_cells\n",
        "        self._bidirectional = bidirectional\n",
        "        self._temperature = temperature\n",
        "        self._epochs = epochs\n",
        "        self._batch_size = batch_size\n",
        "        self.verbose = verbose # no underscore because this should be mutable\n",
        "        self._name = '_'.join([str(bidirectional), str(lstm_cells), str(temperature), str(epochs), str(batch_size)])\n",
        "        if id is not None:\n",
        "            self.name += f\"_{id}\"\n",
        "        self._total_training_time = 0.0 # in seconds\n",
        "    \n",
        "    # ---- setting properties so that these attributes are immutable ----\n",
        "    @property\n",
        "    def name(self):\n",
        "        return self._name\n",
        "    \n",
        "    @property\n",
        "    def model(self):\n",
        "        return self._model\n",
        "        \n",
        "    @property\n",
        "    def num_features(self):\n",
        "        return self._num_features\n",
        "    \n",
        "    @property\n",
        "    def lstm_cells(self):\n",
        "        return self._lstm_cells\n",
        "    \n",
        "    @property\n",
        "    def bidirectional(self):\n",
        "        return self._bidirectional\n",
        "    \n",
        "    @property\n",
        "    def temperature(self):\n",
        "        return self._temperature\n",
        "    \n",
        "    @property\n",
        "    def epochs(self):\n",
        "        return self._epochs\n",
        "    \n",
        "    @property\n",
        "    def batch_size(self):\n",
        "        return self._batch_size\n",
        "        \n",
        "    # returns a string version of training time\n",
        "    @property\n",
        "    def training_duration(self):\n",
        "        total_time = self._total_training_time\n",
        "        hours = int(total_time // 3600)  # 3600 seconds/hour\n",
        "        minutes = int((total_time - (3600 * hours)) // 60) # subtract the hours from remaining time; 60 sec/min\n",
        "        seconds = (total_time - (3600 * hours)) - (60 * minutes)\n",
        "        return \"{}h {}m {:.2f}s\".format(hours, minutes, seconds)\n",
        "            \n",
        "    def train(self, X):\n",
        "        start_time = time.time()\n",
        "        train_model(self.model, X, self.bidirectional, self.epochs, self.batch_size, self.verbose)\n",
        "        end_time = time.time()\n",
        "        self._total_training_time += end_time - start_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-ikO1pxB53-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_start_pitch():\n",
        "    \"\"\"\n",
        "    Sample from the dictionary containing the probabilities of starting a piece with a given pitch.\n",
        "    \n",
        "    Parameters:\n",
        "        dictionary (dict(int: float)): The dictionary whose values are probabilities, and whose keys are the MIDI pitch.\n",
        "                                       This dictionary must be sorted by key.\n",
        "        \n",
        "    Returns:\n",
        "        int: The index of the MIDI pitch in the pitches list.\n",
        "    \"\"\"\n",
        "    logits = np.array(list(starting_pitch_likelihood.values()))\n",
        "    return np.argmax(np.random.multinomial(1, logits))\n",
        "    \n",
        "def sample_start_duration():\n",
        "    \"\"\"\n",
        "    Sample from the dictionary containing the probabilities of starting a piece with a given duration.\n",
        "    \n",
        "    Parameters:\n",
        "        dictionary (dict(float: float)): The dictionary whose values are probabilities, and whose keys are the quarter length duration.\n",
        "                                         This dictionary must be sorted by key.\n",
        "        \n",
        "    Returns:\n",
        "        np.array: The index of the sampled duration in the durations list.\n",
        "    \"\"\"\n",
        "    logits = np.array(list(starting_duration_likelihood.values()))\n",
        "    return np.argmax(np.random.multinomial(1, logits))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT0PniOzB54E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_tests(pitch_short, pitch_medium, pitch_long, duration_short, duration_medium,\\\n",
        "              duration_long, param_set_start=None, param_set_end=None,\\\n",
        "              num_compositions=5, verbose=0):\n",
        "    \"\"\"\n",
        "    Creates, trains, and composes with networks of a multitude of parameter combinations.\n",
        "    \n",
        "    Parameters:\n",
        "        pitch_short (np.array): The short pitch sequences.\n",
        "        pitch_medium (np.array): The medium pitch sequences.\n",
        "        pitch_long (np.array): The long pitch sequences.\n",
        "        duration_short (np.array): The short duration sequences.\n",
        "        duration_medium (np.array): The medium duration sequences.\n",
        "        duration_long (np.array): The long duration sequences.\n",
        "        param_set_start (int): The first of the generated param. sets to be tested on.\n",
        "        param_set_end (int): The last of the generated param. sets to be tested on.\n",
        "        num_compositions (int): How many pieces to compose for each model being tested.\n",
        "        verbose (int): The amount of information to print throughout the test.\n",
        "        \n",
        "        Returns: None\n",
        "    \"\"\"\n",
        "    \n",
        "    param_sets = generate_param_sets(param_set_start, param_set_end)\n",
        "    pitch_models, duration_models = [], []\n",
        "    model_no = 0 # which iteration of model we are on\n",
        "    if param_set_start is not None:\n",
        "      model_no = param_set_start\n",
        "    if not os.path.exists(\"models\"):\n",
        "            os.mkdir(\"models\")\n",
        "            \n",
        "    test_start_time=time.time()            \n",
        "    for params in param_sets:\n",
        "        bidirectional = params[\"bidirectional\"]\n",
        "        lstm_cells = params[\"lstm_cells\"]\n",
        "        temperature = params[\"temperature\"]\n",
        "        epochs = params[\"epochs\"]\n",
        "        batch_size = params[\"batch_size\"]\n",
        "        \n",
        "        if verbose:\n",
        "            print(f\"Model {model_no}:\\n\\tbidirectional – {bidirectional}\\n\\tlstm cells – {lstm_cells}\\\n",
        "            \\n\\ttemperature – {temperature}\\n\\tepochs – {epochs}\\n\\tbatch size – {batch_size}\")\n",
        "        \n",
        "        pitch_model = MetadataModel(num_pitches, lstm_cells, bidirectional, temperature, epochs, batch_size, verbose)\n",
        "        duration_model = MetadataModel(num_durations, lstm_cells, bidirectional, temperature, epochs, batch_size, verbose)\n",
        "        \n",
        "        # train the pitch network\n",
        "        if verbose:\n",
        "            print('\\n\\tTraining pitch generation network...')\n",
        "            print('\\t\\tOn short data set:')\n",
        "        pitch_model.train(pitch_short)\n",
        "        if verbose:\n",
        "            print('\\t\\tOn medium data set:')\n",
        "        pitch_model.train(pitch_medium)\n",
        "        if verbose:\n",
        "            print('\\t\\tOn long data set:')\n",
        "        pitch_model.train(pitch_long)\n",
        "        pitch_model.model.save(f\"{MODELS_DIRECTORY}/{model_no}_pitch_{pitch_model.name}.h5\")\n",
        "        if verbose:\n",
        "            print(f\"\\t\\tPitch model training complete: saved at {MODELS_DIRECTORY}/{model_no}_pitch_{pitch_model.name}.h5\")\n",
        "            print(f\"\\tTotal training time: {pitch_model.training_duration}'\")\n",
        "        \n",
        "        # train the duration network\n",
        "        if verbose:\n",
        "            print('\\n\\tTraining rhythm (duration) generation network...')\n",
        "            print('\\t\\tOn short data set:')\n",
        "        duration_model.train(duration_short)\n",
        "        if verbose:\n",
        "            print('\\t\\tOn medium data set:')\n",
        "        duration_model.train(duration_medium)\n",
        "        if verbose:\n",
        "            print('\\t\\tOn long data set:')\n",
        "        duration_model.train(duration_long)\n",
        "        duration_model.model.save(f\"{MODELS_DIRECTORY}/{model_no}_duration_{duration_model.name}.h5\")\n",
        "        if verbose:\n",
        "            print(f\"\\t\\tPitch model training complete: saved at {MODELS_DIRECTORY}/{model_no}_duration_{duration_model.name}.h5\")\n",
        "            print(f\"\\tTotal training time: {duration_model.training_duration}'\")\n",
        "        \n",
        "        if verbose:\n",
        "            print(f'\\tModel {model_no} training complete')\n",
        "            print(f'\\t\\tTotal time to train pitch and duration models: {duration_model.training_duration + pitch_model.training_duration}')\n",
        "        \n",
        "        # compose outputs and save them\n",
        "        if not os.path.exists(f\"{COMPOSITIONS_DIRECTORY}/model_no_{model_no}\"):\n",
        "            os.makedirs(f\"{COMPOSITIONS_DIRECTORY}/model_{model_no}\")\n",
        "        comp_count = 1\n",
        "        for c in range(num_compositions):\n",
        "            pitch_prompt = sample_start_pitch()\n",
        "            duration_prompt = sample_start_duration()\n",
        "            composition = compose(pitch_model.model, duration_model.model, pitch_prompt, duration_prompt, length=100)\n",
        "            composition.write('musicxml', f'{COMPOSITIONS_DIRECTORY}/model_{model_no}/composition_{comp_count}.mxl')\n",
        "            composition.write('midi', f'{COMPOSITIONS_DIRECTORY}/model_{model_no}/composition_{comp_count}.mid')\n",
        "            comp_count += 1\n",
        "        print(f\"\\t\\tCompositions successfully written to {COMPOSITIONS_DIRECTORY}/model_{model_no}\")\n",
        "            \n",
        "        model_no = model_no + 1\n",
        "        print('–' * 50 + \"\\n\\n\")\n",
        "        \n",
        "        \n",
        "    test_end_time=time.time()\n",
        "    total_time = test_end_time - test_start_time\n",
        "    hours = int(total_time // 3600)  # 3600 seconds/hour\n",
        "    minutes = int((total_time - (3600 * hours)) // 60) # subtract the hours from remaining time; 60 sec/min\n",
        "    seconds = (total_time - (3600 * hours)) - (60 * minutes)\n",
        "    print(f\"TRAINING COMPLETE – elapsed time: {hours}h {minutes}m {seconds}s\")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kVVnQFOsB54J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_tests(short_seqs_pitch, medium_seqs_pitch, long_seqs_pitch, short_seqs_duration, medium_seqs_duration, long_seqs_duration, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJe34JhXB54a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}

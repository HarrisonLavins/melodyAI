{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import numpy as np\n",
    "from music21 import *\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets and then split in to train/test data sets\n",
    "# note that we don't need label sets, only input sets for bidirectional LSTM (labels == inputs)\n",
    "# unidirectional label set is the same as the inputs but without the first time step\n",
    "with open(\"pickles/short_sequences_duration.pickle\", 'rb') as short_duration,\\\n",
    "     open(\"pickles/short_sequences_duration.pickle\", 'rb') as short_pitch:\n",
    "    short_seqs_duration_train, short_seqs_duration_test = train_test_split(pickle.load(short_duration), train_size=0.95)\n",
    "    short_seqs_pitch_train, short_seqs_pitch_test = train_test_split(pickle.load(short_pitch), train_size=0.95)\n",
    "\n",
    "with open(\"pickles/medium_sequences_duration.pickle\", 'rb') as medium_duration,\\\n",
    "     open(\"pickles/medium_sequences_duration.pickle\", 'rb') as medium_pitch:\n",
    "    medium_seqs_duration_train, medium_seqs_duration_test = train_test_split(pickle.load(medium_duration), train_size=0.95)\n",
    "    medium_seqs_pitch_train, medium_seqs_pitch_test = train_test_split(pickle.load(medium_pitch), train_size=0.95)\n",
    "    \n",
    "with open(\"pickles/long_sequences_duration.pickle\", 'rb') as long_duration,\\\n",
    "     open(\"pickles/long_sequences_duration.pickle\", 'rb') as long_pitch:\n",
    "    long_seqs_duration_train, long_seqs_duration_test = train_test_split(pickle.load(long_duration), train_size=0.95)\n",
    "    long_seqs_pitch_train, long_seqs_pitch_test = train_test_split(pickle.load(long_pitch), train_size=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the pitches and durations that were used to build the data set\n",
    "# these will be used to convert the output one-hot vectors back to actual pitch/duration values\n",
    "with open('pickles/durations.pickle', 'rb') as d, open('pickles/pitches.pickle', 'rb') as p:\n",
    "    durations = pickle.load(d)\n",
    "    pitches = pickle.load(p)\n",
    "\n",
    "num_durations = len(durations)\n",
    "num_pitches = len(pitches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single layer Unidirectional or Bidirectional LSTM; will easily allow us to test various configurations\n",
    "def getModel(num_features, bidirectional=True):\n",
    "    model = Sequential()\n",
    "    # only dif. betwn. bi. LSTM and uni. LSTM is the presence/absence of Bidirectional wrapper\n",
    "    # hidden layer 1; 20  units; input (# timesteps, # features); return a sequence of each time step's outputs\n",
    "    # input_shape first value None makes it variable (we don't have fixed length sequences)\n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(LSTM(20, input_shape=(None, num_features), return_sequences=True)))\n",
    "    else:\n",
    "        model.add(LSTM(20, input_shape=(None, num_features), return_sequences=True))\n",
    "        \n",
    "    # TimeDistributed is a wrapper allowing one output per time step; \n",
    "    # ...requires hidden layer to have return_sequences == True\n",
    "    model.add(TimeDistributed(Dense(num_features, activation='softmax')))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'categorical_crossentropy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train LSTM\n",
    "def trainModel(model, X, epochs=30, bidirectional=True):\n",
    "    print(X.shape)\n",
    "    Y = deepcopy(X)\n",
    "    if not bidirectional:\n",
    "        Y = Y[1:] # labels include all time steps but the first one in unidir. LSTM\n",
    "    model.fit(X, Y, epochs=epochs, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_bidirectional = getModel(num_durations, bidirectional=True)\n",
    "trainModel(duration_bidirectional, short_seqs_duration_train, bidirectional=True)\n",
    "trainModel(duration_bidirectional, medium_seqs_duration_train, bidirectional=True)\n",
    "trainModel(duration_bidirectional, long_seqs_duration_train, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in medium_seqs_duration_train:\n",
    "    print(seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_bidirectional = getModel(num_pitches, bidirectional=True)\n",
    "trainModel(pitch_bidirectional, short_seqs_pitch_train, bidirectional=True)\n",
    "trainModel(pitch_bidirectional, medium_seqs_pitch_train, bidirectional=True)\n",
    "trainModel(pitch_bidirectional, long_seqs_pitch_train, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict requires 3D vector, so this reshapes a 2D input to 3D so it can be fed through the network\n",
    "def to_3D(sample):\n",
    "    return sample.reshape(1, sample.shape[0], sample.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts output one-hot vectors to its respective quarter length value (based on durations seen in data set)\n",
    "def duration_one_hot_to_quarter_length(prediction):\n",
    "    new_durations = []\n",
    "    for timestep in prediction:\n",
    "        index = np.argmax(timestep)\n",
    "        new_durations.append(durations[index])\n",
    "    \n",
    "    return new_durations\n",
    "\n",
    "# converts output one-hot vectors to its respective MIDI pitch value (based on durations seen in data set)\n",
    "def pitch_one_hot_to_MIDI(prediction):\n",
    "    new_pitches = []\n",
    "    for timestep in prediction:\n",
    "        index = np.argmax(timestep)\n",
    "        new_pitches.append(pitches[index])\n",
    "    \n",
    "    return new_pitches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "duration_pred = duration_bidirectional.predict(to_3D(medium_seqs_duration_test[0])).reshape(timesteps, duration_num_features)\n",
    "composed_durations = duration_one_hot_to_quarter_length(duration_pred)\n",
    "\n",
    "pitch_pred = pitch_bidirectional.predict(to_3D(medium_seqs_pitch_test[0])).reshape(timesteps, pitch_num_features)\n",
    "composed_pitches = pitch_one_hot_to_MIDI(pitch_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_pairs = list(zip(composed_pitches, composed_durations))\n",
    "\n",
    "composed_stream = stream.Stream()\n",
    "for pair in composed_pairs:\n",
    "    p = pitch.Pitch(midi=pair[0])\n",
    "    d = duration.Duration(pair[1])\n",
    "    n = note.Note()\n",
    "    n.pitch = p\n",
    "    n.duration = d\n",
    "    composed_stream.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_stream.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "composed_stream.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

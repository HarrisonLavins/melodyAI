{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Bidirectional, Lambda\n",
    "import numpy as np\n",
    "from music21 import *\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "MODELS_DIRECTORY = 'models'\n",
    "if not os.path.exists(MODELS_DIRECTORY):\n",
    "    os.makedirs(MODELS_DIRECTORY)\n",
    "PICKLES_DIRECTORY = 'pickles'\n",
    "if not os.path.exists(PICKLES_DIRECTORY):\n",
    "    os.makedirs(PICKLES_DIRECTORY)\n",
    "COMPOSITIONS_DIRECTORY = 'compositions'\n",
    "if not os.path.exist(COMPOSITIONS_DIRECTORY):\n",
    "    os.makedirs(COMPOSITIONS_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "with open(f\"{PICKLES_DIRECTORY}/short_seqs_duration.pickle\", 'rb') as short_duration,\\\n",
    "     open(f\"{PICKLES_DIRECTORY}/short_seqs_pitch.pickle\", 'rb') as short_pitch:\n",
    "    short_seqs_duration = pickle.load(short_duration)\n",
    "    short_seqs_pitch = pickle.load(short_pitch)\n",
    "\n",
    "with open(f\"{PICKLES_DIRECTORY}/medium_seqs_duration.pickle\", 'rb') as medium_duration,\\\n",
    "     open(f\"{PICKLES_DIRECTORY}/medium_seqs_pitch.pickle\", 'rb') as medium_pitch:\n",
    "    medium_seqs_duration = pickle.load(medium_duration)\n",
    "    medium_seqs_pitch = pickle.load(medium_pitch)\n",
    "    \n",
    "with open(f\"{PICKLES_DIRECTORY}/long_seqs_duration.pickle\", 'rb') as long_duration,\\\n",
    "     open(f\"{PICKLES_DIRECTORY}/long_seqs_pitch.pickle\", 'rb') as long_pitch:\n",
    "    long_seqs_duration = pickle.load(long_duration)\n",
    "    long_seqs_pitch = pickle.load(long_pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the pitches and durations that were used to build the data set\n",
    "with open(f'{PICKLES_DIRECTORY}/durations.pickle', 'rb') as d, open(f'{PICKLES_DIRECTORY}/pitches.pickle', 'rb') as p:\n",
    "    durations = pickle.load(d)\n",
    "    pitches = pickle.load(p)\n",
    "    \n",
    "# retrieve the mapping from pitch/duration values to one-hot vector indices\n",
    "with open(f'{PICKLES_DIRECTORY}/duration_indices.pickle', 'rb') as d, open(f'{PICKLES_DIRECTORY}/pitch_indices.pickle', 'rb') as p:\n",
    "    duration_indices = pickle.load(d)\n",
    "    pitch_indices = pickle.load(p)\n",
    "    \n",
    "num_durations = len(durations)\n",
    "num_pitches = len(pitches)\n",
    "short_seq_len = short_seqs_duration.shape[1]\n",
    "medium_seq_len = medium_seqs_duration.shape[1]\n",
    "long_seq_len = long_seqs_duration.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with how temperature affects a softmax distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW: [0.0320586  0.08714432 0.23688282 0.64391426]\n",
      "TEMP 0.0: [5.14820022e-131 1.38389653e-087 3.72007598e-044 1.00000000e+000]\n",
      "TEMP 0.2: [3.03841168e-07 4.50940275e-05 6.69254708e-03 9.93262055e-01]\n",
      "TEMP 0.4: [5.07707490e-04 6.18514343e-03 7.53504725e-02 9.17956677e-01]\n",
      "TEMP 0.6: [0.00547228 0.02897292 0.15339683 0.81215798]\n",
      "TEMP 0.8: [0.01689363 0.05896455 0.20580651 0.71833531]\n",
      "TEMP 1.0: [0.0320586  0.08714432 0.23688282 0.64391426]\n",
      "TEMP 1.5: [0.07076911 0.13783941 0.26847452 0.52291696]\n",
      "TEMP 150: [0.24750558 0.24916113 0.25082776 0.25250553]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "logits = np.array([1,2,3,4])\n",
    "logits_temp_p0 = logits / 0.01\n",
    "logits_temp_p2 = logits / 0.2\n",
    "logits_temp_p4 = logits / 0.4\n",
    "logits_temp_p6 = logits / 0.6\n",
    "logits_temp_p8 = logits / 0.8\n",
    "logits_temp_p10 = logits / 1.0\n",
    "logits_temp_p15 = logits / 1.5\n",
    "logits_temp_p150 = logits / 150\n",
    "\n",
    "print(f\"RAW: {softmax(logits)}\")\n",
    "print(f\"TEMP 0.0: {softmax(logits_temp_p0)}\")\n",
    "print(f\"TEMP 0.2: {softmax(logits_temp_p2)}\")\n",
    "print(f\"TEMP 0.4: {softmax(logits_temp_p4)}\")\n",
    "print(f\"TEMP 0.6: {softmax(logits_temp_p6)}\")\n",
    "print(f\"TEMP 0.8: {softmax(logits_temp_p8)}\")\n",
    "print(f\"TEMP 1.0: {softmax(logits_temp_p10)}\")\n",
    "print(f\"TEMP 1.5: {softmax(logits_temp_p15)}\")\n",
    "print(f\"TEMP 150: {softmax(logits_temp_p150)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a 1D vector (a single sam) and converts it to 3D for input to the network\n",
    "def timestep_to3d(x):\n",
    "    return np.reshape(x, (1, 1, x.shape[0]))\n",
    "\n",
    "# create one-hot vector representation for a time step given the index position of the encoded value\n",
    "def vectorize(index, vec_size):\n",
    "    index = int(index)\n",
    "    vec = np.zeros(vec_size, np.float32)\n",
    "    vec[index] = 1.0\n",
    "    return vec\n",
    "\n",
    "# returns the index of the one-hot encoded value\n",
    "def unvectorize(x):\n",
    "    return np.argmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single layer Unidirectional or Bidirectional LSTM; will easily allow us to test various configurations\n",
    "def get_model(num_features, lstm_cells=500, bidirectional=True, temperature=1.0, optimizer=\"adam\"):\n",
    "    model = Sequential()\n",
    "    # only dif. betwn. bi. LSTM and uni. LSTM is the presence/absence of Bidirectional wrapper\n",
    "    # hidden layer 1; 20  units; input (# timesteps, # features); return a sequence of each time step's outputs\n",
    "    # input_shape first value None makes it variable (we don't have fixed length sequences)\n",
    "    # output of LSTM cell uses tanh activation, recurrent connections use sigmoid\n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(LSTM(lstm_cells, input_shape=(None, num_features), return_sequences=True)))\n",
    "    else:\n",
    "        model.add(LSTM(lstm_cells, input_shape=(None, num_features), return_sequences=True))\n",
    "        \n",
    "    # so that we can divibe by temperature before feeding through softmax\n",
    "    model.add(Lambda(lambda x: x / temperature))\n",
    "        \n",
    "    # TimeDistributed is a wrapper allowing one output per time step; \n",
    "    # ...requires hidden layer to have return_sequences == True\n",
    "    model.add(TimeDistributed(Dense(num_features, activation='softmax')))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', 'categorical_crossentropy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train LSTM\n",
    "def train_model(model, X, bidirectional=True, epochs=15, batch_size=32, verbose=1):\n",
    "    Y = deepcopy(X)\n",
    "    if not bidirectional:\n",
    "        X = X[0:-1] # do not input the final time step in unidirectional LSTM\n",
    "        Y = Y[1:] # labels include all time steps but the first one in unidir. LSTM\n",
    "    model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composing with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a single index from a sample of a softmax distribution vector\n",
    "def sample_distribution(dist_vec, num_categories):\n",
    "    return tf.random.categorical(dist_vec.reshape(1, num_categories), 1).numpy().flatten()[0]\n",
    "\n",
    "# use the trained model to compose new music by feeding in a single input and desired length\n",
    "def compose(pitch_model, duration_model, pitch_prompt, duration_prompt, length=50):\n",
    "    '''pitch_model: the trained model for pitch predictions\n",
    "       duration_model: trained model for duration predictions\n",
    "       pitch_prompt: the first pitch of the piece (index of the one-hot encoded pitch vector)\n",
    "       duration_prompt: the first duration of the piece (index of the one-hot encoded duration vector)\n",
    "       length: how many time steps to generate for\n",
    "       \n",
    "       returns a music21.stream.Stream object representing the composition\n",
    "    '''    \n",
    "    # the lists that hold the indices of the values to index in to pitches/durations lists\n",
    "    generated_pitches, generated_durations = [pitch_prompt], [duration_prompt]\n",
    "    \n",
    "    current_pitch, current_duration = pitch_prompt, duration_prompt\n",
    "    for t in range(length):\n",
    "        # model only accepts 3D inputs\n",
    "        pitch_vec = timestep_to3d(vectorize(current_pitch, num_pitches))\n",
    "        duration_vec = timestep_to3d(vectorize(current_duration, num_durations))\n",
    "        \n",
    "        # predict the output distributions\n",
    "        pitch_pred = pitch_model.predict(pitch_vec)\n",
    "        duration_pred = duration_model.predict(duration_vec)\n",
    "        # sample the distributions (returns the index of the one-hot vectors)\n",
    "        next_pitch = sample_distribution(pitch_pred, num_pitches)\n",
    "        print(f'Sampled pitch index {next_pitch}: MIDI no. {pitches[next_pitch]}')\n",
    "        next_duration = sample_distribution(duration_pred, num_durations)\n",
    "        print(f'Sampled duration index {next_duration}: quarter length {durations[next_duration]}')\n",
    "        generated_pitches.append(next_pitch)\n",
    "        generated_durations.append(next_duration)\n",
    "        \n",
    "        # get ready for next iteration\n",
    "        current_pitch, current_duration = next_pitch, next_duration\n",
    "        \n",
    "    \n",
    "    composed_stream = stream.Stream()\n",
    "    for pair in list(zip(generated_pitches, generated_durations)):\n",
    "        p = pitch.Pitch(midi=pitches[pair[0]])\n",
    "        d = duration.Duration(durations[pair[1]])\n",
    "        n = note.Note()\n",
    "        n.pitch = p\n",
    "        n.duration = d\n",
    "        composed_stream.append(n)\n",
    "    \n",
    "    return composed_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bidirectional_vals = [True, False]\n",
    "lstm_cell_vals = [500, 1000, 2000]\n",
    "temperature_vals = [0.2, 0.5, 1.0, 10.0]\n",
    "epoch_batch_vals = [(1, 1), (5, 8), (10, 16), (30, 32)] # [(epochs, batch_size), ...]\n",
    "\n",
    "# generate sets of parameters on which to build/train models for testing purposes\n",
    "def generate_param_sets(start=None, end=None):\n",
    "    if start ^ end:  # ^ is XOR; must pass either no arguments or both\n",
    "        raise ValueError('Must pass no optional arguments or both optional arguments; received one')\n",
    "        \n",
    "    sets = []\n",
    "    for bidirectional in bidirectional_vals:\n",
    "        for lstm_cells in lstm_cell_vals:\n",
    "            for temperature in temperature_vals:\n",
    "                for epochs, batch_size in epoch_batch_vals:\n",
    "                    s = {\n",
    "                        \"bidirectional\": bidirectional,\n",
    "                        \"lstm_cells\": lstm_cells,\n",
    "                        \"temperature\": temperature,\n",
    "                        \"epochs\": epochs,\n",
    "                        \"batch_size\": batch_size\n",
    "                    }\n",
    "                    sets.append(s)\n",
    "                    \n",
    "    if start is None and end is None:\n",
    "        return sets\n",
    "    else:\n",
    "        return sets[start:end+1] # make end index inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetadataModel:\n",
    "    def __init__(self, num_features, lstm_cells, bidirectional, temperature, epochs,\\\n",
    "                 batch_size, verbose=0, id=None):\n",
    "        self._model = get_model(num_features, lstm_cells, bidirectional, temperature)\n",
    "        self._num_features = num_features\n",
    "        self._lstm_cells = lstm_cells\n",
    "        self._bidirectional = bidirectional\n",
    "        self._temperature = temperature\n",
    "        self._epochs = epochs\n",
    "        self._batch_size = batch_size\n",
    "        self.verbose = verbose # no underscore because this should be mutable\n",
    "        self._name = '_'.join([str(bidirectional), str(lstm_cells), str(temperature), str(epochs), str(batch_size)])\n",
    "        if id is not None:\n",
    "            self.name += f\"_{id}\"\n",
    "        self._total_training_time = 0.0 # in seconds\n",
    "    \n",
    "    # ---- setting properties so that these attributes are immutable ----\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    \n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "        \n",
    "    @property\n",
    "    def num_features(self):\n",
    "        return self._num_features\n",
    "    \n",
    "    @property\n",
    "    def lstm_cells(self):\n",
    "        return self._lstm_cells\n",
    "    \n",
    "    @property\n",
    "    def bidirectional(self):\n",
    "        return self._bidirectional\n",
    "    \n",
    "    @property\n",
    "    def temperature(self):\n",
    "        return self._temperature\n",
    "    \n",
    "    @property\n",
    "    def epochs(self):\n",
    "        return self._epochs\n",
    "    \n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self._batch_size\n",
    "        \n",
    "    # returns a string version of training time\n",
    "    @property\n",
    "    def training_duration(self):\n",
    "        total_time = self._total_training_time\n",
    "        hours = int(total_time // 3600)  # 3600 seconds/hour\n",
    "        minutes = int((total_time - (3600 * hours)) // 60) # subtract the hours from remaining time; 60 sec/min\n",
    "        seconds = (total_time - (3600 * hours)) - (60 * minutes)\n",
    "        return f\"{hours}h {minutes}m {seconds}s\"\n",
    "            \n",
    "    def train(self, X):\n",
    "        start_time = time.time()\n",
    "        train_model(self.model, X, self.bidirectional, self.epochs, self.batch_size, self.verbose)\n",
    "        end_time = time.time()\n",
    "        self._total_training_time += end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests(pitch_short, pitch_medium, pitch_long, duration_short, duration_medium, duration_long,\\\n",
    "              num_compositions=5, verbose=0):\n",
    "    param_sets = generate_param_sets()\n",
    "    pitch_models, duration_models = [], []\n",
    "    model_no = 1 # which iteration of model we are on\n",
    "    if not os.path.exists(\"models\"):\n",
    "            os.mkdir(\"models\")\n",
    "            \n",
    "    test_start_time=time.time()            \n",
    "    for params in param_sets:\n",
    "        bidirectional = params[\"bidirectional\"]\n",
    "        lstm_cells = params[\"lstm_cells\"]\n",
    "        temperature = params[\"temperature\"]\n",
    "        epochs = params[\"epochs\"]\n",
    "        batch_size = params[\"batch_size\"]\n",
    "        \n",
    "        if verbose > 0:\n",
    "            print(f\"Model {model_no}:\\n\\tbidirectional – {bidirectional}\\n\\tlstm cells – {lstm_cells}\\\n",
    "            \\n\\ttemperature – {temperature}\\n\\tepochs – {epochs}\\n\\tbatch size – {batch_size}\")\n",
    "        \n",
    "        pitch_model = MetadataModel(num_pitches, lstm_cells, bidirectional, temperature, epochs, batch_size, verbose)\n",
    "        duration_model = MetadataModel(num_durations, lstm_cells, bidirectional, temperature, epochs, batch_size, verbose)\n",
    "        \n",
    "        # train the pitch network\n",
    "        if verbose > 0:\n",
    "            print('\\n\\tTraining pitch generation network...')\n",
    "            print('\\t\\tOn short data set:')\n",
    "        pitch_model.train(pitch_short)\n",
    "        if verbose > 0:\n",
    "            print('\\t\\tOn medium data set:')\n",
    "        pitch_model.train(pitch_medium)\n",
    "        if verbose > 0:\n",
    "            print('\\t\\tOn long data set:')\n",
    "        pitch_model.train(pitch_long)\n",
    "        pitch_model.model.save(f\"{MODEL_DIRECTORY}/{model_no}_pitch_{pitch_model.name}.h5\")\n",
    "        if verbose > 0:\n",
    "            print(f\"\\t\\tPitch model training complete: saved at {MODEL_DIRECTORY}/{model_no}_pitch_{pitch_model.name}.h5\")\n",
    "            print(\"\\tTotal training time'\")\n",
    "        \n",
    "        # train the duration network\n",
    "        if verbose > 0:\n",
    "            print('\\n\\tTraining rhythm (duration) generation network...')\n",
    "            print('\\t\\tOn short data set:')\n",
    "        duration_model.train(duration_short)\n",
    "        return\n",
    "        if verbose > 0:\n",
    "            print('\\t\\tOn medium data set:')\n",
    "        duration_model.train(duration_medium)\n",
    "        if verbose > 0:\n",
    "            print('\\t\\tOn long data set:')\n",
    "        duration_model.train(duration_long)\n",
    "        duration_model.model.save(f\"{MODEL_DIRECTORY}/{model_no}_duration_{duration_model.name}.h5\")\n",
    "        if verbose > 0:\n",
    "            print(f\"\\t\\tPitch model training complete: saved at {MODEL_DIRECTORY}/{model_no}_duration_{duration_model.name}.h5\")\n",
    "        \n",
    "        if verbose > 0:\n",
    "            print(f'\\tModel {model_iter} training complete')\n",
    "        \n",
    "        # compose outputs and save them\n",
    "        if not os.path.exists(f\"{COMPOSITION_DIRECTORY}/model_no_{model_no}\"):\n",
    "            os.makedirs(f\"{COMPOSITION_DIRECTORY}/model_no_{model_no}\")\n",
    "        comp_count = 1\n",
    "        for c in num_compositions:\n",
    "            pitch_prompt = #TODO\n",
    "            duration_prompt = #TODO\n",
    "            composition = compose(pitch_model, duration_model, pitch_prompt, duration_prompt, length=100)\n",
    "            composition.write('musicxml', f'composition_{comp_count}.mxl')\n",
    "            composition.write('midi', f'composition_{comp_count}.mid')\n",
    "            \n",
    "        model_no = model_no + 1\n",
    "        print('–' * 50 + \"\\n\\n\")\n",
    "        \n",
    "        \n",
    "    test_end_time=time.time()\n",
    "    total_time = test_end_time - test_start_time\n",
    "    hours = int(total_time // 3600)  # 3600 seconds/hour\n",
    "    minutes = int((total_time - (3600 * hours)) // 60) # subtract the hours from remaining time; 60 sec/min\n",
    "    seconds = (total_time - (3600 * hours)) - (60 * minutes)\n",
    "    print(f\"TRAINING COMPLETE – elapsed time: {hours}h {minutes}m {seconds}s\")\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1:\n",
      "\tbidirectional – True\n",
      "\tlstm cells – 500            \n",
      "\ttemperature – 0.2\n",
      "\tepochs – 1\n",
      "\tbatch size – 1\n",
      "\n",
      "\tTraining pitch generation network...\n",
      "\t\tOn short data set:\n",
      "Train on 1668 samples\n",
      "1668/1668 [==============================] - 576s 345ms/sample - loss: 0.1334 - accuracy: 0.8758 - categorical_crossentropy: 0.1334\n",
      "\t\tOn medium data set:\n",
      "Train on 972 samples\n",
      "972/972 [==============================] - 366s 377ms/sample - loss: 0.0083 - accuracy: 0.8990 - categorical_crossentropy: 0.0083\n",
      "\t\tOn long data set:\n",
      "Train on 612 samples\n",
      "612/612 [==============================] - 297s 485ms/sample - loss: 0.0092 - accuracy: 0.8988 - categorical_crossentropy: 0.0092\n",
      "\t\tPitch model training complete: saved at models/1_pitch_True_500_0.2_1_1.h5\n",
      "'tTotal training time'\n",
      "\n",
      "\tTraining rhythm (duration) generation network...\n",
      "\t\tOn short data set:\n",
      "Train on 1668 samples\n",
      " 535/1668 [========>.....................] - ETA: 5:53 - loss: 0.0719 - accuracy: 0.8924 - categorical_crossentropy: 0.0719"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-219cd7e0b655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshort_seqs_pitch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedium_seqs_pitch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlong_seqs_pitch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshort_seqs_duration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedium_seqs_duration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlong_seqs_duration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-c99af6e1fe55>\u001b[0m in \u001b[0;36mrun_tests\u001b[0;34m(pitch_short, pitch_medium, pitch_long, duration_short, duration_medium, duration_long, verbose)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\tTraining rhythm (duration) generation network...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t\\tOn short data set:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mduration_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduration_short\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-fa76a80acd00>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-9d9dffbef1c0>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, X, bidirectional, epochs, batch_size, verbose)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# do not input the final time step in unidirectional LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# labels include all time steps but the first one in unidir. LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_tests(short_seqs_pitch, medium_seqs_pitch, long_seqs_pitch, short_seqs_duration, medium_seqs_duration, long_seqs_duration, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
